{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import  Input, LSTM,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Embedding\n",
    "import cPickle as pickle\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=5272322048, percent=36.0, used=2463342592, free=3402358784, active=3214114816, inactive=1365135360, buffers=725307392, cached=1649274880, shared=238923776)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FN1='embeddingReviewsFilewithOtherdata'\n",
    "FN2='myPaddedDataFile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('%s.pkl'%FN2,'rb') as fp:\n",
    "    embeddingReviews, modiefiedSummaryWord_index,myPaddedData= pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=5242023936, percent=36.4, used=2493640704, free=3372060672, active=3270201344, inactive=1338785792, buffers=725331968, cached=1649250304, shared=238923776)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paddedReviews=myPaddedData['paddedReviews']\n",
    "paddedSummary=myPaddedData['paddedSummary']\n",
    "paddedModifiedSummary=myPaddedData['paddedModifiedSummary']\n",
    "testPaddedReviews=myPaddedData['testPaddedReviews']\n",
    "testPaddedSummary=myPaddedData['testPaddedSummary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1150, 400), (1150, 40), (1150, 40))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataIX=paddedReviews\n",
    "TrainingDataTY=paddedSummary\n",
    "TrainingDataIY=paddedModifiedSummary\n",
    "TrainingDataIX.shape,TrainingDataIY.shape,TrainingDataTY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestDataIX=testPaddedReviews\n",
    "TestDataTY=testPaddedSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=5241278464, percent=36.4, used=2494373888, free=3371266048, active=3270791168, inactive=1338593280, buffers=725372928, cached=1649270784, shared=238923776)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples=len(TrainingDataIX)\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModifiedVocabSize=len(modiefiedSummaryWord_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6023"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModifiedVocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=5239406592, percent=36.4, used=2496147456, free=3369172992, active=3272024064, inactive=1338773504, buffers=725659648, cached=1649303552, shared=238923776)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderInputSummary=to_categorical(paddedModifiedSummary,num_classes=ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderInputSummary=decoderInputSummary.reshape(nb_samples,-1,ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 40, 6023)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderInputSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=5055418368, percent=38.6, used=2681806848, free=3185070080, active=3454480384, inactive=1337245696, buffers=725692416, cached=1647714304, shared=237355008)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderTargetSummary=to_categorical(paddedSummary,num_classes=ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 40, 6023)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderTargetSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderTargetSummary=decoderTargetSummary.reshape(nb_samples,-1,ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 40, 6023)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderTargetSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240283648, available=4862971904, percent=41.0, used=2874261504, free=2992566272, active=3642580992, inactive=1337253888, buffers=725741568, cached=1647714304, shared=237355008)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('%s.pkl'%'embeddingReviewsFile', 'rb') as fp:\n",
    "    embeddingReviews = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ReviewsVocabSize=30171#39119#30172#27789\n",
    "maxReviewLength=400#300\n",
    "maxSummaryLength=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input shape is:-> (?, 400)\n"
     ]
    }
   ],
   "source": [
    "#Encoder\n",
    "EncoderEmbeddingLayer = Embedding(ReviewsVocabSize,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddingReviews],\n",
    "                            input_length=maxReviewLength,\n",
    "                            trainable=True,\n",
    "                            #mask_zero=True\n",
    "                                   )\n",
    "encoderInputLayer=Input(shape=(maxReviewLength,))\n",
    "print('encoder_input shape is:->',encoderInputLayer.shape)\n",
    "embedded_Encoder_inputSequence=EncoderEmbeddingLayer(encoderInputLayer)\n",
    "encoderLSTMLayer=LSTM(256,return_state=True)\n",
    "#print(type(encoder_LSTM))\n",
    "encoderOutput,encoderHState,encoderCState=encoderLSTMLayer(embedded_Encoder_inputSequence)\n",
    "#print('encoder_output shape:->',encoder_output.shape)\n",
    "encoderStates=[encoderHState,encoderCState]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoderInputLayer=Input(shape=(None,ModifiedVocabSize))\n",
    "#embedded_Decoder_inputSequence=Decoder_embedding_layer(decoder_input)\n",
    "decoderLSTMLayer=LSTM(256,return_sequences=True, return_state = True,)\n",
    "decoderOutput,decoderHState,decoderCState=decoderLSTMLayer(decoderInputLayer,initial_state=encoderStates)\n",
    "decoderDenseLayer=Dense(ModifiedVocabSize,activation='softmax',kernel_regularizer=regularizers.l2(0.015))\n",
    "finalDecoderOutput=decoderDenseLayer(decoderOutput)\n",
    "#finalDecoderOutput=Dropout(0.25)(finalDecoderOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model=Model(inputs=[encoderInputLayer,decoderInputLayer],output=finalDecoderOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('AbstractiveTextSummarization1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999,decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='AbstractiveTextSummarization2.2.hdf5', verbose=1, save_best_only=False,mode='auto',period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 400, 100)     3017100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 6023)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  6430720     input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 6023)   1547911     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 11,361,299\n",
      "Trainable params: 11,361,299\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 281.00 337.00\" width=\"281pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 277,-333 277,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139945734461392 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139945734461392</title>\n",
       "<polygon fill=\"none\" points=\"18,-292.5 18,-328.5 143,-328.5 143,-292.5 18,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-306.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139945811664784 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139945811664784</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 161,-255.5 161,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-233.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 139945734461392&#45;&gt;139945811664784 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139945734461392-&gt;139945811664784</title>\n",
       "<path d=\"M80.5,-292.313C80.5,-284.289 80.5,-274.547 80.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"84.0001,-265.529 80.5,-255.529 77.0001,-265.529 84.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945811501648 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139945811501648</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-146.5 31.5,-182.5 129.5,-182.5 129.5,-146.5 31.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-160.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 139945811664784&#45;&gt;139945811501648 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139945811664784-&gt;139945811501648</title>\n",
       "<path d=\"M80.5,-219.313C80.5,-211.289 80.5,-201.547 80.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"84.0001,-192.529 80.5,-182.529 77.0001,-192.529 84.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945812087696 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139945812087696</title>\n",
       "<polygon fill=\"none\" points=\"148,-146.5 148,-182.5 273,-182.5 273,-146.5 148,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-160.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139945806514960 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139945806514960</title>\n",
       "<polygon fill=\"none\" points=\"96.5,-73.5 96.5,-109.5 194.5,-109.5 194.5,-73.5 96.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145.5\" y=\"-87.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 139945812087696&#45;&gt;139945806514960 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139945812087696-&gt;139945806514960</title>\n",
       "<path d=\"M194.765,-146.313C186.701,-137.505 176.741,-126.625 167.892,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"170.424,-114.541 161.09,-109.529 165.261,-119.268 170.424,-114.541\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945811501648&#45;&gt;139945806514960 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139945811501648-&gt;139945806514960</title>\n",
       "<path d=\"M96.2347,-146.313C104.299,-137.505 114.259,-126.625 123.108,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125.739,-119.268 129.91,-109.529 120.576,-114.541 125.739,-119.268\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139945737223824 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139945737223824</title>\n",
       "<polygon fill=\"none\" points=\"94.5,-0.5 94.5,-36.5 196.5,-36.5 196.5,-0.5 94.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139945806514960&#45;&gt;139945737223824 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139945806514960-&gt;139945737223824</title>\n",
       "<path d=\"M145.5,-73.3129C145.5,-65.2895 145.5,-55.5475 145.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"149,-46.5288 145.5,-36.5288 142,-46.5289 149,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/500\n",
      "1600/1600 [==============================] - 250s 156ms/step - loss: 13.9392 - acc: 0.1516 - val_loss: 11.9526 - val_acc: 0.4601\n",
      "\n",
      "Epoch 00001: saving model to AbstractiveTextSummarization2.2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:2368: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500\n",
      "1600/1600 [==============================] - 249s 156ms/step - loss: 13.2093 - acc: 0.3545 - val_loss: 11.3606 - val_acc: 0.4603\n",
      "\n",
      "Epoch 00002: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 3/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 12.6991 - acc: 0.3573 - val_loss: 10.9102 - val_acc: 0.4601\n",
      "\n",
      "Epoch 00003: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 4/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 12.2531 - acc: 0.3573 - val_loss: 10.3156 - val_acc: 0.4598\n",
      "\n",
      "Epoch 00004: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 5/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 11.7202 - acc: 0.3570 - val_loss: 9.7858 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00005: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 6/500\n",
      "1600/1600 [==============================] - 273s 171ms/step - loss: 11.3507 - acc: 0.3550 - val_loss: 9.4178 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00006: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 7/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 11.0486 - acc: 0.3567 - val_loss: 9.1098 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00007: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 8/500\n",
      "1600/1600 [==============================] - 271s 170ms/step - loss: 10.7847 - acc: 0.3569 - val_loss: 8.8363 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00008: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 9/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 10.5801 - acc: 0.3553 - val_loss: 8.5842 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00009: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 10/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 10.3576 - acc: 0.3572 - val_loss: 8.3473 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00010: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 11/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 10.1931 - acc: 0.3552 - val_loss: 8.1299 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00011: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 12/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 9.9954 - acc: 0.3572 - val_loss: 7.9316 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00012: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 13/500\n",
      "1600/1600 [==============================] - 273s 171ms/step - loss: 9.8458 - acc: 0.3566 - val_loss: 7.7569 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00013: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 14/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 9.7090 - acc: 0.3556 - val_loss: 7.6042 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00014: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 15/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 9.6091 - acc: 0.3558 - val_loss: 7.4727 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00015: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 16/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 9.4928 - acc: 0.3575 - val_loss: 7.3578 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00016: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 17/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 9.4187 - acc: 0.3544 - val_loss: 7.2585 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00017: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 18/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 9.3063 - acc: 0.3568 - val_loss: 7.1700 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00018: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 19/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 9.2548 - acc: 0.3553 - val_loss: 7.0906 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00019: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 20/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 9.1614 - acc: 0.3587 - val_loss: 7.0180 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00020: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 21/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 9.0951 - acc: 0.3593 - val_loss: 6.9518 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00021: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 22/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 9.0728 - acc: 0.3571 - val_loss: 6.8910 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00022: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 23/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 9.0260 - acc: 0.3565 - val_loss: 6.8346 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00023: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 24/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 8.9479 - acc: 0.3586 - val_loss: 6.7819 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00024: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 25/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 8.9406 - acc: 0.3573 - val_loss: 6.7327 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00025: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 26/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 8.8868 - acc: 0.3565 - val_loss: 6.6866 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00026: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 27/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 8.8387 - acc: 0.3577 - val_loss: 6.6430 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00027: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 28/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.8258 - acc: 0.3560 - val_loss: 6.6020 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00028: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 29/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 8.8187 - acc: 0.3552 - val_loss: 6.5633 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00029: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 30/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 8.8043 - acc: 0.3549 - val_loss: 6.5268 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00030: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 31/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 8.7196 - acc: 0.3577 - val_loss: 6.4922 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00031: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 32/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 8.7207 - acc: 0.3550 - val_loss: 6.4594 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00032: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 33/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 8.6650 - acc: 0.3562 - val_loss: 6.4283 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00033: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 34/500\n",
      "1600/1600 [==============================] - 260s 163ms/step - loss: 8.6473 - acc: 0.3556 - val_loss: 6.3986 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00034: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 35/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 8.6228 - acc: 0.3568 - val_loss: 6.3704 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00035: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 36/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 8.6035 - acc: 0.3563 - val_loss: 6.3434 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00036: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 37/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 8.5822 - acc: 0.3576 - val_loss: 6.3176 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00037: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 38/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 8.5554 - acc: 0.3581 - val_loss: 6.2929 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00038: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 39/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.5419 - acc: 0.3570 - val_loss: 6.2691 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00039: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 40/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.4816 - acc: 0.3577 - val_loss: 6.2462 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00040: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 41/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.5322 - acc: 0.3552 - val_loss: 6.2243 - val_acc: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 42/500\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 8.4831 - acc: 0.3566 - val_loss: 6.2032 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00042: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 43/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 8.4734 - acc: 0.3565 - val_loss: 6.1828 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00043: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 44/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 8.4886 - acc: 0.3559 - val_loss: 6.1632 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00044: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 45/500\n",
      "1600/1600 [==============================] - 273s 171ms/step - loss: 8.4634 - acc: 0.3569 - val_loss: 6.1442 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00045: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 46/500\n",
      "1600/1600 [==============================] - 273s 170ms/step - loss: 8.4715 - acc: 0.3547 - val_loss: 6.1260 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00046: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 47/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.3970 - acc: 0.3579 - val_loss: 6.1082 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00047: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 48/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.3815 - acc: 0.3575 - val_loss: 6.0909 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00048: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 49/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.4090 - acc: 0.3539 - val_loss: 6.0743 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00049: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 50/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.4033 - acc: 0.3540 - val_loss: 6.0582 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00050: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 51/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 8.3715 - acc: 0.3556 - val_loss: 6.0426 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00051: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 52/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.3403 - acc: 0.3582 - val_loss: 6.0273 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00052: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 53/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 8.3440 - acc: 0.3572 - val_loss: 6.0125 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00053: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 54/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.3292 - acc: 0.3579 - val_loss: 5.9981 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00054: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 55/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 8.3550 - acc: 0.3555 - val_loss: 5.9841 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00055: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 56/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.2822 - acc: 0.3587 - val_loss: 5.9706 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00056: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 57/500\n",
      "1600/1600 [==============================] - 276s 173ms/step - loss: 8.3247 - acc: 0.3555 - val_loss: 5.9573 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00057: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 58/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 8.3061 - acc: 0.3554 - val_loss: 5.9444 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00058: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 59/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.2514 - acc: 0.3583 - val_loss: 5.9318 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00059: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 60/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 8.2665 - acc: 0.3569 - val_loss: 5.9195 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00060: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 61/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.2816 - acc: 0.3556 - val_loss: 5.9076 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00061: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 62/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.2572 - acc: 0.3559 - val_loss: 5.8960 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00062: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 63/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 8.2146 - acc: 0.3568 - val_loss: 5.8845 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00063: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 64/500\n",
      "1600/1600 [==============================] - 273s 170ms/step - loss: 8.2390 - acc: 0.3564 - val_loss: 5.8734 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00064: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 65/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.2415 - acc: 0.3568 - val_loss: 5.8625 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00065: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 66/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.2365 - acc: 0.3554 - val_loss: 5.8519 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00066: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 67/500\n",
      "1600/1600 [==============================] - 276s 173ms/step - loss: 8.2377 - acc: 0.3550 - val_loss: 5.8415 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00067: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 68/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 8.2200 - acc: 0.3565 - val_loss: 5.8314 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00068: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 69/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.1962 - acc: 0.3576 - val_loss: 5.8214 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00069: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 70/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 8.1597 - acc: 0.3584 - val_loss: 5.8117 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00070: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 71/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.1835 - acc: 0.3555 - val_loss: 5.8021 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00071: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 72/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.1648 - acc: 0.3573 - val_loss: 5.7927 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00072: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 73/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 8.1590 - acc: 0.3563 - val_loss: 5.7836 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00073: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 74/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 8.1604 - acc: 0.3551 - val_loss: 5.7745 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00074: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 75/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.1842 - acc: 0.3544 - val_loss: 5.7658 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00075: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 76/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 8.1260 - acc: 0.3570 - val_loss: 5.7572 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00076: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 77/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 8.1439 - acc: 0.3567 - val_loss: 5.7487 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00077: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 78/500\n",
      "1600/1600 [==============================] - 276s 173ms/step - loss: 8.1525 - acc: 0.3559 - val_loss: 5.7403 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00078: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 79/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 8.1038 - acc: 0.3577 - val_loss: 5.7322 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00079: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 80/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.1108 - acc: 0.3573 - val_loss: 5.7241 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00080: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 81/500\n",
      "1600/1600 [==============================] - 278s 173ms/step - loss: 8.1178 - acc: 0.3560 - val_loss: 5.7163 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00081: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 82/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.0857 - acc: 0.3573 - val_loss: 5.7085 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00082: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 83/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 8.1195 - acc: 0.3549 - val_loss: 5.7009 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00083: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 84/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 8.0807 - acc: 0.3573 - val_loss: 5.6934 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00084: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 85/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 8.0883 - acc: 0.3565 - val_loss: 5.6861 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00085: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 86/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 8.0657 - acc: 0.3585 - val_loss: 5.6788 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00086: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 87/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 8.0687 - acc: 0.3575 - val_loss: 5.6717 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00087: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 88/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 8.0599 - acc: 0.3566 - val_loss: 5.6647 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00088: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 89/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 8.0909 - acc: 0.3549 - val_loss: 5.6579 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00089: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 90/500\n",
      "1600/1600 [==============================] - 258s 161ms/step - loss: 8.0595 - acc: 0.3555 - val_loss: 5.6511 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00090: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 91/500\n",
      "1600/1600 [==============================] - 260s 163ms/step - loss: 8.0291 - acc: 0.3568 - val_loss: 5.6444 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00091: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 92/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 8.0738 - acc: 0.3546 - val_loss: 5.6379 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00092: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 93/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.0348 - acc: 0.3568 - val_loss: 5.6315 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00093: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 94/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 8.0263 - acc: 0.3569 - val_loss: 5.6251 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00094: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 95/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 8.0381 - acc: 0.3568 - val_loss: 5.6188 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00095: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 96/500\n",
      "1600/1600 [==============================] - 274s 172ms/step - loss: 8.0515 - acc: 0.3566 - val_loss: 5.6127 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00096: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 97/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 8.0437 - acc: 0.3565 - val_loss: 5.6066 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00097: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 98/500\n",
      "1600/1600 [==============================] - 260s 162ms/step - loss: 7.9981 - acc: 0.3584 - val_loss: 5.6006 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00098: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 99/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 8.0214 - acc: 0.3565 - val_loss: 5.5948 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00099: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 100/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.9899 - acc: 0.3583 - val_loss: 5.5889 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00100: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 101/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.9806 - acc: 0.3568 - val_loss: 5.5832 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00101: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 102/500\n",
      "1600/1600 [==============================] - 258s 161ms/step - loss: 7.9792 - acc: 0.3576 - val_loss: 5.5775 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00102: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 103/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.9781 - acc: 0.3557 - val_loss: 5.5719 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00103: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 104/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.9976 - acc: 0.3565 - val_loss: 5.5664 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00104: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 105/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 8.0156 - acc: 0.3549 - val_loss: 5.5610 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00105: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 106/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.9780 - acc: 0.3574 - val_loss: 5.5557 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00106: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 107/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.9776 - acc: 0.3570 - val_loss: 5.5504 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00107: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 108/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.9835 - acc: 0.3580 - val_loss: 5.5451 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00108: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 109/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 8.0082 - acc: 0.3550 - val_loss: 5.5400 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00109: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 110/500\n",
      "1600/1600 [==============================] - 276s 173ms/step - loss: 7.9661 - acc: 0.3573 - val_loss: 5.5349 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00110: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 111/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.9462 - acc: 0.3588 - val_loss: 5.5299 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00111: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 112/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.9514 - acc: 0.3573 - val_loss: 5.5250 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00112: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 113/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.9748 - acc: 0.3554 - val_loss: 5.5201 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00113: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 114/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.9465 - acc: 0.3566 - val_loss: 5.5153 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00114: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 115/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.9281 - acc: 0.3567 - val_loss: 5.5105 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00115: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 116/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.9356 - acc: 0.3574 - val_loss: 5.5058 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00116: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 117/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.9418 - acc: 0.3557 - val_loss: 5.5012 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00117: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 118/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.9608 - acc: 0.3555 - val_loss: 5.4965 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00118: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 119/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.9814 - acc: 0.3541 - val_loss: 5.4920 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00119: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 120/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.9204 - acc: 0.3580 - val_loss: 5.4876 - val_acc: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00120: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 121/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.9772 - acc: 0.3550 - val_loss: 5.4831 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00121: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 122/500\n",
      "1600/1600 [==============================] - 278s 173ms/step - loss: 7.9120 - acc: 0.3579 - val_loss: 5.4788 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00122: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 123/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 7.9385 - acc: 0.3563 - val_loss: 5.4744 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00123: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 124/500\n",
      "1600/1600 [==============================] - 273s 171ms/step - loss: 7.8956 - acc: 0.3592 - val_loss: 5.4701 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00124: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 125/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.8827 - acc: 0.3596 - val_loss: 5.4659 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00125: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 126/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.8872 - acc: 0.3578 - val_loss: 5.4616 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00126: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 127/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.9130 - acc: 0.3569 - val_loss: 5.4575 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00127: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 128/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.9302 - acc: 0.3548 - val_loss: 5.4534 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00128: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 129/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.9027 - acc: 0.3577 - val_loss: 5.4494 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00129: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 130/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.8821 - acc: 0.3566 - val_loss: 5.4454 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00130: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 131/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.8717 - acc: 0.3580 - val_loss: 5.4414 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00131: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 132/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.8828 - acc: 0.3569 - val_loss: 5.4374 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00132: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 133/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.8966 - acc: 0.3566 - val_loss: 5.4336 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00133: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 134/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.9051 - acc: 0.3561 - val_loss: 5.4297 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00134: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 135/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.8764 - acc: 0.3564 - val_loss: 5.4259 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00135: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 136/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.9088 - acc: 0.3552 - val_loss: 5.4221 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00136: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 137/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.9025 - acc: 0.3559 - val_loss: 5.4184 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00137: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 138/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8610 - acc: 0.3574 - val_loss: 5.4147 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00138: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 139/500\n",
      "1600/1600 [==============================] - 258s 161ms/step - loss: 7.8867 - acc: 0.3555 - val_loss: 5.4111 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00139: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 140/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.8777 - acc: 0.3554 - val_loss: 5.4075 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00140: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 141/500\n",
      "1600/1600 [==============================] - 260s 162ms/step - loss: 7.8316 - acc: 0.3584 - val_loss: 5.4039 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00141: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 142/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.8727 - acc: 0.3564 - val_loss: 5.4003 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00142: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 143/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.8187 - acc: 0.3578 - val_loss: 5.3968 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00143: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 144/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 7.8664 - acc: 0.3561 - val_loss: 5.3934 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00144: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 145/500\n",
      "1600/1600 [==============================] - 262s 163ms/step - loss: 7.8858 - acc: 0.3551 - val_loss: 5.3899 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00145: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 146/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8601 - acc: 0.3569 - val_loss: 5.3865 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00146: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 147/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.8406 - acc: 0.3563 - val_loss: 5.3831 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00147: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 148/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.8584 - acc: 0.3566 - val_loss: 5.3798 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00148: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 149/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 7.8149 - acc: 0.3586 - val_loss: 5.3764 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00149: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 150/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8586 - acc: 0.3556 - val_loss: 5.3731 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00150: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 151/500\n",
      "1600/1600 [==============================] - 258s 161ms/step - loss: 7.8371 - acc: 0.3565 - val_loss: 5.3699 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00151: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 152/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8444 - acc: 0.3565 - val_loss: 5.3666 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00152: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 153/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.8380 - acc: 0.3567 - val_loss: 5.3635 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00153: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 154/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8458 - acc: 0.3549 - val_loss: 5.3603 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00154: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 155/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8320 - acc: 0.3553 - val_loss: 5.3572 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00155: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 156/500\n",
      "1600/1600 [==============================] - 258s 162ms/step - loss: 7.8773 - acc: 0.3539 - val_loss: 5.3541 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00156: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 157/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8333 - acc: 0.3561 - val_loss: 5.3510 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00157: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 158/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7823 - acc: 0.3600 - val_loss: 5.3479 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00158: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 159/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8284 - acc: 0.3563 - val_loss: 5.3449 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00159: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8168 - acc: 0.3570 - val_loss: 5.3419 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00160: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 161/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8264 - acc: 0.3571 - val_loss: 5.3389 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00161: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 162/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.8340 - acc: 0.3553 - val_loss: 5.3359 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00162: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 163/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8369 - acc: 0.3576 - val_loss: 5.3330 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00163: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 164/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.8131 - acc: 0.3570 - val_loss: 5.3301 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00164: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 165/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.8308 - acc: 0.3549 - val_loss: 5.3272 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00165: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 166/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7958 - acc: 0.3577 - val_loss: 5.3243 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00166: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 167/500\n",
      "1600/1600 [==============================] - 260s 163ms/step - loss: 7.7894 - acc: 0.3583 - val_loss: 5.3215 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00167: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 168/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.7922 - acc: 0.3558 - val_loss: 5.3187 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00168: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 169/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.8142 - acc: 0.3569 - val_loss: 5.3158 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00169: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 170/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.8029 - acc: 0.3570 - val_loss: 5.3131 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00170: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 171/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.8154 - acc: 0.3555 - val_loss: 5.3103 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00171: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 172/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8453 - acc: 0.3534 - val_loss: 5.3076 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00172: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 173/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.8017 - acc: 0.3569 - val_loss: 5.3049 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00173: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 174/500\n",
      "1600/1600 [==============================] - 260s 163ms/step - loss: 7.7643 - acc: 0.3576 - val_loss: 5.3022 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00174: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 175/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7981 - acc: 0.3558 - val_loss: 5.2996 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00175: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 176/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.7705 - acc: 0.3578 - val_loss: 5.2970 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00176: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 177/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.8002 - acc: 0.3569 - val_loss: 5.2943 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00177: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 178/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7812 - acc: 0.3579 - val_loss: 5.2917 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00178: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 179/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7629 - acc: 0.3577 - val_loss: 5.2891 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00179: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 180/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.7754 - acc: 0.3565 - val_loss: 5.2866 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00180: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 181/500\n",
      "1600/1600 [==============================] - 258s 161ms/step - loss: 7.7949 - acc: 0.3558 - val_loss: 5.2840 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00181: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 182/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.8037 - acc: 0.3543 - val_loss: 5.2815 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00182: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 183/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7771 - acc: 0.3567 - val_loss: 5.2790 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00183: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 184/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7711 - acc: 0.3561 - val_loss: 5.2765 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00184: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 185/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7995 - acc: 0.3556 - val_loss: 5.2741 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00185: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 186/500\n",
      "1600/1600 [==============================] - 254s 158ms/step - loss: 7.7806 - acc: 0.3559 - val_loss: 5.2716 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00186: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 187/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7860 - acc: 0.3559 - val_loss: 5.2692 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00187: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 188/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7504 - acc: 0.3570 - val_loss: 5.2668 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00188: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 189/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7679 - acc: 0.3546 - val_loss: 5.2644 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00189: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 190/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7317 - acc: 0.3585 - val_loss: 5.2620 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00190: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 191/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7790 - acc: 0.3555 - val_loss: 5.2596 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00191: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 192/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.7325 - acc: 0.3580 - val_loss: 5.2573 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00192: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 193/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7885 - acc: 0.3545 - val_loss: 5.2550 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00193: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 194/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7740 - acc: 0.3561 - val_loss: 5.2526 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00194: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 195/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7881 - acc: 0.3537 - val_loss: 5.2504 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00195: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 196/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7619 - acc: 0.3549 - val_loss: 5.2481 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00196: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 197/500\n",
      "1600/1600 [==============================] - 254s 159ms/step - loss: 7.7398 - acc: 0.3578 - val_loss: 5.2458 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00197: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 198/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.7410 - acc: 0.3579 - val_loss: 5.2436 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00198: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 199/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7688 - acc: 0.3557 - val_loss: 5.2414 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00199: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 200/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7658 - acc: 0.3559 - val_loss: 5.2391 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00200: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 201/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7617 - acc: 0.3562 - val_loss: 5.2369 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00201: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 202/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.7261 - acc: 0.3584 - val_loss: 5.2348 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00202: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 203/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.7466 - acc: 0.3574 - val_loss: 5.2326 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00203: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 204/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.7404 - acc: 0.3558 - val_loss: 5.2304 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00204: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 205/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.6914 - acc: 0.3589 - val_loss: 5.2283 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00205: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 206/500\n",
      "1600/1600 [==============================] - 256s 160ms/step - loss: 7.7583 - acc: 0.3552 - val_loss: 5.2261 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00206: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 207/500\n",
      "1600/1600 [==============================] - 255s 159ms/step - loss: 7.7310 - acc: 0.3572 - val_loss: 5.2240 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00207: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 208/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.7309 - acc: 0.3559 - val_loss: 5.2219 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00208: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 209/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.7248 - acc: 0.3574 - val_loss: 5.2198 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00209: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 210/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.7317 - acc: 0.3561 - val_loss: 5.2178 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00210: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 211/500\n",
      "1600/1600 [==============================] - 263s 165ms/step - loss: 7.7594 - acc: 0.3548 - val_loss: 5.2157 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00211: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 212/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.7159 - acc: 0.3578 - val_loss: 5.2136 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00212: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 213/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.7063 - acc: 0.3575 - val_loss: 5.2116 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00213: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 214/500\n",
      "1600/1600 [==============================] - 266s 167ms/step - loss: 7.7203 - acc: 0.3565 - val_loss: 5.2096 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00214: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 215/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.7569 - acc: 0.3551 - val_loss: 5.2076 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00215: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 216/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.7467 - acc: 0.3553 - val_loss: 5.2056 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00216: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 217/500\n",
      "1600/1600 [==============================] - 271s 170ms/step - loss: 7.7380 - acc: 0.3572 - val_loss: 5.2036 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00217: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 218/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.7396 - acc: 0.3550 - val_loss: 5.2016 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00218: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 219/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.7158 - acc: 0.3571 - val_loss: 5.1997 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00219: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 220/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.7253 - acc: 0.3551 - val_loss: 5.1978 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00220: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 221/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.6999 - acc: 0.3587 - val_loss: 5.1958 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00221: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 222/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.7554 - acc: 0.3543 - val_loss: 5.1939 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00222: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 223/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.7263 - acc: 0.3559 - val_loss: 5.1920 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00223: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 224/500\n",
      "1600/1600 [==============================] - 286s 179ms/step - loss: 7.7246 - acc: 0.3555 - val_loss: 5.1901 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00224: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 225/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.7277 - acc: 0.3552 - val_loss: 5.1882 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00225: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 226/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.7132 - acc: 0.3577 - val_loss: 5.1863 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00226: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 227/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.6864 - acc: 0.3570 - val_loss: 5.1845 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00227: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 228/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.7127 - acc: 0.3567 - val_loss: 5.1826 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00228: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 229/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.7131 - acc: 0.3559 - val_loss: 5.1808 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00229: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 230/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.6852 - acc: 0.3572 - val_loss: 5.1790 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00230: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 231/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.7331 - acc: 0.3545 - val_loss: 5.1771 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00231: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 232/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.7227 - acc: 0.3545 - val_loss: 5.1753 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00232: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 233/500\n",
      "1600/1600 [==============================] - 265s 165ms/step - loss: 7.7250 - acc: 0.3550 - val_loss: 5.1735 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00233: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 234/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.7029 - acc: 0.3568 - val_loss: 5.1717 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00234: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 235/500\n",
      "1600/1600 [==============================] - 260s 162ms/step - loss: 7.7117 - acc: 0.3557 - val_loss: 5.1700 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00235: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 236/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.6971 - acc: 0.3559 - val_loss: 5.1682 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00236: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 237/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.7261 - acc: 0.3542 - val_loss: 5.1665 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00237: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.6823 - acc: 0.3564 - val_loss: 5.1647 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00238: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 239/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.7107 - acc: 0.3549 - val_loss: 5.1630 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00239: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 240/500\n",
      "1600/1600 [==============================] - 257s 160ms/step - loss: 7.6987 - acc: 0.3560 - val_loss: 5.1613 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00240: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 241/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.7078 - acc: 0.3561 - val_loss: 5.1596 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00241: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 242/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.6764 - acc: 0.3578 - val_loss: 5.1579 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00242: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 243/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.6883 - acc: 0.3554 - val_loss: 5.1562 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00243: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 244/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.7167 - acc: 0.3558 - val_loss: 5.1545 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00244: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 245/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.6798 - acc: 0.3568 - val_loss: 5.1528 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00245: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 246/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.6422 - acc: 0.3566 - val_loss: 5.1511 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00246: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 247/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.6750 - acc: 0.3566 - val_loss: 5.1494 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00247: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 248/500\n",
      "1600/1600 [==============================] - 257s 161ms/step - loss: 7.7319 - acc: 0.3545 - val_loss: 5.1478 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00248: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 249/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.6881 - acc: 0.3551 - val_loss: 5.1462 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00249: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 250/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.6646 - acc: 0.3576 - val_loss: 5.1446 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00250: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 251/500\n",
      "1600/1600 [==============================] - 263s 164ms/step - loss: 7.6481 - acc: 0.3587 - val_loss: 5.1429 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00251: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 252/500\n",
      "1600/1600 [==============================] - 263s 165ms/step - loss: 7.6919 - acc: 0.3574 - val_loss: 5.1413 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00252: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 253/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.6652 - acc: 0.3568 - val_loss: 5.1397 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00253: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 254/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.6982 - acc: 0.3551 - val_loss: 5.1381 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00254: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 255/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.6488 - acc: 0.3581 - val_loss: 5.1365 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00255: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 256/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.6528 - acc: 0.3576 - val_loss: 5.1349 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00256: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 257/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.6563 - acc: 0.3575 - val_loss: 5.1334 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00257: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 258/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.6521 - acc: 0.3572 - val_loss: 5.1318 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00258: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 259/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.6504 - acc: 0.3583 - val_loss: 5.1302 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00259: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 260/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.6795 - acc: 0.3564 - val_loss: 5.1287 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00260: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 261/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 7.6728 - acc: 0.3558 - val_loss: 5.1272 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00261: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 262/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.6651 - acc: 0.3565 - val_loss: 5.1256 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00262: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 263/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.6970 - acc: 0.3559 - val_loss: 5.1241 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00263: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 264/500\n",
      "1600/1600 [==============================] - 276s 173ms/step - loss: 7.6800 - acc: 0.3556 - val_loss: 5.1226 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00264: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 265/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.6350 - acc: 0.3585 - val_loss: 5.1211 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00265: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 266/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.6766 - acc: 0.3543 - val_loss: 5.1196 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00266: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 267/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.6601 - acc: 0.3576 - val_loss: 5.1181 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00267: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 268/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.6331 - acc: 0.3568 - val_loss: 5.1166 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00268: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 269/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.6525 - acc: 0.3572 - val_loss: 5.1152 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00269: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 270/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 7.6503 - acc: 0.3581 - val_loss: 5.1137 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00270: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 271/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.6177 - acc: 0.3581 - val_loss: 5.1122 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00271: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 272/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.6394 - acc: 0.3576 - val_loss: 5.1108 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00272: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 273/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.6388 - acc: 0.3576 - val_loss: 5.1093 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00273: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 274/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.6349 - acc: 0.3567 - val_loss: 5.1079 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00274: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 275/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.6363 - acc: 0.3571 - val_loss: 5.1064 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00275: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 276/500\n",
      "1600/1600 [==============================] - 271s 170ms/step - loss: 7.6541 - acc: 0.3545 - val_loss: 5.1050 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00276: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 277/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.6651 - acc: 0.3561 - val_loss: 5.1036 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00277: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 278/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.6630 - acc: 0.3556 - val_loss: 5.1022 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00278: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 279/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.6336 - acc: 0.3574 - val_loss: 5.1008 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00279: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 280/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.6214 - acc: 0.3578 - val_loss: 5.0994 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00280: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 281/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.6508 - acc: 0.3575 - val_loss: 5.0980 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00281: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 282/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.6257 - acc: 0.3582 - val_loss: 5.0967 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00282: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 283/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.6112 - acc: 0.3578 - val_loss: 5.0953 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00283: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 284/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.6635 - acc: 0.3558 - val_loss: 5.0939 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00284: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 285/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6935 - acc: 0.3540 - val_loss: 5.0926 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00285: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 286/500\n",
      "1600/1600 [==============================] - 275s 172ms/step - loss: 7.6310 - acc: 0.3568 - val_loss: 5.0912 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00286: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 287/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.6406 - acc: 0.3559 - val_loss: 5.0899 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00287: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 288/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.6112 - acc: 0.3579 - val_loss: 5.0885 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00288: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 289/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.6275 - acc: 0.3570 - val_loss: 5.0872 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00289: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 290/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.6624 - acc: 0.3560 - val_loss: 5.0859 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00290: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 291/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.6505 - acc: 0.3555 - val_loss: 5.0846 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00291: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 292/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.6056 - acc: 0.3582 - val_loss: 5.0832 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00292: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 293/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.6323 - acc: 0.3565 - val_loss: 5.0819 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00293: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 294/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.6488 - acc: 0.3563 - val_loss: 5.0806 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00294: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 295/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6314 - acc: 0.3578 - val_loss: 5.0793 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00295: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 296/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6422 - acc: 0.3563 - val_loss: 5.0781 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00296: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 297/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.6453 - acc: 0.3564 - val_loss: 5.0768 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00297: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 298/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.6354 - acc: 0.3560 - val_loss: 5.0755 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00298: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 299/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.6143 - acc: 0.3574 - val_loss: 5.0743 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00299: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 300/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.6389 - acc: 0.3563 - val_loss: 5.0730 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00300: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 301/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6279 - acc: 0.3563 - val_loss: 5.0717 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00301: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 302/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5859 - acc: 0.3581 - val_loss: 5.0705 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00302: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 303/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.6348 - acc: 0.3558 - val_loss: 5.0692 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00303: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 304/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6384 - acc: 0.3545 - val_loss: 5.0680 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00304: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 305/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.6252 - acc: 0.3576 - val_loss: 5.0668 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00305: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 306/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.6459 - acc: 0.3558 - val_loss: 5.0655 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00306: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 307/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6307 - acc: 0.3557 - val_loss: 5.0643 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00307: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 308/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6517 - acc: 0.3560 - val_loss: 5.0631 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00308: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 309/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.6278 - acc: 0.3558 - val_loss: 5.0619 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00309: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 310/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6026 - acc: 0.3572 - val_loss: 5.0607 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00310: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 311/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5737 - acc: 0.3586 - val_loss: 5.0595 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00311: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 312/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.6267 - acc: 0.3563 - val_loss: 5.0583 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00312: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 313/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.6340 - acc: 0.3570 - val_loss: 5.0571 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00313: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 314/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6193 - acc: 0.3574 - val_loss: 5.0559 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00314: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 315/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6263 - acc: 0.3558 - val_loss: 5.0547 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00315: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5715 - acc: 0.3580 - val_loss: 5.0535 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00316: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 317/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.6286 - acc: 0.3548 - val_loss: 5.0524 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00317: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 318/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5747 - acc: 0.3585 - val_loss: 5.0512 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00318: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 319/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.6169 - acc: 0.3566 - val_loss: 5.0500 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00319: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 320/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6010 - acc: 0.3565 - val_loss: 5.0489 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00320: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 321/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6171 - acc: 0.3568 - val_loss: 5.0477 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00321: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 322/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5844 - acc: 0.3570 - val_loss: 5.0466 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00322: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 323/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.6157 - acc: 0.3557 - val_loss: 5.0454 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00323: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 324/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5762 - acc: 0.3577 - val_loss: 5.0443 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00324: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 325/500\n",
      "1600/1600 [==============================] - 286s 178ms/step - loss: 7.6192 - acc: 0.3559 - val_loss: 5.0432 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00325: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 326/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5674 - acc: 0.3570 - val_loss: 5.0421 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00326: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 327/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6232 - acc: 0.3552 - val_loss: 5.0409 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00327: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 328/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5831 - acc: 0.3576 - val_loss: 5.0398 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00328: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 329/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5966 - acc: 0.3566 - val_loss: 5.0387 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00329: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 330/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.6110 - acc: 0.3566 - val_loss: 5.0376 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00330: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 331/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5863 - acc: 0.3560 - val_loss: 5.0365 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00331: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 332/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6281 - acc: 0.3561 - val_loss: 5.0354 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00332: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 333/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5878 - acc: 0.3565 - val_loss: 5.0343 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00333: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 334/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.5980 - acc: 0.3554 - val_loss: 5.0332 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00334: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 335/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5880 - acc: 0.3574 - val_loss: 5.0321 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00335: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 336/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5847 - acc: 0.3573 - val_loss: 5.0310 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00336: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 337/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.6080 - acc: 0.3568 - val_loss: 5.0299 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00337: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 338/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5897 - acc: 0.3566 - val_loss: 5.0288 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00338: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 339/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5974 - acc: 0.3572 - val_loss: 5.0277 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00339: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 340/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.6021 - acc: 0.3570 - val_loss: 5.0266 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00340: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 341/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5676 - acc: 0.3574 - val_loss: 5.0256 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00341: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 342/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5588 - acc: 0.3570 - val_loss: 5.0245 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00342: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 343/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5777 - acc: 0.3560 - val_loss: 5.0234 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00343: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 344/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5805 - acc: 0.3575 - val_loss: 5.0224 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00344: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 345/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5859 - acc: 0.3558 - val_loss: 5.0213 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00345: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 346/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5792 - acc: 0.3578 - val_loss: 5.0203 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00346: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 347/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5808 - acc: 0.3567 - val_loss: 5.0192 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00347: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 348/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5784 - acc: 0.3564 - val_loss: 5.0182 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00348: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 349/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5922 - acc: 0.3558 - val_loss: 5.0171 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00349: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 350/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.5916 - acc: 0.3564 - val_loss: 5.0161 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00350: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 351/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5719 - acc: 0.3576 - val_loss: 5.0150 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00351: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 352/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5912 - acc: 0.3556 - val_loss: 5.0140 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00352: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 353/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5735 - acc: 0.3565 - val_loss: 5.0130 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00353: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 354/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5834 - acc: 0.3571 - val_loss: 5.0119 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00354: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 355/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5527 - acc: 0.3578 - val_loss: 5.0109 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00355: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 356/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5635 - acc: 0.3576 - val_loss: 5.0099 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00356: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 357/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5877 - acc: 0.3565 - val_loss: 5.0089 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00357: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 358/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5782 - acc: 0.3565 - val_loss: 5.0079 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00358: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 359/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5741 - acc: 0.3561 - val_loss: 5.0069 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00359: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 360/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5767 - acc: 0.3565 - val_loss: 5.0059 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00360: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 361/500\n",
      "1600/1600 [==============================] - 276s 172ms/step - loss: 7.5721 - acc: 0.3562 - val_loss: 5.0049 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00361: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 362/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5486 - acc: 0.3573 - val_loss: 5.0039 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00362: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 363/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5367 - acc: 0.3586 - val_loss: 5.0030 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00363: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 364/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5910 - acc: 0.3551 - val_loss: 5.0020 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00364: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 365/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5879 - acc: 0.3553 - val_loss: 5.0010 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00365: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 366/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5562 - acc: 0.3576 - val_loss: 5.0001 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00366: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 367/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5848 - acc: 0.3567 - val_loss: 4.9991 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00367: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 368/500\n",
      "1600/1600 [==============================] - 284s 177ms/step - loss: 7.5635 - acc: 0.3559 - val_loss: 4.9982 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00368: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 369/500\n",
      "1600/1600 [==============================] - 285s 178ms/step - loss: 7.5365 - acc: 0.3580 - val_loss: 4.9972 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00369: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 370/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5897 - acc: 0.3555 - val_loss: 4.9963 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00370: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 371/500\n",
      "1600/1600 [==============================] - 285s 178ms/step - loss: 7.5574 - acc: 0.3570 - val_loss: 4.9953 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00371: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 372/500\n",
      "1600/1600 [==============================] - 284s 178ms/step - loss: 7.5573 - acc: 0.3558 - val_loss: 4.9944 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00372: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 373/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5711 - acc: 0.3576 - val_loss: 4.9935 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00373: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 374/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5579 - acc: 0.3558 - val_loss: 4.9926 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00374: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 375/500\n",
      "1600/1600 [==============================] - 289s 181ms/step - loss: 7.5376 - acc: 0.3570 - val_loss: 4.9917 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00375: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 376/500\n",
      "1600/1600 [==============================] - 284s 178ms/step - loss: 7.5614 - acc: 0.3570 - val_loss: 4.9907 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00376: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 377/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5400 - acc: 0.3576 - val_loss: 4.9898 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00377: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 378/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5605 - acc: 0.3565 - val_loss: 4.9889 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00378: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 379/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5721 - acc: 0.3572 - val_loss: 4.9880 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00379: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 380/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5556 - acc: 0.3575 - val_loss: 4.9871 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00380: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 381/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5759 - acc: 0.3557 - val_loss: 4.9862 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00381: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 382/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5580 - acc: 0.3561 - val_loss: 4.9853 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00382: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 383/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5698 - acc: 0.3564 - val_loss: 4.9844 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00383: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 384/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5690 - acc: 0.3555 - val_loss: 4.9835 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00384: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 385/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5680 - acc: 0.3549 - val_loss: 4.9826 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00385: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 386/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5324 - acc: 0.3569 - val_loss: 4.9818 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00386: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 387/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5579 - acc: 0.3560 - val_loss: 4.9809 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00387: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 388/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5787 - acc: 0.3555 - val_loss: 4.9800 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00388: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 389/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.5750 - acc: 0.3553 - val_loss: 4.9791 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00389: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 390/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5689 - acc: 0.3553 - val_loss: 4.9783 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00390: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 391/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5797 - acc: 0.3544 - val_loss: 4.9774 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00391: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 392/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5265 - acc: 0.3585 - val_loss: 4.9765 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00392: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 393/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5439 - acc: 0.3557 - val_loss: 4.9757 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00393: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5484 - acc: 0.3560 - val_loss: 4.9748 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00394: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 395/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5614 - acc: 0.3558 - val_loss: 4.9740 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00395: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 396/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5351 - acc: 0.3567 - val_loss: 4.9731 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00396: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 397/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5524 - acc: 0.3572 - val_loss: 4.9723 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00397: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 398/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5881 - acc: 0.3547 - val_loss: 4.9715 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00398: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 399/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5395 - acc: 0.3575 - val_loss: 4.9706 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00399: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 400/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5402 - acc: 0.3570 - val_loss: 4.9698 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00400: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 401/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5261 - acc: 0.3567 - val_loss: 4.9690 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00401: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 402/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5615 - acc: 0.3565 - val_loss: 4.9681 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00402: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 403/500\n",
      "1600/1600 [==============================] - 279s 175ms/step - loss: 7.5692 - acc: 0.3550 - val_loss: 4.9673 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00403: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 404/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5758 - acc: 0.3549 - val_loss: 4.9665 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00404: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 405/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5401 - acc: 0.3571 - val_loss: 4.9657 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00405: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 406/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5444 - acc: 0.3562 - val_loss: 4.9649 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00406: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 407/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5331 - acc: 0.3570 - val_loss: 4.9641 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00407: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 408/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.5003 - acc: 0.3581 - val_loss: 4.9633 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00408: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 409/500\n",
      "1600/1600 [==============================] - 277s 173ms/step - loss: 7.5486 - acc: 0.3568 - val_loss: 4.9624 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00409: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 410/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.5132 - acc: 0.3577 - val_loss: 4.9617 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00410: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 411/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5335 - acc: 0.3582 - val_loss: 4.9609 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00411: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 412/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.5122 - acc: 0.3577 - val_loss: 4.9600 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00412: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 413/500\n",
      "1600/1600 [==============================] - 274s 172ms/step - loss: 7.5002 - acc: 0.3593 - val_loss: 4.9593 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00413: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 414/500\n",
      "1600/1600 [==============================] - 266s 167ms/step - loss: 7.5021 - acc: 0.3586 - val_loss: 4.9585 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00414: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 415/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.5462 - acc: 0.3544 - val_loss: 4.9577 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00415: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 416/500\n",
      "1600/1600 [==============================] - 265s 165ms/step - loss: 7.5278 - acc: 0.3583 - val_loss: 4.9569 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00416: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 417/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.5273 - acc: 0.3586 - val_loss: 4.9561 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00417: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 418/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5346 - acc: 0.3559 - val_loss: 4.9553 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00418: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 419/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5430 - acc: 0.3563 - val_loss: 4.9545 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00419: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 420/500\n",
      "1600/1600 [==============================] - 286s 179ms/step - loss: 7.5525 - acc: 0.3570 - val_loss: 4.9538 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00420: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 421/500\n",
      "1600/1600 [==============================] - 284s 178ms/step - loss: 7.5207 - acc: 0.3569 - val_loss: 4.9530 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00421: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 422/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5070 - acc: 0.3583 - val_loss: 4.9522 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00422: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 423/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5364 - acc: 0.3550 - val_loss: 4.9515 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00423: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 424/500\n",
      "1600/1600 [==============================] - 291s 182ms/step - loss: 7.5167 - acc: 0.3570 - val_loss: 4.9507 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00424: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 425/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5750 - acc: 0.3540 - val_loss: 4.9500 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00425: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 426/500\n",
      "1600/1600 [==============================] - 282s 176ms/step - loss: 7.5304 - acc: 0.3563 - val_loss: 4.9492 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00426: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 427/500\n",
      "1600/1600 [==============================] - 281s 175ms/step - loss: 7.5296 - acc: 0.3572 - val_loss: 4.9485 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00427: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 428/500\n",
      "1600/1600 [==============================] - 281s 176ms/step - loss: 7.5164 - acc: 0.3578 - val_loss: 4.9477 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00428: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 429/500\n",
      "1600/1600 [==============================] - 279s 174ms/step - loss: 7.5358 - acc: 0.3563 - val_loss: 4.9470 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00429: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 430/500\n",
      "1600/1600 [==============================] - 280s 175ms/step - loss: 7.5056 - acc: 0.3585 - val_loss: 4.9462 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00430: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 431/500\n",
      "1600/1600 [==============================] - 283s 177ms/step - loss: 7.5217 - acc: 0.3582 - val_loss: 4.9455 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00431: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 432/500\n",
      "1600/1600 [==============================] - 278s 174ms/step - loss: 7.5385 - acc: 0.3555 - val_loss: 4.9447 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00432: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 433/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.4963 - acc: 0.3582 - val_loss: 4.9440 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00433: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 434/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.5130 - acc: 0.3580 - val_loss: 4.9433 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00434: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 435/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5381 - acc: 0.3557 - val_loss: 4.9425 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00435: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 436/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.5216 - acc: 0.3562 - val_loss: 4.9418 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00436: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 437/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.5313 - acc: 0.3566 - val_loss: 4.9411 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00437: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 438/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.5273 - acc: 0.3567 - val_loss: 4.9404 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00438: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 439/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.5120 - acc: 0.3584 - val_loss: 4.9397 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00439: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 440/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.5230 - acc: 0.3566 - val_loss: 4.9389 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00440: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 441/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.5077 - acc: 0.3581 - val_loss: 4.9382 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00441: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 442/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5340 - acc: 0.3560 - val_loss: 4.9375 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00442: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 443/500\n",
      "1600/1600 [==============================] - 273s 171ms/step - loss: 7.5228 - acc: 0.3572 - val_loss: 4.9368 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00443: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 444/500\n",
      "1600/1600 [==============================] - 271s 170ms/step - loss: 7.5410 - acc: 0.3561 - val_loss: 4.9361 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00444: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 445/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.5303 - acc: 0.3572 - val_loss: 4.9354 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00445: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 446/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5243 - acc: 0.3563 - val_loss: 4.9347 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00446: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 447/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.5087 - acc: 0.3561 - val_loss: 4.9340 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00447: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 448/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5611 - acc: 0.3551 - val_loss: 4.9333 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00448: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 449/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5658 - acc: 0.3533 - val_loss: 4.9326 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00449: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 450/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.5260 - acc: 0.3565 - val_loss: 4.9319 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00450: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 451/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.4865 - acc: 0.3584 - val_loss: 4.9313 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00451: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 452/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.4936 - acc: 0.3583 - val_loss: 4.9306 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00452: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 453/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.4999 - acc: 0.3563 - val_loss: 4.9299 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00453: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 454/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.4939 - acc: 0.3575 - val_loss: 4.9292 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00454: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 455/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5313 - acc: 0.3553 - val_loss: 4.9285 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00455: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 456/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.5406 - acc: 0.3557 - val_loss: 4.9278 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00456: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 457/500\n",
      "1600/1600 [==============================] - 268s 168ms/step - loss: 7.5139 - acc: 0.3565 - val_loss: 4.9272 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00457: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 458/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.5358 - acc: 0.3560 - val_loss: 4.9265 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00458: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 459/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.5561 - acc: 0.3556 - val_loss: 4.9258 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00459: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 460/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5175 - acc: 0.3580 - val_loss: 4.9252 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00460: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 461/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.5589 - acc: 0.3536 - val_loss: 4.9245 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00461: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 462/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.5161 - acc: 0.3568 - val_loss: 4.9238 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00462: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 463/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.4800 - acc: 0.3576 - val_loss: 4.9232 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00463: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 464/500\n",
      "1600/1600 [==============================] - 272s 170ms/step - loss: 7.5238 - acc: 0.3557 - val_loss: 4.9225 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00464: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 465/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5087 - acc: 0.3560 - val_loss: 4.9219 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00465: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 466/500\n",
      "1600/1600 [==============================] - 270s 169ms/step - loss: 7.5261 - acc: 0.3551 - val_loss: 4.9212 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00466: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 467/500\n",
      "1600/1600 [==============================] - 274s 171ms/step - loss: 7.5474 - acc: 0.3552 - val_loss: 4.9205 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00467: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 468/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.5282 - acc: 0.3560 - val_loss: 4.9199 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00468: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 469/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.5015 - acc: 0.3567 - val_loss: 4.9193 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00469: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 470/500\n",
      "1600/1600 [==============================] - 271s 169ms/step - loss: 7.5087 - acc: 0.3573 - val_loss: 4.9186 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00470: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 471/500\n",
      "1600/1600 [==============================] - 267s 167ms/step - loss: 7.5359 - acc: 0.3549 - val_loss: 4.9180 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00471: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.5007 - acc: 0.3562 - val_loss: 4.9173 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00472: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 473/500\n",
      "1600/1600 [==============================] - 262s 164ms/step - loss: 7.5097 - acc: 0.3554 - val_loss: 4.9167 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00473: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 474/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.4813 - acc: 0.3583 - val_loss: 4.9161 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00474: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 475/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.5187 - acc: 0.3554 - val_loss: 4.9154 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00475: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 476/500\n",
      "1600/1600 [==============================] - 262s 163ms/step - loss: 7.4918 - acc: 0.3568 - val_loss: 4.9148 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00476: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 477/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.5134 - acc: 0.3558 - val_loss: 4.9142 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00477: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 478/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.5349 - acc: 0.3541 - val_loss: 4.9136 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00478: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 479/500\n",
      "1600/1600 [==============================] - 263s 165ms/step - loss: 7.5161 - acc: 0.3561 - val_loss: 4.9129 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00479: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 480/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.4746 - acc: 0.3587 - val_loss: 4.9123 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00480: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 481/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.5196 - acc: 0.3549 - val_loss: 4.9117 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00481: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 482/500\n",
      "1600/1600 [==============================] - 265s 166ms/step - loss: 7.4811 - acc: 0.3574 - val_loss: 4.9111 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00482: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 483/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.5036 - acc: 0.3560 - val_loss: 4.9105 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00483: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 484/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5363 - acc: 0.3555 - val_loss: 4.9099 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00484: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 485/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5265 - acc: 0.3558 - val_loss: 4.9092 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00485: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 486/500\n",
      "1600/1600 [==============================] - 259s 162ms/step - loss: 7.5072 - acc: 0.3559 - val_loss: 4.9086 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00486: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 487/500\n",
      "1600/1600 [==============================] - 264s 165ms/step - loss: 7.4906 - acc: 0.3559 - val_loss: 4.9080 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00487: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 488/500\n",
      "1600/1600 [==============================] - 263s 165ms/step - loss: 7.4973 - acc: 0.3575 - val_loss: 4.9074 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00488: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 489/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5130 - acc: 0.3562 - val_loss: 4.9068 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00489: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 490/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.4892 - acc: 0.3582 - val_loss: 4.9062 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00490: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 491/500\n",
      "1600/1600 [==============================] - 268s 167ms/step - loss: 7.5238 - acc: 0.3567 - val_loss: 4.9056 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00491: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 492/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5052 - acc: 0.3561 - val_loss: 4.9050 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00492: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 493/500\n",
      "1600/1600 [==============================] - 269s 168ms/step - loss: 7.5049 - acc: 0.3558 - val_loss: 4.9044 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00493: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 494/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5114 - acc: 0.3553 - val_loss: 4.9038 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00494: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 495/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5491 - acc: 0.3548 - val_loss: 4.9032 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00495: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 496/500\n",
      "1600/1600 [==============================] - 263s 165ms/step - loss: 7.4944 - acc: 0.3574 - val_loss: 4.9027 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00496: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 497/500\n",
      "1600/1600 [==============================] - 260s 163ms/step - loss: 7.4887 - acc: 0.3572 - val_loss: 4.9021 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00497: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 498/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.4946 - acc: 0.3568 - val_loss: 4.9015 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00498: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 499/500\n",
      "1600/1600 [==============================] - 266s 166ms/step - loss: 7.5371 - acc: 0.3558 - val_loss: 4.9009 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00499: saving model to AbstractiveTextSummarization2.2.hdf5\n",
      "Epoch 500/500\n",
      "1600/1600 [==============================] - 261s 163ms/step - loss: 7.4672 - acc: 0.3569 - val_loss: 4.9003 - val_acc: 0.4591\n",
      "\n",
      "Epoch 00500: saving model to AbstractiveTextSummarization2.2.hdf5\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=[TrainingDataIX,decoderInputSummary], \n",
    "          y=decoderTargetSummary,\n",
    "          batch_size=64,\n",
    "          epochs=500,\n",
    "          validation_split=0.2,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhjjc5YIjDHG5ywRGGOMz1kiMMYYn/t/jXKds/RDUwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7599fc9bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoderModelInference=Model(inputs=encoderInputLayer,outputs=encoderStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DecoderInputStateH=Input(shape=(256,))\n",
    "DecoderInputStateC = Input(shape=(256,))\n",
    "DecoderInputStates = [DecoderInputStateH, DecoderInputStateC]\n",
    "decoderOutput,decoderHState,decoderCState = decoderLSTMLayer(decoderInputLayer,initial_state=DecoderInputStates)\n",
    "decoderStates=[decoderHState,decoderCState]\n",
    "decoderInferenceFinalOutput = decoderDenseLayer(decoderOutput)\n",
    "decoderModelInf = Model(inputs=[decoderInputLayer] + DecoderInputStates,\n",
    "                          outputs=[decoderInferenceFinalOutput] + decoderStates )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6021"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modiefiedSummaryWord_index['SOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_vocab_summaries = {}\n",
    "for word, value in modiefiedSummaryWord_index.items():\n",
    "    int_to_vocab_summaries[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSummary(inputReview):\n",
    "    # Initial states value is coming from the encoder \n",
    "    #We get the encoder states into encoderStatesVar variable\n",
    "    encoderStatesVar = encoderModelInference.predict(inputReview)#return encoder states\n",
    "    targetSummary = np.zeros((1,1,ModifiedVocabSize))\n",
    "    print('targetSummary shape:->',targetSummary.shape)\n",
    "    targetSummary[0, 0, modiefiedSummaryWord_index['SOS']] = 1\n",
    "    print(targetSummary.shape)\n",
    "    #targetSummary=embeddingModifiedSummaries[modiefiedSummaryWord_index['SOS']]\n",
    "    summarized_sent = ''\n",
    "    stop = False\n",
    "    i=1\n",
    "    while not stop:\n",
    "        decoderOutput,decoderHState,decoderCState = decoderModelInf.predict(x=[targetSummary] + encoderStatesVar)\n",
    "        #print(decoder_out)\n",
    "        maxValIndex = np.argmax(decoderOutput[0,-1,:])\n",
    "        sampledSummaryWord = int_to_vocab_summaries[maxValIndex]\n",
    "        #print('sampledSummaryWord is:->',sampledSummaryWord)\n",
    "        #print()\n",
    "        summarized_sent += sampledSummaryWord+\" \"\n",
    "        #print('summarized_sent is:->',summarized_sent)\n",
    "        #print()\n",
    "        if ((sampledSummaryWord == 'EOS') or (len(summarized_sent) >= maxSummaryLength)) :\n",
    "            print('terminated')\n",
    "            stop = True\n",
    "        \n",
    "        targetSummary = np.zeros((1,1,ModifiedVocabSize))\n",
    "        targetSummary[0, 0, maxValIndex]=1\n",
    "        \n",
    "        encoderStatesVar  = [decoderHState,decoderCState]\n",
    "        i=i+1\n",
    "        \n",
    "    return summarized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the sleek kate kate and do but it is still \n",
      "Human Summary  tragic and haunting a beautifully heartwrenching portrait of child abandonment PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though it is not much this comic and offers \n",
      "Human Summary  it might be thinly written and messily made but gainsbourg a heroic life is also appropriately glamorous and intense and powerfully led by a gripping performance from erik elmosnino PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a raw entertaining family drama with ultimately \n",
      "Human Summary  faithful to its literary source this is imaginative intelligent family entertainment PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of the cinema \n",
      "Human Summary  campy charm and a knowing sense of humor help to overcome a silly plot involving a spacefaring exfootball player his adoring bevy of groupies and a supervillain named ming the merciless PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  visually creative but also aimless repetitve and devoid of character development PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though you has a good cast and the marshalls \n",
      "Human Summary  sharp performances by patrick dempsey and michelle monaghan cannot save this forgettable formulaic chick flick from its comic failings PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the last impossible is an appealing but \n",
      "Human Summary  while fans of the hasbro toy franchise may revel in a bit of nostalgia gi joe the rise of cobra is largely a cartoonish overthetop action fest propelled by silly writing inconsistent visual effects and merely passable performances PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  moody yet touching mommas man successfully illustrates with elegant simplicity the struggles of a man consumed with his adolescence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though assayas shyamalan bloody part of \n",
      "Human Summary  bolstered by a trio of powerful performances from its talented leads clouds of sils maria is an absorbing richly detailed drama with impressive depth and intelligence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though campy tale is a cheesy but what in \n",
      "Human Summary  by turns funny sad and profound killer of sheep offers a sympathetic and humane glimpse into innercity life PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a gleefully entertaining backstage comedy bullets over broadway features some of woody allens sharpest most inspired lateperiod writing and direction PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous as a very meditation \n",
      "Human Summary  startupcom is more than just a look at the rise and fall of the new economy at its center is a friendship being tested to the limit and that is what makes it worth viewing PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: with its pace is an casting action but it \n",
      "Human Summary  well researched and finely crafted standard operating procedure is another gem from master documentarian errol morris PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite its strong and moving assembled \n",
      "Human Summary  a witty commentary on modern filmmaking with enough jokes to keep it entertaining throughout PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  wardance is beautifully filmed and effectively captures the heartbreaking and uplifting experiences of its subjects PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite some of earlier musical petits plays \n",
      "Human Summary  venerable action star chow yunfat is the only saving grace in this silly action flick that more often than not resembles a commercial in style PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a lowkey but charming tale that will put a smile on your face PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: sandra bullock and visually documentary \n",
      "Human Summary  all the atmospherics in dark water cannot make up for the lack of genuine scares PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a witty and the movie that suffers is a \n",
      "Human Summary  a calm charismatic performance from robert de niro nearly saves the movie but ultimately everybodys fine has the look and feel of a stereotypical christmas dramedy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though mona film film made long long are \n",
      "Human Summary  director wong karwai has created in 2046 another visually stunning atmospheric and melancholy movie about unrequited love and loneliness PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and lithely in this in this financial \n",
      "Human Summary  laden with melodramatic clichs leaving needed a talented star to succeed and kristin scott thomas delivers the goods with another superb performance PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though made is not formulaic but this is \n",
      "Human Summary  the killer inside me is stylish and beautifully shot but michael winterbottoms distance from his characters robs this often brutally violent film of crucial emotional context PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous in this farmiga \n",
      "Human Summary  deeply esoteric and unapologetically onesided the art of the steal proves a documentary does not have to make an objective argument as long as it argues well PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: although on a gripping performance from \n",
      "Human Summary  the final film by the great robert altman a prairie home companion the big screen adaptation of garrison keillors radio broadcast showcases plenty of the directors strengths it is got a gigantic cast and plenty of quirky acting and dialogue \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a manic overstuffed blend of scifi comedy and romance innerspace nonetheless charms thanks to martin shorts fine performance and the insistent zaniness of the plot PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  overblown in the best sense of the word francis ford coppolas vision of bram stokers dracula rescues the character from decades of campy interpretations and features some terrific performances to boot PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous in this farmiga \n",
      "Human Summary  magic trip is overall unenlightening though there is an inherent novelty and joy in seeing the unearthed footage of ken kesey and his band of merry pranksters PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and fails to this the movie that \n",
      "Human Summary  francis ford coppolas haunting hallucinatory vietnam war epic is cinema at its most audacious and visionary PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the ending is an few action but is another \n",
      "Human Summary  for better and for worse joe carnahans bigscreen version of the ateam captures the superficial noisy spirit of the tv series PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the wind may not the first is the movie \n",
      "Human Summary  gore without scares and cardboard cutout characters make this clash of the monsters a dull sit PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: at its cast and jeff bridges sky plays just \n",
      "Human Summary  the franchise is showing its age but scream 4 is undeniably an improvement over its predecessor with just enough meta humor and clever kills PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though fractures is a uneven but this alejandro \n",
      "Human Summary  gleefully uncomfortable force majeure is a relationship drama that is hard to watch and just as difficult to ignore PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  an insightful if fawning documentary that explores a group of 90s nyc artists PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the film is a appealing of its own crazy \n",
      "Human Summary  as starstudded as it is heartbreakingly lazy little fockers takes the topgrossing trilogy to embarrassing new lows PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike film that covers \n",
      "Human Summary  with a summers tale eric rohmer continues his tales of the four seasons in typically rohmeresque fashion and for cineastes that is excellent news indeed PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not uneven but what from alejandro \n",
      "Human Summary  a grossout comedy that is more sophomoric than funny the benchwarmers goes down swinging PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: sandra is an engrossing pleasant vision \n",
      "Human Summary  smarter fresher and funnier than a modern vampire movie has any right to be what we do in the shadows is bloody good fun PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a strong performances performance of emotional \n",
      "Human Summary  sometimes inventive and witty this animated adventure into an antsized world is a pleasant diversion PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  though it features some of the most memorable and electrifying aereial footage shot with an expert eye for action top gun offers too little for nonadolescent viewers to chew on when its characters are not in the air PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a exciting is a lavish and overly series \n",
      "Human Summary  a gutwrenching and riveting docudrama that serves as a stinging indictment of us military justice in an era of everincreasing scrutiny PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of ang lees speechifying \n",
      "Human Summary  derivative and full of pop culture injokes PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not quite as funny and the movie but \n",
      "Human Summary  executed with little panache or invention dragonball evolution lacks the magic that made the books upon which it was based a cult sensation PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of ang lees speechifying \n",
      "Human Summary  thanks largely to stellar allaround performances from a talented cast the madness of king george is a funny entertaining and immensely likable adaptation of the eponymous stage production PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not of its original but it is the \n",
      "Human Summary  raw terrifying and painfully difficult to watch the act of killing offers a haunting testament to the edifying confrontational power of documentary cinema PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though it may may some of this alice themes \n",
      "Human Summary  a manipulative tearjerker life as a house benefits from fine performances from the cast PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though of a good cast with a innocence drama \n",
      "Human Summary  a creepy thriller that poses more questions than it answers PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite the plot of the year of steve cumberbatch \n",
      "Human Summary  competent but somewhat static tristan isolde does not achieve the sweeping romanticism that it aims for PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: clever and and is stylish with its musical \n",
      "Human Summary  the dances in rize are electric even if the documentary does not go that deeply into the performers lives PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a raw tale tale a a as as a little explores \n",
      "Human Summary  with little chemistry among the performers humorless gags and a predictable storyline fools gold fails on every level PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: as last narrative provides a midwestern \n",
      "Human Summary  atmospheric and thrilling enemy at the gates gets the look and feel of war right however the love story seems out of place PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n"
     ]
    }
   ],
   "source": [
    "human_summary=[]\n",
    "for i in range(50):    \n",
    "    #print('System Generated Summary:',summary)\n",
    "    temp=[]\n",
    "    for j in range(len(testPaddedSummary[i])):\n",
    "        temp.append(int_to_vocab_summaries[testPaddedSummary[i][j]])\n",
    "    human_summary.append(temp)    \n",
    "humanSummary=\" \"        \n",
    "for i in range(50):\n",
    "    data=testPaddedReviews[i].reshape(1,400)\n",
    "    summary=generateSummary(data)\n",
    "    print('System Generated Summary:',summary)\n",
    "    for j in range(len(human_summary[i])):\n",
    "        humanSummary+=human_summary[i][j]+\" \"\n",
    "    print('Human Summary',humanSummary)\n",
    "    humanSummary=\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though it is not much this comic and offers \n",
      "Human Summary  it might be thinly written and messily made but gainsbourg a heroic life is also appropriately glamorous and intense and powerfully led by a gripping performance from erik elmosnino PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.26548932464\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a raw entertaining family drama with ultimately \n",
      "Human Summary  faithful to its literary source this is imaginative intelligent family entertainment PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.263262095056\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of the cinema \n",
      "Human Summary  campy charm and a knowing sense of humor help to overcome a silly plot involving a spacefaring exfootball player his adoring bevy of groupies and a supervillain named ming the merciless PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.291893462965\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  visually creative but also aimless repetitve and devoid of character development PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.284267621807\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though you has a good cast and the marshalls \n",
      "Human Summary  sharp performances by patrick dempsey and michelle monaghan cannot save this forgettable formulaic chick flick from its comic failings PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.269679944985\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the last impossible is an appealing but \n",
      "Human Summary  while fans of the hasbro toy franchise may revel in a bit of nostalgia gi joe the rise of cobra is largely a cartoonish overthetop action fest propelled by silly writing inconsistent visual effects and merely passable performances PAD PAD \n",
      "BlEU SCORE IS:-> 0.25\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  moody yet touching mommas man successfully illustrates with elegant simplicity the struggles of a man consumed with his adolescence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.279894647725\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though assayas shyamalan bloody part of \n",
      "Human Summary  bolstered by a trio of powerful performances from its talented leads clouds of sils maria is an absorbing richly detailed drama with impressive depth and intelligence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.27548658251\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though campy tale is a cheesy but what in \n",
      "Human Summary  by turns funny sad and profound killer of sheep offers a sympathetic and humane glimpse into innercity life PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.293759112614\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a gleefully entertaining backstage comedy bullets over broadway features some of woody allens sharpest most inspired lateperiod writing and direction PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.27914526312\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous as a very meditation \n",
      "Human Summary  startupcom is more than just a look at the rise and fall of the new economy at its center is a friendship being tested to the limit and that is what makes it worth viewing PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.313760411548\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: with its pace is an casting action but it \n",
      "Human Summary  well researched and finely crafted standard operating procedure is another gem from master documentarian errol morris PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.255178915802\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite its strong and moving assembled \n",
      "Human Summary  a witty commentary on modern filmmaking with enough jokes to keep it entertaining throughout PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.265908011739\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  wardance is beautifully filmed and effectively captures the heartbreaking and uplifting experiences of its subjects PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.295901341137\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite some of earlier musical petits plays \n",
      "Human Summary  venerable action star chow yunfat is the only saving grace in this silly action flick that more often than not resembles a commercial in style PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.261968415998\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a lowkey but charming tale that will put a smile on your face PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.315301767642\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: sandra bullock and visually documentary \n",
      "Human Summary  all the atmospherics in dark water cannot make up for the lack of genuine scares PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.287084625882\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a witty and the movie that suffers is a \n",
      "Human Summary  a calm charismatic performance from robert de niro nearly saves the movie but ultimately everybodys fine has the look and feel of a stereotypical christmas dramedy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.269069117599\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though mona film film made long long are \n",
      "Human Summary  director wong karwai has created in 2046 another visually stunning atmospheric and melancholy movie about unrequited love and loneliness PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.251123601167\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and lithely in this in this financial \n",
      "Human Summary  laden with melodramatic clichs leaving needed a talented star to succeed and kristin scott thomas delivers the goods with another superb performance PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.276724730692\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though made is not formulaic but this is \n",
      "Human Summary  the killer inside me is stylish and beautifully shot but michael winterbottoms distance from his characters robs this often brutally violent film of crucial emotional context PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.270695146002\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous in this farmiga \n",
      "Human Summary  deeply esoteric and unapologetically onesided the art of the steal proves a documentary does not have to make an objective argument as long as it argues well PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.300078978546\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated\n",
      "System Generated Summary: although on a gripping performance from \n",
      "Human Summary  the final film by the great robert altman a prairie home companion the big screen adaptation of garrison keillors radio broadcast showcases plenty of the directors strengths it is got a gigantic cast and plenty of quirky acting and dialogue \n",
      "BlEU SCORE IS:-> 0.257129738613\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  a manic overstuffed blend of scifi comedy and romance innerspace nonetheless charms thanks to martin shorts fine performance and the insistent zaniness of the plot PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.274873708375\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  overblown in the best sense of the word francis ford coppolas vision of bram stokers dracula rescues the character from decades of campy interpretations and features some terrific performances to boot PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.275009549108\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and meticulous in this farmiga \n",
      "Human Summary  magic trip is overall unenlightening though there is an inherent novelty and joy in seeing the unearthed footage of ken kesey and his band of merry pranksters PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.291385758707\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful and fails to this the movie that \n",
      "Human Summary  francis ford coppolas haunting hallucinatory vietnam war epic is cinema at its most audacious and visionary PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.296318878995\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the ending is an few action but is another \n",
      "Human Summary  for better and for worse joe carnahans bigscreen version of the ateam captures the superficial noisy spirit of the tv series PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.290100699485\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the wind may not the first is the movie \n",
      "Human Summary  gore without scares and cardboard cutout characters make this clash of the monsters a dull sit PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.270030862434\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: at its cast and jeff bridges sky plays just \n",
      "Human Summary  the franchise is showing its age but scream 4 is undeniably an improvement over its predecessor with just enough meta humor and clever kills PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.303698879993\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though fractures is a uneven but this alejandro \n",
      "Human Summary  gleefully uncomfortable force majeure is a relationship drama that is hard to watch and just as difficult to ignore PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.299252800832\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  an insightful if fawning documentary that explores a group of 90s nyc artists PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.310252613997\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: the film is a appealing of its own crazy \n",
      "Human Summary  as starstudded as it is heartbreakingly lazy little fockers takes the topgrossing trilogy to embarrassing new lows PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.302235262413\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike film that covers \n",
      "Human Summary  with a summers tale eric rohmer continues his tales of the four seasons in typically rohmeresque fashion and for cineastes that is excellent news indeed PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.297968197513\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not uneven but what from alejandro \n",
      "Human Summary  a grossout comedy that is more sophomoric than funny the benchwarmers goes down swinging PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.287183263447\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: sandra is an engrossing pleasant vision \n",
      "Human Summary  smarter fresher and funnier than a modern vampire movie has any right to be what we do in the shadows is bloody good fun PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.274351630584\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a strong performances performance of emotional \n",
      "Human Summary  sometimes inventive and witty this animated adventure into an antsized world is a pleasant diversion PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.243733339111\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike examination of \n",
      "Human Summary  though it features some of the most memorable and electrifying aereial footage shot with an expert eye for action top gun offers too little for nonadolescent viewers to chew on when its characters are not in the air PAD PAD \n",
      "BlEU SCORE IS:-> 0.282842712475\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a exciting is a lavish and overly series \n",
      "Human Summary  a gutwrenching and riveting docudrama that serves as a stinging indictment of us military justice in an era of everincreasing scrutiny PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.274721127897\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of ang lees speechifying \n",
      "Human Summary  derivative and full of pop culture injokes PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.301511344578\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not quite as funny and the movie but \n",
      "Human Summary  executed with little panache or invention dragonball evolution lacks the magic that made the books upon which it was based a cult sensation PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.258815853326\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a powerful documentarylike of ang lees speechifying \n",
      "Human Summary  thanks largely to stellar allaround performances from a talented cast the madness of king george is a funny entertaining and immensely likable adaptation of the eponymous stage production PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.290496446887\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: it is not of its original but it is the \n",
      "Human Summary  raw terrifying and painfully difficult to watch the act of killing offers a haunting testament to the edifying confrontational power of documentary cinema PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.25\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: though it may may some of this alice themes \n",
      "Human Summary  a manipulative tearjerker life as a house benefits from fine performances from the cast PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.259533259821\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated\n",
      "System Generated Summary: though of a good cast with a innocence drama \n",
      "Human Summary  a creepy thriller that poses more questions than it answers PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.278115203285\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: despite the plot of the year of steve cumberbatch \n",
      "Human Summary  competent but somewhat static tristan isolde does not achieve the sweeping romanticism that it aims for PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.299252800832\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: clever and and is stylish with its musical \n",
      "Human Summary  the dances in rize are electric even if the documentary does not go that deeply into the performers lives PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.289429842117\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: a raw tale tale a a as as a little explores \n",
      "Human Summary  with little chemistry among the performers humorless gags and a predictable storyline fools gold fails on every level PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.230521358269\n",
      "targetSummary shape:-> (1, 1, 6023)\n",
      "(1, 1, 6023)\n",
      "terminated\n",
      "System Generated Summary: as last narrative provides a midwestern \n",
      "Human Summary  atmospheric and thrilling enemy at the gates gets the look and feel of war right however the love story seems out of place PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0.279508497187\n",
      "AVERAGE BLEU SCORE:-> 0.279264219377\n"
     ]
    }
   ],
   "source": [
    "humanSummary=\" \"  \n",
    "scores=[]\n",
    "for i in range(1,50):\n",
    "    data=testPaddedReviews[i].reshape(1,400)\n",
    "    summary=generateSummary(data)\n",
    "    print('System Generated Summary:',summary)\n",
    "    for j in range(len(human_summary[i])):\n",
    "        humanSummary+=human_summary[i][j]+\" \"\n",
    "    print('Human Summary',humanSummary)\n",
    "    #calculation of bleu score\n",
    "    score=sentence_bleu(summary,humanSummary,weights=(0.5, 0.5, 0, 0))\n",
    "    print('BlEU SCORE IS:->',score)\n",
    "    scores.append(score)      \n",
    "    humanSummary=\" \"\n",
    "\n",
    "total=0\n",
    "for i in scores:\n",
    "    total+=i\n",
    "print('AVERAGE BLEU SCORE:->',total/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
