{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function,division\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply,LeakyReLU\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam,sgd\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import gensim\n",
    "from nmt_utils import *\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from gensim.models import KeyedVectors\n",
    "import cPickle as pickle\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=6411116544, percent=22.2, used=1414701056, free=5703749632, active=1588920320, inactive=723636224, buffers=95129600, cached=1026719744, shared=154492928)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN1='embeddingReviewsFilewithOtherdata'\n",
    "FN2='myPaddedDataFile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s.pkl'%FN2,'rb') as fp:\n",
    "    embeddingReviews, modiefiedSummaryWord_index,myPaddedData= pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=6399401984, percent=22.3, used=1421742080, free=5644189696, active=1596702720, inactive=774131712, buffers=119242752, cached=1055125504, shared=158695424)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddedReviews=myPaddedData['paddedReviews']\n",
    "paddedSummary=myPaddedData['paddedSummary']\n",
    "paddedModifiedSummary=myPaddedData['paddedModifiedSummary']\n",
    "testPaddedReviews=myPaddedData['testPaddedReviews']\n",
    "testPaddedSummary=myPaddedData['testPaddedSummary']\n",
    "#testEncoded_modiefiedSummaries=myData['testEncoded_modiefiedSummaries']\n",
    "#valPaddedReviews=myPaddedData['valPaddedReviews']\n",
    "#valPaddedSummary=myPaddedData['valPaddedSummary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((950, 200), (950, 40), (950, 40))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingDataIX=paddedReviews\n",
    "TrainingDataTY=paddedSummary\n",
    "TrainingDataIY=paddedModifiedSummary\n",
    "TrainingDataIX.shape,TrainingDataIY.shape,TrainingDataTY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDataIX=testPaddedReviews\n",
    "TestDataTY=testPaddedSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ValDataIX=valPaddedReviews\n",
    "#ValDataTY=valPaddedSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=6394519552, percent=22.4, used=1426477056, free=5638500352, active=1601617920, inactive=774909952, buffers=119345152, cached=1055977472, shared=158695424)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples=len(TrainingDataIX)\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModifiedVocabSize=len(modiefiedSummaryWord_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModifiedVocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=6396149760, percent=22.4, used=1425022976, free=5639954432, active=1600008192, inactive=775438336, buffers=119443456, cached=1055879168, shared=158695424)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderInputSummary=to_categorical(paddedModifiedSummary,num_classes=ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderInputSummary=decoderInputSummary.reshape(nb_samples,-1,ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 40, 5425)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderInputSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=4770807808, percent=42.1, used=3050909696, free=4014518272, active=3221848064, inactive=775122944, buffers=119549952, cached=1055322112, shared=158695424)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN2='CtegoricalSummaryData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderTargetSummary=to_categorical(paddedSummary,num_classes=ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 5425)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderTargetSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderTargetSummary=decoderTargetSummary.reshape(nb_samples,-1,ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 40, 5425)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderTargetSummary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8240300032, available=3168755712, percent=61.5, used=4652371968, free=2411954176, active=4822372352, inactive=775057408, buffers=120410112, cached=1055563776, shared=158646272)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valOneHotSummary=to_categorical(valPaddedSummary,num_classes=ModifiedVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s.pkl'%'embeddingReviewsFile', 'rb') as fp:\n",
    "    embeddingReviews = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReviewsVocabSize=27789\n",
    "maxReviewLength=200\n",
    "maxSummaryLength=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input shape is:-> (?, 200)\n"
     ]
    }
   ],
   "source": [
    "#Encoder\n",
    "Encoder_embedding_layer = Embedding(ReviewsVocabSize,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddingReviews],\n",
    "                            input_length=maxReviewLength,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True)\n",
    "encoder_input=Input(shape=(maxReviewLength,))\n",
    "print('encoder_input shape is:->',encoder_input.shape)\n",
    "embedded_Encoder_inputSequence=Encoder_embedding_layer(encoder_input)\n",
    "encoder_LSTM=LSTM(128,return_state=True,bias_regularizer=regularizers.l2(0.05),recurrent_regularizer=regularizers.l2(0.05))\n",
    "#print(type(encoder_LSTM))\n",
    "encoder_output,encoder_h,encoder_c=encoder_LSTM(embedded_Encoder_inputSequence)\n",
    "#print('encoder_output shape:->',encoder_output.shape)\n",
    "encoder_states=[encoder_h,encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input=Input(shape=(None,ModifiedVocabSize))\n",
    "#embedded_Decoder_inputSequence=Decoder_embedding_layer(decoder_input)\n",
    "decoder_LSTM=LSTM(128,return_sequences=True, return_state = True,dropout=0.5,recurrent_dropout=0.5,bias_regularizer=regularizers.l2(0.05),recurrent_regularizer=regularizers.l2(0.05))\n",
    "decoder_output,decoder_h,decoder_c=decoder_LSTM(decoder_input,initial_state=encoder_states)\n",
    "#decoder_dense_rel=Dense(ModifiedVocabSize,activation='relu',kernel_regularizer=regularizers.l2(0.04),activity_regularizer=regularizers.l1(0.04))\n",
    "#decoder_dense=Dense(ModifiedVocabSize,activation='softmax',kernel_regularizer=regularizers.l2(0.04),activity_regularizer=regularizers.l1(0.04))\n",
    "#decoder_out=decoder_dense_rel(decoder_output)\n",
    "#final_decoder_out=decoder_dense(decoder_out)\n",
    "\n",
    "decoder_dense=Dense(ModifiedVocabSize,activation='softmax',kernel_regularizer=regularizers.l2(0.05),activity_regularizer=regularizers.l2(0.1))\n",
    "final_decoder_out=decoder_dense(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model=Model(inputs=[encoder_input,decoder_input],output=final_decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,decay=0.009)\n",
    "#opt=sgd(lr=0.001, momentum=0.2, decay=0.1, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "#filepath=\"summWithoutAttention.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "checkpointer = ModelCheckpoint(filepath='SummarizationWithoutAttentionV3.2.7Weights.hdf5', verbose=1, save_best_only=False,mode='auto',period=1)\n",
    "\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 200, 100)      2778900     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, None, 5425)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 128), (None,  117248      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    [(None, None, 128), ( 2843648     input_2[0][0]                    \n",
      "                                                                   lstm_1[0][1]                     \n",
      "                                                                   lstm_1[0][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, None, 5425)    699825      lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 6,439,621\n",
      "Trainable params: 6,439,621\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1752a1e5a8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 190 samples\n",
      "Epoch 1/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 18.0518 - acc: 0.4630Epoch 00000: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 18.0420 - acc: 0.4632 - val_loss: 14.3878 - val_acc: 0.4993\n",
      "Epoch 2/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 13.9081 - acc: 0.4656Epoch 00001: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 13.9086 - acc: 0.4653 - val_loss: 13.0943 - val_acc: 0.4993\n",
      "Epoch 3/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 12.9415 - acc: 0.4652Epoch 00002: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 12.9400 - acc: 0.4653 - val_loss: 12.3567 - val_acc: 0.4993\n",
      "Epoch 4/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 12.3205 - acc: 0.4656Epoch 00003: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 12.3220 - acc: 0.4653 - val_loss: 11.8433 - val_acc: 0.4993\n",
      "Epoch 5/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 11.8636 - acc: 0.4656Epoch 00004: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 11.8654 - acc: 0.4653 - val_loss: 11.4547 - val_acc: 0.4993\n",
      "Epoch 6/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 11.5181 - acc: 0.4650Epoch 00005: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 209s - loss: 11.5162 - acc: 0.4653 - val_loss: 11.1361 - val_acc: 0.4993\n",
      "Epoch 7/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 11.2228 - acc: 0.4652Epoch 00006: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 11.2222 - acc: 0.4653 - val_loss: 10.8775 - val_acc: 0.4993\n",
      "Epoch 8/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.9727 - acc: 0.4655Epoch 00007: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 10.9740 - acc: 0.4653 - val_loss: 10.6533 - val_acc: 0.4993\n",
      "Epoch 9/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.7715 - acc: 0.4648Epoch 00008: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 10.7683 - acc: 0.4653 - val_loss: 10.4530 - val_acc: 0.4993\n",
      "Epoch 10/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.5843 - acc: 0.4651Epoch 00009: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 10.5829 - acc: 0.4653 - val_loss: 10.2792 - val_acc: 0.4993\n",
      "Epoch 11/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.4226 - acc: 0.4649Epoch 00010: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 10.4207 - acc: 0.4653 - val_loss: 10.1248 - val_acc: 0.4993\n",
      "Epoch 12/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.2699 - acc: 0.4649Epoch 00011: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 10.2674 - acc: 0.4653 - val_loss: 9.9833 - val_acc: 0.4993\n",
      "Epoch 13/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.1402 - acc: 0.4649Epoch 00012: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 10.1380 - acc: 0.4653 - val_loss: 9.8582 - val_acc: 0.4993\n",
      "Epoch 14/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 10.0079 - acc: 0.4649Epoch 00013: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 10.0060 - acc: 0.4653 - val_loss: 9.7371 - val_acc: 0.4993\n",
      "Epoch 15/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.8933 - acc: 0.4654Epoch 00014: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 9.8939 - acc: 0.4653 - val_loss: 9.6327 - val_acc: 0.4993\n",
      "Epoch 16/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.7942 - acc: 0.4650Epoch 00015: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 9.7924 - acc: 0.4653 - val_loss: 9.5306 - val_acc: 0.4993\n",
      "Epoch 17/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.6963 - acc: 0.4650Epoch 00016: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 9.6947 - acc: 0.4653 - val_loss: 9.4375 - val_acc: 0.4993\n",
      "Epoch 18/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.6037 - acc: 0.4659Epoch 00017: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 9.6069 - acc: 0.4653 - val_loss: 9.3498 - val_acc: 0.4993\n",
      "Epoch 19/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.5157 - acc: 0.4649Epoch 00018: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 9.5138 - acc: 0.4653 - val_loss: 9.2660 - val_acc: 0.4993\n",
      "Epoch 20/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.4370 - acc: 0.4654Epoch 00019: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 9.4374 - acc: 0.4653 - val_loss: 9.1902 - val_acc: 0.4993\n",
      "Epoch 21/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.3560 - acc: 0.4655Epoch 00020: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 9.3571 - acc: 0.4653 - val_loss: 9.1133 - val_acc: 0.4993\n",
      "Epoch 22/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.2889 - acc: 0.4652Epoch 00021: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 9.2887 - acc: 0.4653 - val_loss: 9.0472 - val_acc: 0.4993\n",
      "Epoch 23/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.2185 - acc: 0.4655Epoch 00022: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 9.2192 - acc: 0.4653 - val_loss: 8.9832 - val_acc: 0.4993\n",
      "Epoch 24/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.1586 - acc: 0.4649Epoch 00023: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 9.1564 - acc: 0.4653 - val_loss: 8.9216 - val_acc: 0.4993\n",
      "Epoch 25/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.0983 - acc: 0.4651Epoch 00024: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 9.0979 - acc: 0.4653 - val_loss: 8.8604 - val_acc: 0.4993\n",
      "Epoch 26/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 9.0358 - acc: 0.4648Epoch 00025: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 9.0333 - acc: 0.4653 - val_loss: 8.8033 - val_acc: 0.4993\n",
      "Epoch 27/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.9838 - acc: 0.4651Epoch 00026: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 8.9833 - acc: 0.4653 - val_loss: 8.7513 - val_acc: 0.4993\n",
      "Epoch 28/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.9263 - acc: 0.4654Epoch 00027: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 8.9264 - acc: 0.4653 - val_loss: 8.6977 - val_acc: 0.4993\n",
      "Epoch 29/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.8742 - acc: 0.4656Epoch 00028: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 185s - loss: 8.8760 - acc: 0.4653 - val_loss: 8.6492 - val_acc: 0.4993\n",
      "Epoch 30/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.8314 - acc: 0.4650Epoch 00029: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 8.8293 - acc: 0.4653 - val_loss: 8.6026 - val_acc: 0.4993\n",
      "Epoch 31/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.7765 - acc: 0.4653Epoch 00030: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 8.7759 - acc: 0.4653 - val_loss: 8.5539 - val_acc: 0.4993\n",
      "Epoch 32/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.7358 - acc: 0.4652Epoch 00031: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 8.7353 - acc: 0.4653 - val_loss: 8.5128 - val_acc: 0.4993\n",
      "Epoch 33/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.6941 - acc: 0.4655Epoch 00032: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 8.6954 - acc: 0.4653 - val_loss: 8.4707 - val_acc: 0.4993\n",
      "Epoch 34/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.6529 - acc: 0.4650Epoch 00033: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 8.6515 - acc: 0.4653 - val_loss: 8.4288 - val_acc: 0.4993\n",
      "Epoch 35/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.6116 - acc: 0.4656Epoch 00034: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 8.6138 - acc: 0.4653 - val_loss: 8.3901 - val_acc: 0.4993\n",
      "Epoch 36/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.5710 - acc: 0.4651Epoch 00035: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 8.5706 - acc: 0.4653 - val_loss: 8.3498 - val_acc: 0.4993\n",
      "Epoch 37/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.5398 - acc: 0.4651Epoch 00036: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 8.5387 - acc: 0.4653 - val_loss: 8.3168 - val_acc: 0.4993\n",
      "Epoch 38/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.4970 - acc: 0.4654Epoch 00037: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 8.4979 - acc: 0.4653 - val_loss: 8.2790 - val_acc: 0.4993\n",
      "Epoch 39/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.4598 - acc: 0.4655Epoch 00038: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 8.4610 - acc: 0.4653 - val_loss: 8.2431 - val_acc: 0.4993\n",
      "Epoch 40/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.4222 - acc: 0.4658Epoch 00039: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 8.4252 - acc: 0.4653 - val_loss: 8.2099 - val_acc: 0.4993\n",
      "Epoch 41/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.3949 - acc: 0.4651Epoch 00040: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 8.3940 - acc: 0.4653 - val_loss: 8.1781 - val_acc: 0.4993\n",
      "Epoch 42/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.3685 - acc: 0.4648Epoch 00041: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 8.3658 - acc: 0.4653 - val_loss: 8.1480 - val_acc: 0.4993\n",
      "Epoch 43/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.3267 - acc: 0.4657Epoch 00042: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 8.3291 - acc: 0.4653 - val_loss: 8.1158 - val_acc: 0.4993\n",
      "Epoch 44/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.2977 - acc: 0.4653Epoch 00043: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 8.2988 - acc: 0.4653 - val_loss: 8.0849 - val_acc: 0.4993\n",
      "Epoch 45/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.2715 - acc: 0.4653Epoch 00044: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 8.2716 - acc: 0.4653 - val_loss: 8.0566 - val_acc: 0.4993\n",
      "Epoch 46/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.2388 - acc: 0.4651Epoch 00045: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 8.2379 - acc: 0.4653 - val_loss: 8.0284 - val_acc: 0.4993\n",
      "Epoch 47/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.2137 - acc: 0.4650Epoch 00046: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 8.2124 - acc: 0.4653 - val_loss: 8.0017 - val_acc: 0.4993\n",
      "Epoch 48/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.1910 - acc: 0.4648Epoch 00047: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 8.1890 - acc: 0.4653 - val_loss: 7.9755 - val_acc: 0.4993\n",
      "Epoch 49/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.1612 - acc: 0.4650Epoch 00048: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 8.1593 - acc: 0.4653 - val_loss: 7.9483 - val_acc: 0.4993\n",
      "Epoch 50/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.1360 - acc: 0.4653Epoch 00049: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 8.1363 - acc: 0.4653 - val_loss: 7.9229 - val_acc: 0.4993\n",
      "Epoch 51/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.1096 - acc: 0.4652Epoch 00050: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 8.1093 - acc: 0.4653 - val_loss: 7.8986 - val_acc: 0.4993\n",
      "Epoch 52/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.0850 - acc: 0.4651Epoch 00051: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 8.0845 - acc: 0.4653 - val_loss: 7.8753 - val_acc: 0.4993\n",
      "Epoch 53/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.0569 - acc: 0.4649Epoch 00052: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 8.0554 - acc: 0.4653 - val_loss: 7.8513 - val_acc: 0.4993\n",
      "Epoch 54/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.0381 - acc: 0.4653Epoch 00053: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 8.0384 - acc: 0.4653 - val_loss: 7.8281 - val_acc: 0.4993\n",
      "Epoch 55/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 8.0069 - acc: 0.4658Epoch 00054: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 8.0105 - acc: 0.4653 - val_loss: 7.8049 - val_acc: 0.4993\n",
      "Epoch 56/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.9864 - acc: 0.4653Epoch 00055: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 7.9869 - acc: 0.4653 - val_loss: 7.7822 - val_acc: 0.4993\n",
      "Epoch 57/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.9725 - acc: 0.4650Epoch 00056: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 7.9713 - acc: 0.4653 - val_loss: 7.7620 - val_acc: 0.4993\n",
      "Epoch 58/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.9469 - acc: 0.4648Epoch 00057: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 175s - loss: 7.9445 - acc: 0.4653 - val_loss: 7.7378 - val_acc: 0.4993\n",
      "Epoch 59/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.9255 - acc: 0.4655Epoch 00058: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 7.9269 - acc: 0.4653 - val_loss: 7.7175 - val_acc: 0.4993\n",
      "Epoch 60/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.9012 - acc: 0.4658Epoch 00059: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 7.9041 - acc: 0.4653 - val_loss: 7.6982 - val_acc: 0.4993\n",
      "Epoch 61/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.8797 - acc: 0.4649Epoch 00060: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 7.8777 - acc: 0.4653 - val_loss: 7.6771 - val_acc: 0.4993\n",
      "Epoch 62/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.8601 - acc: 0.4652Epoch 00061: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 7.8597 - acc: 0.4653 - val_loss: 7.6585 - val_acc: 0.4993\n",
      "Epoch 63/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.8389 - acc: 0.4656Epoch 00062: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 7.8409 - acc: 0.4653 - val_loss: 7.6392 - val_acc: 0.4993\n",
      "Epoch 64/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.8239 - acc: 0.4655Epoch 00063: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 7.8254 - acc: 0.4653 - val_loss: 7.6214 - val_acc: 0.4993\n",
      "Epoch 65/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.8022 - acc: 0.4649Epoch 00064: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 7.8003 - acc: 0.4653 - val_loss: 7.6017 - val_acc: 0.4993\n",
      "Epoch 66/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7847 - acc: 0.4658Epoch 00065: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 7.7879 - acc: 0.4653 - val_loss: 7.5843 - val_acc: 0.4993\n",
      "Epoch 67/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7680 - acc: 0.4654Epoch 00066: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 7.7685 - acc: 0.4653 - val_loss: 7.5671 - val_acc: 0.4993\n",
      "Epoch 68/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7531 - acc: 0.4658Epoch 00067: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 7.7567 - acc: 0.4653 - val_loss: 7.5503 - val_acc: 0.4993\n",
      "Epoch 69/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7395 - acc: 0.4650Epoch 00068: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.7380 - acc: 0.4653 - val_loss: 7.5336 - val_acc: 0.4993\n",
      "Epoch 70/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7218 - acc: 0.4651Epoch 00069: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 7.7213 - acc: 0.4653 - val_loss: 7.5178 - val_acc: 0.4993\n",
      "Epoch 71/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.7046 - acc: 0.4650Epoch 00070: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 7.7032 - acc: 0.4653 - val_loss: 7.5008 - val_acc: 0.4993\n",
      "Epoch 72/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.6822 - acc: 0.4654Epoch 00071: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 7.6834 - acc: 0.4653 - val_loss: 7.4846 - val_acc: 0.4993\n",
      "Epoch 73/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.6707 - acc: 0.4650Epoch 00072: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 264s - loss: 7.6694 - acc: 0.4653 - val_loss: 7.4686 - val_acc: 0.4993\n",
      "Epoch 74/2000\n",
      "  6/760 [..............................] - ETA: 7086s - loss: 7.3538 - acc: 0.5125 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.839480). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 7.6583 - acc: 0.4652Epoch 00073: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 235s - loss: 7.6571 - acc: 0.4653 - val_loss: 7.4534 - val_acc: 0.4993\n",
      "Epoch 75/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.6352 - acc: 0.4651Epoch 00074: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 7.6341 - acc: 0.4653 - val_loss: 7.4373 - val_acc: 0.4993\n",
      "Epoch 76/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.6227 - acc: 0.4651Epoch 00075: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 7.6216 - acc: 0.4653 - val_loss: 7.4221 - val_acc: 0.4993\n",
      "Epoch 77/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.6046 - acc: 0.4651Epoch 00076: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 7.6033 - acc: 0.4653 - val_loss: 7.4060 - val_acc: 0.4993\n",
      "Epoch 78/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5965 - acc: 0.4650Epoch 00077: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 7.5950 - acc: 0.4653 - val_loss: 7.3930 - val_acc: 0.4993\n",
      "Epoch 79/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5765 - acc: 0.4653Epoch 00078: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.5767 - acc: 0.4653 - val_loss: 7.3785 - val_acc: 0.4993\n",
      "Epoch 80/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5623 - acc: 0.4653Epoch 00079: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 7.5621 - acc: 0.4653 - val_loss: 7.3644 - val_acc: 0.4993\n",
      "Epoch 81/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5475 - acc: 0.4652Epoch 00080: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 7.5468 - acc: 0.4653 - val_loss: 7.3501 - val_acc: 0.4993\n",
      "Epoch 82/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5361 - acc: 0.4653Epoch 00081: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 7.5359 - acc: 0.4653 - val_loss: 7.3361 - val_acc: 0.4993\n",
      "Epoch 83/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5234 - acc: 0.4656Epoch 00082: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 7.5253 - acc: 0.4653 - val_loss: 7.3241 - val_acc: 0.4993\n",
      "Epoch 84/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.5069 - acc: 0.4656Epoch 00083: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 7.5089 - acc: 0.4653 - val_loss: 7.3108 - val_acc: 0.4993\n",
      "Epoch 85/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4881 - acc: 0.4653Epoch 00084: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.4880 - acc: 0.4653 - val_loss: 7.2959 - val_acc: 0.4993\n",
      "Epoch 86/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4825 - acc: 0.4651Epoch 00085: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 7.4811 - acc: 0.4653 - val_loss: 7.2834 - val_acc: 0.4993\n",
      "Epoch 87/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4729 - acc: 0.4650Epoch 00086: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.4719 - acc: 0.4653 - val_loss: 7.2732 - val_acc: 0.4993\n",
      "Epoch 88/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4478 - acc: 0.4661Epoch 00087: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 7.4524 - acc: 0.4653 - val_loss: 7.2591 - val_acc: 0.4993\n",
      "Epoch 89/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4499 - acc: 0.4651Epoch 00088: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 7.4495 - acc: 0.4653 - val_loss: 7.2476 - val_acc: 0.4993\n",
      "Epoch 90/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4327 - acc: 0.4649Epoch 00089: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.4303 - acc: 0.4653 - val_loss: 7.2345 - val_acc: 0.4993\n",
      "Epoch 91/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4206 - acc: 0.4655Epoch 00090: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 7.4212 - acc: 0.4653 - val_loss: 7.2228 - val_acc: 0.4993\n",
      "Epoch 92/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.4155 - acc: 0.4651Epoch 00091: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.4138 - acc: 0.4653 - val_loss: 7.2126 - val_acc: 0.4993\n",
      "Epoch 93/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3934 - acc: 0.4651Epoch 00092: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 7.3916 - acc: 0.4653 - val_loss: 7.1989 - val_acc: 0.4993\n",
      "Epoch 94/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3839 - acc: 0.4659Epoch 00093: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 7.3875 - acc: 0.4653 - val_loss: 7.1887 - val_acc: 0.4993\n",
      "Epoch 95/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3735 - acc: 0.4653Epoch 00094: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 7.3733 - acc: 0.4653 - val_loss: 7.1772 - val_acc: 0.4993\n",
      "Epoch 96/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3600 - acc: 0.4655Epoch 00095: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.3611 - acc: 0.4653 - val_loss: 7.1659 - val_acc: 0.4993\n",
      "Epoch 97/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3482 - acc: 0.4653Epoch 00096: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 7.3490 - acc: 0.4653 - val_loss: 7.1541 - val_acc: 0.4993\n",
      "Epoch 98/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3380 - acc: 0.4646Epoch 00097: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 7.3344 - acc: 0.4653 - val_loss: 7.1420 - val_acc: 0.4993\n",
      "Epoch 99/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3236 - acc: 0.4658Epoch 00098: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 7.3276 - acc: 0.4653 - val_loss: 7.1316 - val_acc: 0.4993\n",
      "Epoch 100/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3184 - acc: 0.4650Epoch 00099: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 7.3171 - acc: 0.4653 - val_loss: 7.1210 - val_acc: 0.4993\n",
      "Epoch 101/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.3099 - acc: 0.4651Epoch 00100: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 7.3089 - acc: 0.4653 - val_loss: 7.1109 - val_acc: 0.4993\n",
      "Epoch 102/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2980 - acc: 0.4652Epoch 00101: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.2975 - acc: 0.4653 - val_loss: 7.1009 - val_acc: 0.4993\n",
      "Epoch 103/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2878 - acc: 0.4650Epoch 00102: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 7.2867 - acc: 0.4653 - val_loss: 7.0907 - val_acc: 0.4993\n",
      "Epoch 104/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2754 - acc: 0.4655Epoch 00103: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 7.2764 - acc: 0.4653 - val_loss: 7.0810 - val_acc: 0.4993\n",
      "Epoch 105/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2625 - acc: 0.4661Epoch 00104: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 7.2665 - acc: 0.4653 - val_loss: 7.0714 - val_acc: 0.4993\n",
      "Epoch 106/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2494 - acc: 0.4659Epoch 00105: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 7.2530 - acc: 0.4653 - val_loss: 7.0607 - val_acc: 0.4993\n",
      "Epoch 107/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2580 - acc: 0.4654Epoch 00106: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 7.2590 - acc: 0.4653 - val_loss: 7.0532 - val_acc: 0.4993\n",
      "Epoch 108/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2401 - acc: 0.4652Epoch 00107: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.2396 - acc: 0.4653 - val_loss: 7.0431 - val_acc: 0.4993\n",
      "Epoch 109/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2236 - acc: 0.4655Epoch 00108: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 7.2250 - acc: 0.4653 - val_loss: 7.0337 - val_acc: 0.4993\n",
      "Epoch 110/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2242 - acc: 0.4652Epoch 00109: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 7.2241 - acc: 0.4653 - val_loss: 7.0249 - val_acc: 0.4993\n",
      "Epoch 111/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2085 - acc: 0.4648Epoch 00110: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 7.2060 - acc: 0.4653 - val_loss: 7.0149 - val_acc: 0.4993\n",
      "Epoch 112/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.2033 - acc: 0.4650Epoch 00111: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 7.2018 - acc: 0.4653 - val_loss: 7.0051 - val_acc: 0.4993\n",
      "Epoch 113/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1906 - acc: 0.4653Epoch 00112: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.1909 - acc: 0.4653 - val_loss: 6.9970 - val_acc: 0.4993\n",
      "Epoch 114/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1736 - acc: 0.4656Epoch 00113: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 7.1754 - acc: 0.4653 - val_loss: 6.9870 - val_acc: 0.4993\n",
      "Epoch 115/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1712 - acc: 0.4648Epoch 00114: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 7.1684 - acc: 0.4653 - val_loss: 6.9775 - val_acc: 0.4993\n",
      "Epoch 116/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1623 - acc: 0.4654Epoch 00115: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 7.1632 - acc: 0.4653 - val_loss: 6.9691 - val_acc: 0.4993\n",
      "Epoch 117/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1625 - acc: 0.4655Epoch 00116: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 207s - loss: 7.1634 - acc: 0.4653 - val_loss: 6.9620 - val_acc: 0.4993\n",
      "Epoch 118/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1490 - acc: 0.4653Epoch 00117: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 213s - loss: 7.1493 - acc: 0.4653 - val_loss: 6.9535 - val_acc: 0.4993\n",
      "Epoch 119/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1312 - acc: 0.4658Epoch 00118: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 7.1342 - acc: 0.4653 - val_loss: 6.9441 - val_acc: 0.4993\n",
      "Epoch 120/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1261 - acc: 0.4655Epoch 00119: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.1274 - acc: 0.4653 - val_loss: 6.9366 - val_acc: 0.4993\n",
      "Epoch 121/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1232 - acc: 0.4650Epoch 00120: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 7.1216 - acc: 0.4653 - val_loss: 6.9282 - val_acc: 0.4993\n",
      "Epoch 122/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1131 - acc: 0.4655Epoch 00121: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 7.1144 - acc: 0.4653 - val_loss: 6.9204 - val_acc: 0.4993\n",
      "Epoch 123/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.1048 - acc: 0.4649Epoch 00122: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 7.1026 - acc: 0.4653 - val_loss: 6.9116 - val_acc: 0.4993\n",
      "Epoch 124/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0919 - acc: 0.4655Epoch 00123: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 7.0931 - acc: 0.4653 - val_loss: 6.9031 - val_acc: 0.4993\n",
      "Epoch 125/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0904 - acc: 0.4656Epoch 00124: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 7.0925 - acc: 0.4653 - val_loss: 6.8959 - val_acc: 0.4993\n",
      "Epoch 126/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0792 - acc: 0.4646Epoch 00125: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 7.0758 - acc: 0.4653 - val_loss: 6.8872 - val_acc: 0.4993\n",
      "Epoch 127/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0706 - acc: 0.4658Epoch 00126: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 7.0731 - acc: 0.4653 - val_loss: 6.8795 - val_acc: 0.4993\n",
      "Epoch 128/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0631 - acc: 0.4657Epoch 00127: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 7.0648 - acc: 0.4653 - val_loss: 6.8722 - val_acc: 0.4993\n",
      "Epoch 129/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0516 - acc: 0.4655Epoch 00128: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 7.0524 - acc: 0.4653 - val_loss: 6.8642 - val_acc: 0.4993\n",
      "Epoch 130/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0527 - acc: 0.4652Epoch 00129: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 7.0524 - acc: 0.4653 - val_loss: 6.8572 - val_acc: 0.4993\n",
      "Epoch 131/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0396 - acc: 0.4649Epoch 00130: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 192s - loss: 7.0373 - acc: 0.4653 - val_loss: 6.8499 - val_acc: 0.4993\n",
      "Epoch 132/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0344 - acc: 0.4658Epoch 00131: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 7.0373 - acc: 0.4653 - val_loss: 6.8433 - val_acc: 0.4993\n",
      "Epoch 133/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0189 - acc: 0.4655Epoch 00132: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 7.0204 - acc: 0.4653 - val_loss: 6.8348 - val_acc: 0.4993\n",
      "Epoch 134/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0188 - acc: 0.4651Epoch 00133: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 7.0177 - acc: 0.4653 - val_loss: 6.8278 - val_acc: 0.4993\n",
      "Epoch 135/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0170 - acc: 0.4651Epoch 00134: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 7.0162 - acc: 0.4653 - val_loss: 6.8217 - val_acc: 0.4993\n",
      "Epoch 136/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 7.0041 - acc: 0.4652Epoch 00135: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 7.0036 - acc: 0.4653 - val_loss: 6.8133 - val_acc: 0.4993\n",
      "Epoch 137/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9960 - acc: 0.4654Epoch 00136: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 6.9967 - acc: 0.4653 - val_loss: 6.8055 - val_acc: 0.4993\n",
      "Epoch 138/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9834 - acc: 0.4655Epoch 00137: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.9846 - acc: 0.4653 - val_loss: 6.7984 - val_acc: 0.4993\n",
      "Epoch 139/2000\n",
      "758/760 [============================>.] - ETA: 5s - loss: 6.9887 - acc: 0.4655 Epoch 00138: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 2064s - loss: 6.9902 - acc: 0.4653 - val_loss: 6.7931 - val_acc: 0.4993\n",
      "Epoch 140/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9736 - acc: 0.4655Epoch 00139: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.9750 - acc: 0.4653 - val_loss: 6.7862 - val_acc: 0.4993\n",
      "Epoch 141/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9763 - acc: 0.4652Epoch 00140: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.9765 - acc: 0.4653 - val_loss: 6.7803 - val_acc: 0.4993\n",
      "Epoch 142/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9625 - acc: 0.4652Epoch 00141: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.9616 - acc: 0.4653 - val_loss: 6.7734 - val_acc: 0.4993\n",
      "Epoch 143/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9555 - acc: 0.4653Epoch 00142: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 209s - loss: 6.9560 - acc: 0.4653 - val_loss: 6.7663 - val_acc: 0.4993\n",
      "Epoch 144/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9579 - acc: 0.4651Epoch 00143: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.9569 - acc: 0.4653 - val_loss: 6.7604 - val_acc: 0.4993\n",
      "Epoch 145/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9427 - acc: 0.4650Epoch 00144: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 6.9411 - acc: 0.4653 - val_loss: 6.7532 - val_acc: 0.4993\n",
      "Epoch 146/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9345 - acc: 0.4651Epoch 00145: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 6.9341 - acc: 0.4653 - val_loss: 6.7461 - val_acc: 0.4993\n",
      "Epoch 147/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9313 - acc: 0.4655Epoch 00146: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.9324 - acc: 0.4653 - val_loss: 6.7397 - val_acc: 0.4993\n",
      "Epoch 148/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9231 - acc: 0.4656Epoch 00147: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.9252 - acc: 0.4653 - val_loss: 6.7340 - val_acc: 0.4993\n",
      "Epoch 149/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9154 - acc: 0.4653Epoch 00148: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.9156 - acc: 0.4653 - val_loss: 6.7280 - val_acc: 0.4993\n",
      "Epoch 150/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9134 - acc: 0.4649Epoch 00149: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.9114 - acc: 0.4653 - val_loss: 6.7223 - val_acc: 0.4993\n",
      "Epoch 151/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.9085 - acc: 0.4653Epoch 00150: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.9080 - acc: 0.4653 - val_loss: 6.7173 - val_acc: 0.4993\n",
      "Epoch 152/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8961 - acc: 0.4654Epoch 00151: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 6.8976 - acc: 0.4653 - val_loss: 6.7100 - val_acc: 0.4993\n",
      "Epoch 153/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8888 - acc: 0.4652Epoch 00152: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.8885 - acc: 0.4653 - val_loss: 6.7030 - val_acc: 0.4993\n",
      "Epoch 154/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8874 - acc: 0.4652Epoch 00153: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.8873 - acc: 0.4653 - val_loss: 6.6972 - val_acc: 0.4993\n",
      "Epoch 155/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8771 - acc: 0.4652Epoch 00154: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.8770 - acc: 0.4653 - val_loss: 6.6911 - val_acc: 0.4993\n",
      "Epoch 156/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8761 - acc: 0.4656Epoch 00155: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.8775 - acc: 0.4653 - val_loss: 6.6853 - val_acc: 0.4993\n",
      "Epoch 157/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8665 - acc: 0.4647Epoch 00156: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.8634 - acc: 0.4653 - val_loss: 6.6786 - val_acc: 0.4993\n",
      "Epoch 158/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8677 - acc: 0.4652Epoch 00157: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.8673 - acc: 0.4653 - val_loss: 6.6742 - val_acc: 0.4993\n",
      "Epoch 159/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8493 - acc: 0.4653Epoch 00158: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.8499 - acc: 0.4653 - val_loss: 6.6675 - val_acc: 0.4993\n",
      "Epoch 160/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8435 - acc: 0.4652Epoch 00159: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 182s - loss: 6.8427 - acc: 0.4653 - val_loss: 6.6612 - val_acc: 0.4993\n",
      "Epoch 161/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8441 - acc: 0.4659Epoch 00160: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.8472 - acc: 0.4653 - val_loss: 6.6558 - val_acc: 0.4993\n",
      "Epoch 162/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8344 - acc: 0.4658Epoch 00161: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.8370 - acc: 0.4653 - val_loss: 6.6501 - val_acc: 0.4993\n",
      "Epoch 163/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8312 - acc: 0.4651Epoch 00162: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.8301 - acc: 0.4653 - val_loss: 6.6444 - val_acc: 0.4993\n",
      "Epoch 164/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8264 - acc: 0.4655Epoch 00163: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.8286 - acc: 0.4653 - val_loss: 6.6394 - val_acc: 0.4993\n",
      "Epoch 165/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8305 - acc: 0.4651Epoch 00164: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.8295 - acc: 0.4653 - val_loss: 6.6355 - val_acc: 0.4993\n",
      "Epoch 166/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8087 - acc: 0.4661Epoch 00165: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.8137 - acc: 0.4653 - val_loss: 6.6290 - val_acc: 0.4993\n",
      "Epoch 167/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8106 - acc: 0.4655Epoch 00166: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.8118 - acc: 0.4653 - val_loss: 6.6236 - val_acc: 0.4993\n",
      "Epoch 168/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8031 - acc: 0.4654Epoch 00167: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.8042 - acc: 0.4653 - val_loss: 6.6182 - val_acc: 0.4993\n",
      "Epoch 169/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.8038 - acc: 0.4648Epoch 00168: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.8013 - acc: 0.4653 - val_loss: 6.6126 - val_acc: 0.4993\n",
      "Epoch 170/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7931 - acc: 0.4651Epoch 00169: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.7926 - acc: 0.4653 - val_loss: 6.6071 - val_acc: 0.4993\n",
      "Epoch 171/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7916 - acc: 0.4653Epoch 00170: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.7920 - acc: 0.4653 - val_loss: 6.6022 - val_acc: 0.4993\n",
      "Epoch 172/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7913 - acc: 0.4649Epoch 00171: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.7890 - acc: 0.4653 - val_loss: 6.5971 - val_acc: 0.4993\n",
      "Epoch 173/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7788 - acc: 0.4655Epoch 00172: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.7799 - acc: 0.4653 - val_loss: 6.5921 - val_acc: 0.4993\n",
      "Epoch 174/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7812 - acc: 0.4649Epoch 00173: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 6.7790 - acc: 0.4653 - val_loss: 6.5870 - val_acc: 0.4993\n",
      "Epoch 175/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7719 - acc: 0.4654Epoch 00174: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.7726 - acc: 0.4653 - val_loss: 6.5824 - val_acc: 0.4993\n",
      "Epoch 176/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7670 - acc: 0.4651Epoch 00175: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.7663 - acc: 0.4653 - val_loss: 6.5770 - val_acc: 0.4993\n",
      "Epoch 177/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7548 - acc: 0.4651Epoch 00176: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.7538 - acc: 0.4653 - val_loss: 6.5719 - val_acc: 0.4993\n",
      "Epoch 178/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7637 - acc: 0.4647Epoch 00177: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.7606 - acc: 0.4653 - val_loss: 6.5679 - val_acc: 0.4993\n",
      "Epoch 179/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7498 - acc: 0.4656Epoch 00178: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.7516 - acc: 0.4653 - val_loss: 6.5630 - val_acc: 0.4993\n",
      "Epoch 180/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7391 - acc: 0.4654Epoch 00179: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.7399 - acc: 0.4653 - val_loss: 6.5577 - val_acc: 0.4993\n",
      "Epoch 181/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7388 - acc: 0.4656Epoch 00180: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.7413 - acc: 0.4653 - val_loss: 6.5534 - val_acc: 0.4993\n",
      "Epoch 182/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7401 - acc: 0.4650Epoch 00181: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 6.7386 - acc: 0.4653 - val_loss: 6.5489 - val_acc: 0.4993\n",
      "Epoch 183/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7389 - acc: 0.4646Epoch 00182: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 6.7354 - acc: 0.4653 - val_loss: 6.5449 - val_acc: 0.4993\n",
      "Epoch 184/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7250 - acc: 0.4651Epoch 00183: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 6.7241 - acc: 0.4653 - val_loss: 6.5393 - val_acc: 0.4993\n",
      "Epoch 185/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7257 - acc: 0.4655Epoch 00184: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.7273 - acc: 0.4653 - val_loss: 6.5349 - val_acc: 0.4993\n",
      "Epoch 186/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7156 - acc: 0.4654Epoch 00185: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 6.7163 - acc: 0.4653 - val_loss: 6.5296 - val_acc: 0.4993\n",
      "Epoch 187/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7120 - acc: 0.4648Epoch 00186: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 6.7093 - acc: 0.4653 - val_loss: 6.5247 - val_acc: 0.4993\n",
      "Epoch 188/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7088 - acc: 0.4645Epoch 00187: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.7050 - acc: 0.4653 - val_loss: 6.5196 - val_acc: 0.4993\n",
      "Epoch 189/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.7027 - acc: 0.4654Epoch 00188: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 180s - loss: 6.7029 - acc: 0.4653 - val_loss: 6.5151 - val_acc: 0.4993\n",
      "Epoch 190/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6948 - acc: 0.4646Epoch 00189: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 6.6914 - acc: 0.4653 - val_loss: 6.5102 - val_acc: 0.4993\n",
      "Epoch 191/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6879 - acc: 0.4654Epoch 00190: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.6889 - acc: 0.4653 - val_loss: 6.5063 - val_acc: 0.4993\n",
      "Epoch 192/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6832 - acc: 0.4652Epoch 00191: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.6820 - acc: 0.4653 - val_loss: 6.5013 - val_acc: 0.4993\n",
      "Epoch 193/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6862 - acc: 0.4663Epoch 00192: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.6918 - acc: 0.4653 - val_loss: 6.4974 - val_acc: 0.4993\n",
      "Epoch 194/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6745 - acc: 0.4656Epoch 00193: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6764 - acc: 0.4653 - val_loss: 6.4931 - val_acc: 0.4993\n",
      "Epoch 195/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6739 - acc: 0.4652Epoch 00194: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6739 - acc: 0.4653 - val_loss: 6.4883 - val_acc: 0.4993\n",
      "Epoch 196/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6640 - acc: 0.4653Epoch 00195: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6643 - acc: 0.4653 - val_loss: 6.4835 - val_acc: 0.4993\n",
      "Epoch 197/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6699 - acc: 0.4651Epoch 00196: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6700 - acc: 0.4653 - val_loss: 6.4803 - val_acc: 0.4993\n",
      "Epoch 198/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6622 - acc: 0.4652Epoch 00197: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6613 - acc: 0.4653 - val_loss: 6.4761 - val_acc: 0.4993\n",
      "Epoch 199/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6577 - acc: 0.4650Epoch 00198: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6563 - acc: 0.4653 - val_loss: 6.4720 - val_acc: 0.4993\n",
      "Epoch 200/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6564 - acc: 0.4653Epoch 00199: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6561 - acc: 0.4653 - val_loss: 6.4681 - val_acc: 0.4993\n",
      "Epoch 201/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6531 - acc: 0.4650Epoch 00200: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6514 - acc: 0.4653 - val_loss: 6.4640 - val_acc: 0.4993\n",
      "Epoch 202/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6458 - acc: 0.4650Epoch 00201: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6447 - acc: 0.4653 - val_loss: 6.4600 - val_acc: 0.4993\n",
      "Epoch 203/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6343 - acc: 0.4655Epoch 00202: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6363 - acc: 0.4653 - val_loss: 6.4556 - val_acc: 0.4993\n",
      "Epoch 204/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6357 - acc: 0.4652Epoch 00203: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6348 - acc: 0.4653 - val_loss: 6.4509 - val_acc: 0.4993\n",
      "Epoch 205/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6219 - acc: 0.4654Epoch 00204: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6224 - acc: 0.4653 - val_loss: 6.4458 - val_acc: 0.4993\n",
      "Epoch 206/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6296 - acc: 0.4650Epoch 00205: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6279 - acc: 0.4653 - val_loss: 6.4418 - val_acc: 0.4993\n",
      "Epoch 207/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6203 - acc: 0.4653Epoch 00206: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6198 - acc: 0.4653 - val_loss: 6.4375 - val_acc: 0.4993\n",
      "Epoch 208/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6212 - acc: 0.4654Epoch 00207: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6222 - acc: 0.4653 - val_loss: 6.4339 - val_acc: 0.4993\n",
      "Epoch 209/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6116 - acc: 0.4654Epoch 00208: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6125 - acc: 0.4653 - val_loss: 6.4297 - val_acc: 0.4993\n",
      "Epoch 210/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6137 - acc: 0.4651Epoch 00209: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.6129 - acc: 0.4653 - val_loss: 6.4258 - val_acc: 0.4993\n",
      "Epoch 211/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6057 - acc: 0.4651Epoch 00210: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6047 - acc: 0.4653 - val_loss: 6.4221 - val_acc: 0.4993\n",
      "Epoch 212/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.6112 - acc: 0.4651Epoch 00211: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.6101 - acc: 0.4653 - val_loss: 6.4188 - val_acc: 0.4993\n",
      "Epoch 213/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5968 - acc: 0.4654Epoch 00212: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.5973 - acc: 0.4653 - val_loss: 6.4150 - val_acc: 0.4993\n",
      "Epoch 214/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5910 - acc: 0.4658Epoch 00213: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.5937 - acc: 0.4653 - val_loss: 6.4111 - val_acc: 0.4993\n",
      "Epoch 215/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5917 - acc: 0.4648Epoch 00214: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.5892 - acc: 0.4653 - val_loss: 6.4071 - val_acc: 0.4993\n",
      "Epoch 216/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5830 - acc: 0.4656Epoch 00215: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.5853 - acc: 0.4653 - val_loss: 6.4032 - val_acc: 0.4993\n",
      "Epoch 217/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5824 - acc: 0.4657Epoch 00216: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.5842 - acc: 0.4653 - val_loss: 6.3997 - val_acc: 0.4993\n",
      "Epoch 218/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5857 - acc: 0.4650Epoch 00217: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 177s - loss: 6.5836 - acc: 0.4653 - val_loss: 6.3956 - val_acc: 0.4993\n",
      "Epoch 219/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5814 - acc: 0.4648Epoch 00218: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5788 - acc: 0.4653 - val_loss: 6.3921 - val_acc: 0.4993\n",
      "Epoch 220/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5692 - acc: 0.4655Epoch 00219: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5702 - acc: 0.4653 - val_loss: 6.3884 - val_acc: 0.4993\n",
      "Epoch 221/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5685 - acc: 0.4653Epoch 00220: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5684 - acc: 0.4653 - val_loss: 6.3853 - val_acc: 0.4993\n",
      "Epoch 222/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5675 - acc: 0.4656Epoch 00221: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5693 - acc: 0.4653 - val_loss: 6.3816 - val_acc: 0.4993\n",
      "Epoch 223/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5626 - acc: 0.4657Epoch 00222: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5643 - acc: 0.4653 - val_loss: 6.3785 - val_acc: 0.4993\n",
      "Epoch 224/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5605 - acc: 0.4646Epoch 00223: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5572 - acc: 0.4653 - val_loss: 6.3744 - val_acc: 0.4993\n",
      "Epoch 225/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5481 - acc: 0.4656Epoch 00224: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5503 - acc: 0.4653 - val_loss: 6.3703 - val_acc: 0.4993\n",
      "Epoch 226/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5525 - acc: 0.4650Epoch 00225: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5512 - acc: 0.4653 - val_loss: 6.3668 - val_acc: 0.4993\n",
      "Epoch 227/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5491 - acc: 0.4649Epoch 00226: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5474 - acc: 0.4653 - val_loss: 6.3636 - val_acc: 0.4993\n",
      "Epoch 228/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5459 - acc: 0.4654Epoch 00227: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5466 - acc: 0.4653 - val_loss: 6.3608 - val_acc: 0.4993\n",
      "Epoch 229/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5466 - acc: 0.4655Epoch 00228: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5477 - acc: 0.4653 - val_loss: 6.3578 - val_acc: 0.4993\n",
      "Epoch 230/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5372 - acc: 0.4651Epoch 00229: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5371 - acc: 0.4653 - val_loss: 6.3537 - val_acc: 0.4993\n",
      "Epoch 231/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5302 - acc: 0.4657Epoch 00230: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5320 - acc: 0.4653 - val_loss: 6.3498 - val_acc: 0.4993\n",
      "Epoch 232/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5323 - acc: 0.4649Epoch 00231: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5297 - acc: 0.4653 - val_loss: 6.3465 - val_acc: 0.4993\n",
      "Epoch 233/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5231 - acc: 0.4655Epoch 00232: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5242 - acc: 0.4653 - val_loss: 6.3434 - val_acc: 0.4993\n",
      "Epoch 234/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5310 - acc: 0.4650Epoch 00233: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.5290 - acc: 0.4653 - val_loss: 6.3405 - val_acc: 0.4993\n",
      "Epoch 235/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5180 - acc: 0.4654Epoch 00234: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5189 - acc: 0.4653 - val_loss: 6.3370 - val_acc: 0.4993\n",
      "Epoch 236/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5127 - acc: 0.4653Epoch 00235: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.5133 - acc: 0.4653 - val_loss: 6.3329 - val_acc: 0.4993\n",
      "Epoch 237/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5094 - acc: 0.4654Epoch 00236: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5098 - acc: 0.4653 - val_loss: 6.3292 - val_acc: 0.4993\n",
      "Epoch 238/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5121 - acc: 0.4650Epoch 00237: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5108 - acc: 0.4653 - val_loss: 6.3257 - val_acc: 0.4993\n",
      "Epoch 239/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5032 - acc: 0.4654Epoch 00238: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5036 - acc: 0.4653 - val_loss: 6.3226 - val_acc: 0.4993\n",
      "Epoch 240/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5041 - acc: 0.4649Epoch 00239: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.5017 - acc: 0.4653 - val_loss: 6.3195 - val_acc: 0.4993\n",
      "Epoch 241/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.5015 - acc: 0.4646Epoch 00240: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4980 - acc: 0.4653 - val_loss: 6.3160 - val_acc: 0.4993\n",
      "Epoch 242/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4930 - acc: 0.4654Epoch 00241: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4930 - acc: 0.4653 - val_loss: 6.3127 - val_acc: 0.4993\n",
      "Epoch 243/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4969 - acc: 0.4655Epoch 00242: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4980 - acc: 0.4653 - val_loss: 6.3103 - val_acc: 0.4993\n",
      "Epoch 244/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4904 - acc: 0.4653Epoch 00243: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4910 - acc: 0.4653 - val_loss: 6.3068 - val_acc: 0.4993\n",
      "Epoch 245/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4885 - acc: 0.4650Epoch 00244: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4875 - acc: 0.4653 - val_loss: 6.3042 - val_acc: 0.4993\n",
      "Epoch 246/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4839 - acc: 0.4653Epoch 00245: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4839 - acc: 0.4653 - val_loss: 6.3011 - val_acc: 0.4993\n",
      "Epoch 247/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4743 - acc: 0.4654Epoch 00246: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 176s - loss: 6.4749 - acc: 0.4653 - val_loss: 6.2970 - val_acc: 0.4993\n",
      "Epoch 248/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4856 - acc: 0.4649Epoch 00247: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4837 - acc: 0.4653 - val_loss: 6.2953 - val_acc: 0.4993\n",
      "Epoch 249/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4785 - acc: 0.4652Epoch 00248: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4783 - acc: 0.4653 - val_loss: 6.2918 - val_acc: 0.4993\n",
      "Epoch 250/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4696 - acc: 0.4657Epoch 00249: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4718 - acc: 0.4653 - val_loss: 6.2887 - val_acc: 0.4993\n",
      "Epoch 251/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4690 - acc: 0.4649Epoch 00250: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4673 - acc: 0.4653 - val_loss: 6.2856 - val_acc: 0.4993\n",
      "Epoch 252/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4620 - acc: 0.4651Epoch 00251: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4609 - acc: 0.4653 - val_loss: 6.2820 - val_acc: 0.4993\n",
      "Epoch 253/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4608 - acc: 0.4649Epoch 00252: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4589 - acc: 0.4653 - val_loss: 6.2785 - val_acc: 0.4993\n",
      "Epoch 254/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4625 - acc: 0.4650Epoch 00253: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4616 - acc: 0.4653 - val_loss: 6.2764 - val_acc: 0.4993\n",
      "Epoch 255/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4609 - acc: 0.4651Epoch 00254: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4599 - acc: 0.4653 - val_loss: 6.2738 - val_acc: 0.4993\n",
      "Epoch 256/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4585 - acc: 0.4648Epoch 00255: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4557 - acc: 0.4653 - val_loss: 6.2712 - val_acc: 0.4993\n",
      "Epoch 257/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4484 - acc: 0.4654Epoch 00256: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4491 - acc: 0.4653 - val_loss: 6.2679 - val_acc: 0.4993\n",
      "Epoch 258/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4533 - acc: 0.4650Epoch 00257: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4517 - acc: 0.4653 - val_loss: 6.2653 - val_acc: 0.4993\n",
      "Epoch 259/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4363 - acc: 0.4660Epoch 00258: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4406 - acc: 0.4653 - val_loss: 6.2617 - val_acc: 0.4993\n",
      "Epoch 260/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4493 - acc: 0.4652Epoch 00259: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4489 - acc: 0.4653 - val_loss: 6.2596 - val_acc: 0.4993\n",
      "Epoch 261/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4370 - acc: 0.4653Epoch 00260: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4373 - acc: 0.4653 - val_loss: 6.2560 - val_acc: 0.4993\n",
      "Epoch 262/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4373 - acc: 0.4654Epoch 00261: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4384 - acc: 0.4653 - val_loss: 6.2534 - val_acc: 0.4993\n",
      "Epoch 263/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4372 - acc: 0.4654Epoch 00262: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4380 - acc: 0.4653 - val_loss: 6.2511 - val_acc: 0.4993\n",
      "Epoch 264/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4263 - acc: 0.4655Epoch 00263: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4276 - acc: 0.4653 - val_loss: 6.2476 - val_acc: 0.4993\n",
      "Epoch 265/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4280 - acc: 0.4645Epoch 00264: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4239 - acc: 0.4653 - val_loss: 6.2444 - val_acc: 0.4993\n",
      "Epoch 266/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4233 - acc: 0.4652Epoch 00265: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4231 - acc: 0.4653 - val_loss: 6.2416 - val_acc: 0.4993\n",
      "Epoch 267/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4142 - acc: 0.4657Epoch 00266: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4163 - acc: 0.4653 - val_loss: 6.2382 - val_acc: 0.4993\n",
      "Epoch 268/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4194 - acc: 0.4658Epoch 00267: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4224 - acc: 0.4653 - val_loss: 6.2366 - val_acc: 0.4993\n",
      "Epoch 269/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4122 - acc: 0.4649Epoch 00268: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.4111 - acc: 0.4653 - val_loss: 6.2333 - val_acc: 0.4993\n",
      "Epoch 270/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4092 - acc: 0.4654Epoch 00269: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4095 - acc: 0.4653 - val_loss: 6.2304 - val_acc: 0.4993\n",
      "Epoch 271/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4085 - acc: 0.4654Epoch 00270: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4098 - acc: 0.4653 - val_loss: 6.2275 - val_acc: 0.4993\n",
      "Epoch 272/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3971 - acc: 0.4654Epoch 00271: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3985 - acc: 0.4653 - val_loss: 6.2246 - val_acc: 0.4993\n",
      "Epoch 273/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3994 - acc: 0.4656Epoch 00272: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.4006 - acc: 0.4653 - val_loss: 6.2219 - val_acc: 0.4993\n",
      "Epoch 274/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.4024 - acc: 0.4655Epoch 00273: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.4040 - acc: 0.4653 - val_loss: 6.2194 - val_acc: 0.4993\n",
      "Epoch 275/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3916 - acc: 0.4654Epoch 00274: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3921 - acc: 0.4653 - val_loss: 6.2160 - val_acc: 0.4993\n",
      "Epoch 276/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3988 - acc: 0.4651Epoch 00275: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 176s - loss: 6.3979 - acc: 0.4653 - val_loss: 6.2136 - val_acc: 0.4993\n",
      "Epoch 277/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3965 - acc: 0.4649Epoch 00276: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3947 - acc: 0.4653 - val_loss: 6.2109 - val_acc: 0.4993\n",
      "Epoch 278/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3890 - acc: 0.4655Epoch 00277: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3903 - acc: 0.4653 - val_loss: 6.2083 - val_acc: 0.4993\n",
      "Epoch 279/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3869 - acc: 0.4655Epoch 00278: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.3888 - acc: 0.4653 - val_loss: 6.2060 - val_acc: 0.4993\n",
      "Epoch 280/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3808 - acc: 0.4661Epoch 00279: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3851 - acc: 0.4653 - val_loss: 6.2034 - val_acc: 0.4993\n",
      "Epoch 281/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3811 - acc: 0.4652Epoch 00280: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.3812 - acc: 0.4653 - val_loss: 6.2010 - val_acc: 0.4993\n",
      "Epoch 282/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3843 - acc: 0.4650Epoch 00281: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3829 - acc: 0.4653 - val_loss: 6.1985 - val_acc: 0.4993\n",
      "Epoch 283/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3683 - acc: 0.4658Epoch 00282: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3712 - acc: 0.4653 - val_loss: 6.1953 - val_acc: 0.4993\n",
      "Epoch 284/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3780 - acc: 0.4651Epoch 00283: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3770 - acc: 0.4653 - val_loss: 6.1932 - val_acc: 0.4993\n",
      "Epoch 285/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3744 - acc: 0.4650Epoch 00284: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3728 - acc: 0.4653 - val_loss: 6.1904 - val_acc: 0.4993\n",
      "Epoch 286/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3699 - acc: 0.4654Epoch 00285: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3709 - acc: 0.4652 - val_loss: 6.1877 - val_acc: 0.4993\n",
      "Epoch 287/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3598 - acc: 0.4656Epoch 00286: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3623 - acc: 0.4653 - val_loss: 6.1847 - val_acc: 0.4993\n",
      "Epoch 288/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3634 - acc: 0.4654Epoch 00287: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3643 - acc: 0.4653 - val_loss: 6.1828 - val_acc: 0.4993\n",
      "Epoch 289/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3595 - acc: 0.4653Epoch 00288: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3599 - acc: 0.4653 - val_loss: 6.1803 - val_acc: 0.4993\n",
      "Epoch 290/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3585 - acc: 0.4651Epoch 00289: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3579 - acc: 0.4653 - val_loss: 6.1777 - val_acc: 0.4993\n",
      "Epoch 291/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3568 - acc: 0.4655Epoch 00290: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3583 - acc: 0.4653 - val_loss: 6.1752 - val_acc: 0.4993\n",
      "Epoch 292/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3516 - acc: 0.4658Epoch 00291: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3547 - acc: 0.4653 - val_loss: 6.1728 - val_acc: 0.4993\n",
      "Epoch 293/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3437 - acc: 0.4654Epoch 00292: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3452 - acc: 0.4653 - val_loss: 6.1695 - val_acc: 0.4993\n",
      "Epoch 294/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3485 - acc: 0.4657Epoch 00293: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.3515 - acc: 0.4653 - val_loss: 6.1678 - val_acc: 0.4993\n",
      "Epoch 295/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3568 - acc: 0.4645Epoch 00294: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.3528 - acc: 0.4653 - val_loss: 6.1661 - val_acc: 0.4993\n",
      "Epoch 296/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3430 - acc: 0.4653Epoch 00295: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3433 - acc: 0.4653 - val_loss: 6.1631 - val_acc: 0.4993\n",
      "Epoch 297/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3387 - acc: 0.4655Epoch 00296: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3403 - acc: 0.4653 - val_loss: 6.1604 - val_acc: 0.4993\n",
      "Epoch 298/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3332 - acc: 0.4653Epoch 00297: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3331 - acc: 0.4653 - val_loss: 6.1579 - val_acc: 0.4993\n",
      "Epoch 299/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3320 - acc: 0.4658Epoch 00298: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3354 - acc: 0.4653 - val_loss: 6.1555 - val_acc: 0.4993\n",
      "Epoch 300/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3305 - acc: 0.4657Epoch 00299: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3324 - acc: 0.4653 - val_loss: 6.1528 - val_acc: 0.4993\n",
      "Epoch 301/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3304 - acc: 0.4654Epoch 00300: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3304 - acc: 0.4653 - val_loss: 6.1503 - val_acc: 0.4993\n",
      "Epoch 302/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3332 - acc: 0.4649Epoch 00301: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3311 - acc: 0.4653 - val_loss: 6.1483 - val_acc: 0.4993\n",
      "Epoch 303/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3221 - acc: 0.4650Epoch 00302: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3207 - acc: 0.4653 - val_loss: 6.1453 - val_acc: 0.4993\n",
      "Epoch 304/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3258 - acc: 0.4652Epoch 00303: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3254 - acc: 0.4653 - val_loss: 6.1433 - val_acc: 0.4993\n",
      "Epoch 305/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3206 - acc: 0.4651Epoch 00304: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 176s - loss: 6.3205 - acc: 0.4653 - val_loss: 6.1409 - val_acc: 0.4993\n",
      "Epoch 306/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3209 - acc: 0.4649Epoch 00305: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3190 - acc: 0.4653 - val_loss: 6.1389 - val_acc: 0.4993\n",
      "Epoch 307/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3166 - acc: 0.4647Epoch 00306: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3138 - acc: 0.4653 - val_loss: 6.1366 - val_acc: 0.4993\n",
      "Epoch 308/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3128 - acc: 0.4651Epoch 00307: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3117 - acc: 0.4653 - val_loss: 6.1338 - val_acc: 0.4993\n",
      "Epoch 309/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3206 - acc: 0.4647Epoch 00308: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3177 - acc: 0.4653 - val_loss: 6.1322 - val_acc: 0.4993\n",
      "Epoch 310/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3095 - acc: 0.4652Epoch 00309: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3092 - acc: 0.4653 - val_loss: 6.1295 - val_acc: 0.4993\n",
      "Epoch 311/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3064 - acc: 0.4655Epoch 00310: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3080 - acc: 0.4653 - val_loss: 6.1274 - val_acc: 0.4993\n",
      "Epoch 312/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3071 - acc: 0.4650Epoch 00311: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3057 - acc: 0.4653 - val_loss: 6.1251 - val_acc: 0.4993\n",
      "Epoch 313/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3027 - acc: 0.4656Epoch 00312: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3043 - acc: 0.4653 - val_loss: 6.1229 - val_acc: 0.4993\n",
      "Epoch 314/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3001 - acc: 0.4652Epoch 00313: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3002 - acc: 0.4653 - val_loss: 6.1209 - val_acc: 0.4993\n",
      "Epoch 315/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3053 - acc: 0.4651Epoch 00314: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.3048 - acc: 0.4653 - val_loss: 6.1194 - val_acc: 0.4993\n",
      "Epoch 316/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.3024 - acc: 0.4654Epoch 00315: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.3031 - acc: 0.4653 - val_loss: 6.1173 - val_acc: 0.4993\n",
      "Epoch 317/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2930 - acc: 0.4651Epoch 00316: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2922 - acc: 0.4653 - val_loss: 6.1149 - val_acc: 0.4993\n",
      "Epoch 318/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2945 - acc: 0.4652Epoch 00317: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2933 - acc: 0.4653 - val_loss: 6.1129 - val_acc: 0.4993\n",
      "Epoch 319/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2857 - acc: 0.4650Epoch 00318: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2843 - acc: 0.4653 - val_loss: 6.1102 - val_acc: 0.4993\n",
      "Epoch 320/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2830 - acc: 0.4652Epoch 00319: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2826 - acc: 0.4653 - val_loss: 6.1074 - val_acc: 0.4993\n",
      "Epoch 321/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2836 - acc: 0.4653Epoch 00320: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2836 - acc: 0.4653 - val_loss: 6.1055 - val_acc: 0.4993\n",
      "Epoch 322/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2845 - acc: 0.4651Epoch 00321: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2838 - acc: 0.4653 - val_loss: 6.1032 - val_acc: 0.4993\n",
      "Epoch 323/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2748 - acc: 0.4657Epoch 00322: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2774 - acc: 0.4653 - val_loss: 6.1008 - val_acc: 0.4993\n",
      "Epoch 324/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2811 - acc: 0.4654Epoch 00323: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2817 - acc: 0.4653 - val_loss: 6.0991 - val_acc: 0.4993\n",
      "Epoch 325/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2726 - acc: 0.4651Epoch 00324: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2721 - acc: 0.4653 - val_loss: 6.0968 - val_acc: 0.4993\n",
      "Epoch 326/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2668 - acc: 0.4663Epoch 00325: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2726 - acc: 0.4653 - val_loss: 6.0951 - val_acc: 0.4993\n",
      "Epoch 327/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2837 - acc: 0.4648Epoch 00326: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2812 - acc: 0.4653 - val_loss: 6.0937 - val_acc: 0.4993\n",
      "Epoch 328/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2698 - acc: 0.4651Epoch 00327: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2692 - acc: 0.4653 - val_loss: 6.0916 - val_acc: 0.4993\n",
      "Epoch 329/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2730 - acc: 0.4649Epoch 00328: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2711 - acc: 0.4653 - val_loss: 6.0894 - val_acc: 0.4993\n",
      "Epoch 330/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2705 - acc: 0.4648Epoch 00329: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2680 - acc: 0.4653 - val_loss: 6.0869 - val_acc: 0.4993\n",
      "Epoch 331/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2583 - acc: 0.4655Epoch 00330: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2593 - acc: 0.4653 - val_loss: 6.0844 - val_acc: 0.4993\n",
      "Epoch 332/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2611 - acc: 0.4654Epoch 00331: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2615 - acc: 0.4653 - val_loss: 6.0820 - val_acc: 0.4993\n",
      "Epoch 333/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2562 - acc: 0.4653Epoch 00332: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2565 - acc: 0.4653 - val_loss: 6.0800 - val_acc: 0.4993\n",
      "Epoch 334/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2582 - acc: 0.4651Epoch 00333: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 177s - loss: 6.2572 - acc: 0.4653 - val_loss: 6.0780 - val_acc: 0.4993\n",
      "Epoch 335/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2520 - acc: 0.4657Epoch 00334: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2546 - acc: 0.4653 - val_loss: 6.0759 - val_acc: 0.4993\n",
      "Epoch 336/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2573 - acc: 0.4647Epoch 00335: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2544 - acc: 0.4653 - val_loss: 6.0740 - val_acc: 0.4993\n",
      "Epoch 337/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2520 - acc: 0.4654Epoch 00336: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.2526 - acc: 0.4653 - val_loss: 6.0722 - val_acc: 0.4993\n",
      "Epoch 338/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2464 - acc: 0.4654Epoch 00337: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2475 - acc: 0.4653 - val_loss: 6.0701 - val_acc: 0.4993\n",
      "Epoch 339/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2527 - acc: 0.4647Epoch 00338: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2497 - acc: 0.4653 - val_loss: 6.0685 - val_acc: 0.4993\n",
      "Epoch 340/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2397 - acc: 0.4656Epoch 00339: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2419 - acc: 0.4653 - val_loss: 6.0662 - val_acc: 0.4993\n",
      "Epoch 341/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2508 - acc: 0.4650Epoch 00340: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2494 - acc: 0.4653 - val_loss: 6.0647 - val_acc: 0.4993\n",
      "Epoch 342/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2441 - acc: 0.4647Epoch 00341: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2419 - acc: 0.4653 - val_loss: 6.0625 - val_acc: 0.4993\n",
      "Epoch 343/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2349 - acc: 0.4652Epoch 00342: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2349 - acc: 0.4653 - val_loss: 6.0605 - val_acc: 0.4993\n",
      "Epoch 344/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2376 - acc: 0.4652Epoch 00343: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2373 - acc: 0.4653 - val_loss: 6.0585 - val_acc: 0.4993\n",
      "Epoch 345/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2330 - acc: 0.4645Epoch 00344: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.2288 - acc: 0.4653 - val_loss: 6.0563 - val_acc: 0.4993\n",
      "Epoch 346/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2287 - acc: 0.4651Epoch 00345: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2283 - acc: 0.4653 - val_loss: 6.0539 - val_acc: 0.4993\n",
      "Epoch 347/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2279 - acc: 0.4655Epoch 00346: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.2295 - acc: 0.4653 - val_loss: 6.0521 - val_acc: 0.4993\n",
      "Epoch 348/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2335 - acc: 0.4650Epoch 00347: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2324 - acc: 0.4653 - val_loss: 6.0505 - val_acc: 0.4993\n",
      "Epoch 349/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2278 - acc: 0.4652Epoch 00348: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2268 - acc: 0.4653 - val_loss: 6.0486 - val_acc: 0.4993\n",
      "Epoch 350/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2219 - acc: 0.4650Epoch 00349: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2208 - acc: 0.4653 - val_loss: 6.0464 - val_acc: 0.4993\n",
      "Epoch 351/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2311 - acc: 0.4651Epoch 00350: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2302 - acc: 0.4653 - val_loss: 6.0450 - val_acc: 0.4993\n",
      "Epoch 352/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2268 - acc: 0.4650Epoch 00351: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2252 - acc: 0.4653 - val_loss: 6.0434 - val_acc: 0.4993\n",
      "Epoch 353/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2140 - acc: 0.4656Epoch 00352: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2163 - acc: 0.4653 - val_loss: 6.0415 - val_acc: 0.4993\n",
      "Epoch 354/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2198 - acc: 0.4652Epoch 00353: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.2194 - acc: 0.4653 - val_loss: 6.0394 - val_acc: 0.4993\n",
      "Epoch 355/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2172 - acc: 0.4655Epoch 00354: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.2185 - acc: 0.4653 - val_loss: 6.0377 - val_acc: 0.4993\n",
      "Epoch 356/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2145 - acc: 0.4649Epoch 00355: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.2130 - acc: 0.4653 - val_loss: 6.0354 - val_acc: 0.4993\n",
      "Epoch 357/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2189 - acc: 0.4651Epoch 00356: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.2177 - acc: 0.4653 - val_loss: 6.0340 - val_acc: 0.4993\n",
      "Epoch 358/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2024 - acc: 0.4659Epoch 00357: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.2060 - acc: 0.4653 - val_loss: 6.0319 - val_acc: 0.4993\n",
      "Epoch 359/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2109 - acc: 0.4654Epoch 00358: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.2111 - acc: 0.4653 - val_loss: 6.0304 - val_acc: 0.4993\n",
      "Epoch 360/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2072 - acc: 0.4655Epoch 00359: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.2085 - acc: 0.4653 - val_loss: 6.0289 - val_acc: 0.4993\n",
      "Epoch 361/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2126 - acc: 0.4652Epoch 00360: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.2124 - acc: 0.4653 - val_loss: 6.0274 - val_acc: 0.4993\n",
      "Epoch 362/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1988 - acc: 0.4651Epoch 00361: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.1979 - acc: 0.4653 - val_loss: 6.0253 - val_acc: 0.4993\n",
      "Epoch 363/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2021 - acc: 0.4653Epoch 00362: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 179s - loss: 6.2021 - acc: 0.4653 - val_loss: 6.0232 - val_acc: 0.4993\n",
      "Epoch 364/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1970 - acc: 0.4656Epoch 00363: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1985 - acc: 0.4653 - val_loss: 6.0213 - val_acc: 0.4993\n",
      "Epoch 365/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2040 - acc: 0.4651Epoch 00364: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.2030 - acc: 0.4653 - val_loss: 6.0201 - val_acc: 0.4993\n",
      "Epoch 366/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1973 - acc: 0.4651Epoch 00365: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.1966 - acc: 0.4653 - val_loss: 6.0181 - val_acc: 0.4993\n",
      "Epoch 367/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.2020 - acc: 0.4649Epoch 00366: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1997 - acc: 0.4653 - val_loss: 6.0161 - val_acc: 0.4993\n",
      "Epoch 368/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1946 - acc: 0.4651Epoch 00367: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1938 - acc: 0.4653 - val_loss: 6.0144 - val_acc: 0.4993\n",
      "Epoch 369/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1930 - acc: 0.4646Epoch 00368: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1895 - acc: 0.4653 - val_loss: 6.0124 - val_acc: 0.4993\n",
      "Epoch 370/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1914 - acc: 0.4652Epoch 00369: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1912 - acc: 0.4653 - val_loss: 6.0110 - val_acc: 0.4993\n",
      "Epoch 371/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1832 - acc: 0.4653Epoch 00370: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1831 - acc: 0.4653 - val_loss: 6.0088 - val_acc: 0.4993\n",
      "Epoch 372/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1933 - acc: 0.4647Epoch 00371: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1907 - acc: 0.4653 - val_loss: 6.0076 - val_acc: 0.4993\n",
      "Epoch 373/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1799 - acc: 0.4654Epoch 00372: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1813 - acc: 0.4653 - val_loss: 6.0055 - val_acc: 0.4993\n",
      "Epoch 374/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1894 - acc: 0.4646Epoch 00373: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1861 - acc: 0.4653 - val_loss: 6.0044 - val_acc: 0.4993\n",
      "Epoch 375/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1855 - acc: 0.4648Epoch 00374: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1834 - acc: 0.4653 - val_loss: 6.0026 - val_acc: 0.4993\n",
      "Epoch 376/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1729 - acc: 0.4653Epoch 00375: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.1734 - acc: 0.4653 - val_loss: 6.0011 - val_acc: 0.4993\n",
      "Epoch 377/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1761 - acc: 0.4658Epoch 00376: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.1791 - acc: 0.4653 - val_loss: 5.9993 - val_acc: 0.4993\n",
      "Epoch 378/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1714 - acc: 0.4652Epoch 00377: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1712 - acc: 0.4653 - val_loss: 5.9974 - val_acc: 0.4993\n",
      "Epoch 379/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1769 - acc: 0.4653Epoch 00378: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1776 - acc: 0.4653 - val_loss: 5.9959 - val_acc: 0.4993\n",
      "Epoch 380/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1720 - acc: 0.4652Epoch 00379: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.1720 - acc: 0.4653 - val_loss: 5.9940 - val_acc: 0.4993\n",
      "Epoch 381/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1712 - acc: 0.4661Epoch 00380: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1761 - acc: 0.4653 - val_loss: 5.9926 - val_acc: 0.4993\n",
      "Epoch 382/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1666 - acc: 0.4660Epoch 00381: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1701 - acc: 0.4653 - val_loss: 5.9909 - val_acc: 0.4993\n",
      "Epoch 383/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1666 - acc: 0.4649Epoch 00382: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1643 - acc: 0.4653 - val_loss: 5.9891 - val_acc: 0.4993\n",
      "Epoch 384/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1674 - acc: 0.4647Epoch 00383: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1646 - acc: 0.4653 - val_loss: 5.9875 - val_acc: 0.4993\n",
      "Epoch 385/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1547 - acc: 0.4653Epoch 00384: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1544 - acc: 0.4653 - val_loss: 5.9853 - val_acc: 0.4993\n",
      "Epoch 386/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1655 - acc: 0.4653Epoch 00385: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1660 - acc: 0.4653 - val_loss: 5.9839 - val_acc: 0.4993\n",
      "Epoch 387/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1654 - acc: 0.4653Epoch 00386: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1658 - acc: 0.4653 - val_loss: 5.9827 - val_acc: 0.4993\n",
      "Epoch 388/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1525 - acc: 0.4654Epoch 00387: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1535 - acc: 0.4653 - val_loss: 5.9804 - val_acc: 0.4993\n",
      "Epoch 389/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1626 - acc: 0.4655Epoch 00388: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1633 - acc: 0.4653 - val_loss: 5.9790 - val_acc: 0.4993\n",
      "Epoch 390/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1583 - acc: 0.4653Epoch 00389: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1585 - acc: 0.4653 - val_loss: 5.9773 - val_acc: 0.4993\n",
      "Epoch 391/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1523 - acc: 0.4652Epoch 00390: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1523 - acc: 0.4653 - val_loss: 5.9754 - val_acc: 0.4993\n",
      "Epoch 392/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1449 - acc: 0.4655Epoch 00391: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 178s - loss: 6.1461 - acc: 0.4653 - val_loss: 5.9737 - val_acc: 0.4993\n",
      "Epoch 393/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1528 - acc: 0.4652Epoch 00392: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1522 - acc: 0.4653 - val_loss: 5.9726 - val_acc: 0.4993\n",
      "Epoch 394/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1534 - acc: 0.4656Epoch 00393: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.1552 - acc: 0.4653 - val_loss: 5.9718 - val_acc: 0.4993\n",
      "Epoch 395/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1473 - acc: 0.4647Epoch 00394: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.1445 - acc: 0.4653 - val_loss: 5.9695 - val_acc: 0.4993\n",
      "Epoch 396/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1381 - acc: 0.4655Epoch 00395: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1396 - acc: 0.4653 - val_loss: 5.9675 - val_acc: 0.4993\n",
      "Epoch 397/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1461 - acc: 0.4652Epoch 00396: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1456 - acc: 0.4653 - val_loss: 5.9662 - val_acc: 0.4993\n",
      "Epoch 398/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1401 - acc: 0.4651Epoch 00397: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.1391 - acc: 0.4653 - val_loss: 5.9646 - val_acc: 0.4993\n",
      "Epoch 399/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1434 - acc: 0.4646Epoch 00398: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1400 - acc: 0.4653 - val_loss: 5.9625 - val_acc: 0.4993\n",
      "Epoch 400/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1358 - acc: 0.4653Epoch 00399: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1356 - acc: 0.4653 - val_loss: 5.9607 - val_acc: 0.4993\n",
      "Epoch 401/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1397 - acc: 0.4648Epoch 00400: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.1374 - acc: 0.4653 - val_loss: 5.9593 - val_acc: 0.4993\n",
      "Epoch 402/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1391 - acc: 0.4652Epoch 00401: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1386 - acc: 0.4653 - val_loss: 5.9583 - val_acc: 0.4993\n",
      "Epoch 403/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1384 - acc: 0.4649Epoch 00402: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 6.1362 - acc: 0.4653 - val_loss: 5.9570 - val_acc: 0.4993\n",
      "Epoch 404/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1404 - acc: 0.4650Epoch 00403: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.1390 - acc: 0.4653 - val_loss: 5.9559 - val_acc: 0.4993\n",
      "Epoch 405/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1297 - acc: 0.4654Epoch 00404: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1303 - acc: 0.4653 - val_loss: 5.9544 - val_acc: 0.4993\n",
      "Epoch 406/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1294 - acc: 0.4652Epoch 00405: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.1292 - acc: 0.4653 - val_loss: 5.9525 - val_acc: 0.4993\n",
      "Epoch 407/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1277 - acc: 0.4653Epoch 00406: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.1282 - acc: 0.4653 - val_loss: 5.9510 - val_acc: 0.4993\n",
      "Epoch 408/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1252 - acc: 0.4657Epoch 00407: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1274 - acc: 0.4653 - val_loss: 5.9491 - val_acc: 0.4993\n",
      "Epoch 409/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1256 - acc: 0.4655Epoch 00408: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1271 - acc: 0.4653 - val_loss: 5.9478 - val_acc: 0.4993\n",
      "Epoch 410/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1189 - acc: 0.4656Epoch 00409: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1207 - acc: 0.4653 - val_loss: 5.9466 - val_acc: 0.4993\n",
      "Epoch 411/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1310 - acc: 0.4648Epoch 00410: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1283 - acc: 0.4653 - val_loss: 5.9455 - val_acc: 0.4993\n",
      "Epoch 412/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1189 - acc: 0.4648Epoch 00411: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1166 - acc: 0.4653 - val_loss: 5.9438 - val_acc: 0.4993\n",
      "Epoch 413/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1199 - acc: 0.4654Epoch 00412: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1200 - acc: 0.4653 - val_loss: 5.9423 - val_acc: 0.4993\n",
      "Epoch 414/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1151 - acc: 0.4657Epoch 00413: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.1172 - acc: 0.4653 - val_loss: 5.9405 - val_acc: 0.4993\n",
      "Epoch 415/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1132 - acc: 0.4653Epoch 00414: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.1133 - acc: 0.4653 - val_loss: 5.9386 - val_acc: 0.4993\n",
      "Epoch 416/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1115 - acc: 0.4652Epoch 00415: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1111 - acc: 0.4653 - val_loss: 5.9371 - val_acc: 0.4993\n",
      "Epoch 417/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1154 - acc: 0.4649Epoch 00416: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.1136 - acc: 0.4653 - val_loss: 5.9356 - val_acc: 0.4993\n",
      "Epoch 418/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1040 - acc: 0.4655Epoch 00417: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1057 - acc: 0.4653 - val_loss: 5.9339 - val_acc: 0.4993\n",
      "Epoch 419/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1157 - acc: 0.4650Epoch 00418: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.1154 - acc: 0.4653 - val_loss: 5.9328 - val_acc: 0.4993\n",
      "Epoch 420/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1106 - acc: 0.4652Epoch 00419: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.1102 - acc: 0.4653 - val_loss: 5.9318 - val_acc: 0.4993\n",
      "Epoch 421/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1048 - acc: 0.4657Epoch 00420: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 178s - loss: 6.1070 - acc: 0.4653 - val_loss: 5.9305 - val_acc: 0.4993\n",
      "Epoch 422/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1094 - acc: 0.4651Epoch 00421: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1088 - acc: 0.4653 - val_loss: 5.9290 - val_acc: 0.4993\n",
      "Epoch 423/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1019 - acc: 0.4654Epoch 00422: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1023 - acc: 0.4653 - val_loss: 5.9274 - val_acc: 0.4993\n",
      "Epoch 424/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1066 - acc: 0.4654Epoch 00423: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1071 - acc: 0.4653 - val_loss: 5.9265 - val_acc: 0.4993\n",
      "Epoch 425/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1006 - acc: 0.4650Epoch 00424: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0999 - acc: 0.4653 - val_loss: 5.9255 - val_acc: 0.4993\n",
      "Epoch 426/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0972 - acc: 0.4659Epoch 00425: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.1002 - acc: 0.4653 - val_loss: 5.9237 - val_acc: 0.4993\n",
      "Epoch 427/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0983 - acc: 0.4653Epoch 00426: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0981 - acc: 0.4653 - val_loss: 5.9221 - val_acc: 0.4993\n",
      "Epoch 428/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0937 - acc: 0.4656Epoch 00427: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0957 - acc: 0.4653 - val_loss: 5.9207 - val_acc: 0.4993\n",
      "Epoch 429/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.1028 - acc: 0.4655Epoch 00428: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.1038 - acc: 0.4653 - val_loss: 5.9196 - val_acc: 0.4993\n",
      "Epoch 430/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0913 - acc: 0.4653Epoch 00429: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 6.0914 - acc: 0.4653 - val_loss: 5.9176 - val_acc: 0.4993\n",
      "Epoch 431/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0953 - acc: 0.4652Epoch 00430: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0946 - acc: 0.4653 - val_loss: 5.9164 - val_acc: 0.4993\n",
      "Epoch 432/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0954 - acc: 0.4650Epoch 00431: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0936 - acc: 0.4653 - val_loss: 5.9151 - val_acc: 0.4993\n",
      "Epoch 433/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0851 - acc: 0.4653Epoch 00432: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0854 - acc: 0.4653 - val_loss: 5.9130 - val_acc: 0.4993\n",
      "Epoch 434/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0833 - acc: 0.4653Epoch 00433: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0832 - acc: 0.4653 - val_loss: 5.9116 - val_acc: 0.4993\n",
      "Epoch 435/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0839 - acc: 0.4652Epoch 00434: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0850 - acc: 0.4653 - val_loss: 5.9100 - val_acc: 0.4993\n",
      "Epoch 436/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0865 - acc: 0.4654Epoch 00435: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0872 - acc: 0.4653 - val_loss: 5.9087 - val_acc: 0.4993\n",
      "Epoch 437/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0813 - acc: 0.4651Epoch 00436: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.0803 - acc: 0.4653 - val_loss: 5.9071 - val_acc: 0.4993\n",
      "Epoch 438/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0747 - acc: 0.4654Epoch 00437: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0759 - acc: 0.4653 - val_loss: 5.9055 - val_acc: 0.4993\n",
      "Epoch 439/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0823 - acc: 0.4656Epoch 00438: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0839 - acc: 0.4653 - val_loss: 5.9045 - val_acc: 0.4993\n",
      "Epoch 440/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0802 - acc: 0.4654Epoch 00439: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0806 - acc: 0.4653 - val_loss: 5.9032 - val_acc: 0.4993\n",
      "Epoch 441/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0792 - acc: 0.4656Epoch 00440: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.0806 - acc: 0.4653 - val_loss: 5.9018 - val_acc: 0.4993\n",
      "Epoch 442/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0769 - acc: 0.4650Epoch 00441: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.0755 - acc: 0.4653 - val_loss: 5.9005 - val_acc: 0.4993\n",
      "Epoch 443/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0751 - acc: 0.4657Epoch 00442: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.0773 - acc: 0.4653 - val_loss: 5.8992 - val_acc: 0.4993\n",
      "Epoch 444/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0781 - acc: 0.4650Epoch 00443: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.0769 - acc: 0.4653 - val_loss: 5.8979 - val_acc: 0.4993\n",
      "Epoch 445/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0700 - acc: 0.4651Epoch 00444: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.0696 - acc: 0.4653 - val_loss: 5.8965 - val_acc: 0.4993\n",
      "Epoch 446/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0699 - acc: 0.4654Epoch 00445: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.0711 - acc: 0.4653 - val_loss: 5.8952 - val_acc: 0.4993\n",
      "Epoch 447/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0674 - acc: 0.4658Epoch 00446: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.0699 - acc: 0.4653 - val_loss: 5.8938 - val_acc: 0.4993\n",
      "Epoch 448/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0671 - acc: 0.4653Epoch 00447: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1687s - loss: 6.0676 - acc: 0.4653 - val_loss: 5.8925 - val_acc: 0.4993\n",
      "Epoch 449/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0647 - acc: 0.4652Epoch 00448: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.0640 - acc: 0.4653 - val_loss: 5.8910 - val_acc: 0.4993\n",
      "Epoch 450/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0639 - acc: 0.4652Epoch 00449: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 178s - loss: 6.0633 - acc: 0.4653 - val_loss: 5.8895 - val_acc: 0.4993\n",
      "Epoch 451/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0672 - acc: 0.4653Epoch 00450: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 201s - loss: 6.0672 - acc: 0.4653 - val_loss: 5.8886 - val_acc: 0.4993\n",
      "Epoch 452/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0584 - acc: 0.4654Epoch 00451: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.0588 - acc: 0.4653 - val_loss: 5.8872 - val_acc: 0.4993\n",
      "Epoch 453/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0618 - acc: 0.4650Epoch 00452: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0599 - acc: 0.4653 - val_loss: 5.8860 - val_acc: 0.4993\n",
      "Epoch 454/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0561 - acc: 0.4663Epoch 00453: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0622 - acc: 0.4653 - val_loss: 5.8850 - val_acc: 0.4993\n",
      "Epoch 455/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0567 - acc: 0.4653Epoch 00454: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.0569 - acc: 0.4653 - val_loss: 5.8835 - val_acc: 0.4993\n",
      "Epoch 456/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0584 - acc: 0.4653Epoch 00455: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0584 - acc: 0.4653 - val_loss: 5.8823 - val_acc: 0.4993\n",
      "Epoch 457/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0586 - acc: 0.4650Epoch 00456: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 6.0575 - acc: 0.4653 - val_loss: 5.8809 - val_acc: 0.4993\n",
      "Epoch 458/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0529 - acc: 0.4651Epoch 00457: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0518 - acc: 0.4653 - val_loss: 5.8796 - val_acc: 0.4993\n",
      "Epoch 459/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0513 - acc: 0.4649Epoch 00458: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0490 - acc: 0.4653 - val_loss: 5.8779 - val_acc: 0.4993\n",
      "Epoch 460/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0485 - acc: 0.4653Epoch 00459: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 6.0490 - acc: 0.4653 - val_loss: 5.8768 - val_acc: 0.4993\n",
      "Epoch 461/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0514 - acc: 0.4654Epoch 00460: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0527 - acc: 0.4653 - val_loss: 5.8758 - val_acc: 0.4993\n",
      "Epoch 462/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0537 - acc: 0.4652Epoch 00461: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0530 - acc: 0.4653 - val_loss: 5.8748 - val_acc: 0.4993\n",
      "Epoch 463/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0473 - acc: 0.4657Epoch 00462: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0491 - acc: 0.4653 - val_loss: 5.8738 - val_acc: 0.4993\n",
      "Epoch 464/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0487 - acc: 0.4656Epoch 00463: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.0509 - acc: 0.4653 - val_loss: 5.8724 - val_acc: 0.4993\n",
      "Epoch 465/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0457 - acc: 0.4650Epoch 00464: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.0446 - acc: 0.4653 - val_loss: 5.8711 - val_acc: 0.4993\n",
      "Epoch 466/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0431 - acc: 0.4653Epoch 00465: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0435 - acc: 0.4653 - val_loss: 5.8697 - val_acc: 0.4993\n",
      "Epoch 467/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0379 - acc: 0.4655Epoch 00466: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0398 - acc: 0.4653 - val_loss: 5.8681 - val_acc: 0.4993\n",
      "Epoch 468/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0416 - acc: 0.4650Epoch 00467: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.0401 - acc: 0.4653 - val_loss: 5.8668 - val_acc: 0.4993\n",
      "Epoch 469/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0415 - acc: 0.4654Epoch 00468: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0420 - acc: 0.4653 - val_loss: 5.8657 - val_acc: 0.4993\n",
      "Epoch 470/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0338 - acc: 0.4654Epoch 00469: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.0346 - acc: 0.4653 - val_loss: 5.8642 - val_acc: 0.4993\n",
      "Epoch 471/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0473 - acc: 0.4645Epoch 00470: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.0440 - acc: 0.4653 - val_loss: 5.8635 - val_acc: 0.4993\n",
      "Epoch 472/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0389 - acc: 0.4653Epoch 00471: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.0395 - acc: 0.4653 - val_loss: 5.8624 - val_acc: 0.4993\n",
      "Epoch 473/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0355 - acc: 0.4649Epoch 00472: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.0336 - acc: 0.4653 - val_loss: 5.8613 - val_acc: 0.4993\n",
      "Epoch 474/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0323 - acc: 0.4652Epoch 00473: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.0317 - acc: 0.4653 - val_loss: 5.8600 - val_acc: 0.4993\n",
      "Epoch 475/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0359 - acc: 0.4652Epoch 00474: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.0357 - acc: 0.4653 - val_loss: 5.8587 - val_acc: 0.4993\n",
      "Epoch 476/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0259 - acc: 0.4653Epoch 00475: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0262 - acc: 0.4653 - val_loss: 5.8571 - val_acc: 0.4993\n",
      "Epoch 477/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0229 - acc: 0.4659Epoch 00476: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.0260 - acc: 0.4653 - val_loss: 5.8557 - val_acc: 0.4993\n",
      "Epoch 478/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0304 - acc: 0.4658Epoch 00477: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.0324 - acc: 0.4653 - val_loss: 5.8547 - val_acc: 0.4993\n",
      "Epoch 479/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0271 - acc: 0.4654Epoch 00478: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 180s - loss: 6.0284 - acc: 0.4653 - val_loss: 5.8535 - val_acc: 0.4993\n",
      "Epoch 480/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0307 - acc: 0.4653Epoch 00479: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 6.0309 - acc: 0.4653 - val_loss: 5.8525 - val_acc: 0.4993\n",
      "Epoch 481/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0278 - acc: 0.4654Epoch 00480: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.0286 - acc: 0.4653 - val_loss: 5.8514 - val_acc: 0.4993\n",
      "Epoch 482/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0188 - acc: 0.4651Epoch 00481: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.0173 - acc: 0.4653 - val_loss: 5.8498 - val_acc: 0.4993\n",
      "Epoch 483/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0223 - acc: 0.4653Epoch 00482: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 6.0223 - acc: 0.4653 - val_loss: 5.8488 - val_acc: 0.4993\n",
      "Epoch 484/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0191 - acc: 0.4654Epoch 00483: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 6.0198 - acc: 0.4653 - val_loss: 5.8478 - val_acc: 0.4993\n",
      "Epoch 485/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0297 - acc: 0.4652Epoch 00484: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 6.0294 - acc: 0.4653 - val_loss: 5.8471 - val_acc: 0.4993\n",
      "Epoch 486/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0212 - acc: 0.4652Epoch 00485: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.0204 - acc: 0.4653 - val_loss: 5.8459 - val_acc: 0.4993\n",
      "Epoch 487/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0211 - acc: 0.4656Epoch 00486: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.0225 - acc: 0.4653 - val_loss: 5.8450 - val_acc: 0.4993\n",
      "Epoch 488/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0180 - acc: 0.4653Epoch 00487: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 6.0176 - acc: 0.4653 - val_loss: 5.8437 - val_acc: 0.4993\n",
      "Epoch 489/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0182 - acc: 0.4655Epoch 00488: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 6.0184 - acc: 0.4653 - val_loss: 5.8426 - val_acc: 0.4993\n",
      "Epoch 490/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0141 - acc: 0.4655Epoch 00489: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 6.0159 - acc: 0.4653 - val_loss: 5.8414 - val_acc: 0.4993\n",
      "Epoch 491/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0241 - acc: 0.4652Epoch 00490: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.0242 - acc: 0.4653 - val_loss: 5.8407 - val_acc: 0.4993\n",
      "Epoch 492/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0162 - acc: 0.4651Epoch 00491: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 6.0157 - acc: 0.4653 - val_loss: 5.8398 - val_acc: 0.4993\n",
      "Epoch 493/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0069 - acc: 0.4657Epoch 00492: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 6.0090 - acc: 0.4653 - val_loss: 5.8386 - val_acc: 0.4993\n",
      "Epoch 494/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0114 - acc: 0.4658Epoch 00493: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 6.0144 - acc: 0.4653 - val_loss: 5.8374 - val_acc: 0.4993\n",
      "Epoch 495/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0053 - acc: 0.4657Epoch 00494: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 6.0075 - acc: 0.4653 - val_loss: 5.8360 - val_acc: 0.4993\n",
      "Epoch 496/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0127 - acc: 0.4653Epoch 00495: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 6.0131 - acc: 0.4653 - val_loss: 5.8350 - val_acc: 0.4993\n",
      "Epoch 497/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0090 - acc: 0.4656Epoch 00496: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 6.0110 - acc: 0.4653 - val_loss: 5.8339 - val_acc: 0.4993\n",
      "Epoch 498/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0033 - acc: 0.4656Epoch 00497: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 6.0053 - acc: 0.4653 - val_loss: 5.8328 - val_acc: 0.4993\n",
      "Epoch 499/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0045 - acc: 0.4655Epoch 00498: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.0055 - acc: 0.4653 - val_loss: 5.8317 - val_acc: 0.4993\n",
      "Epoch 500/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0018 - acc: 0.4656Epoch 00499: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 6.0035 - acc: 0.4653 - val_loss: 5.8306 - val_acc: 0.4993\n",
      "Epoch 501/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0122 - acc: 0.4652Epoch 00500: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.0122 - acc: 0.4653 - val_loss: 5.8298 - val_acc: 0.4993\n",
      "Epoch 502/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9982 - acc: 0.4656Epoch 00501: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.9999 - acc: 0.4653 - val_loss: 5.8284 - val_acc: 0.4993\n",
      "Epoch 503/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0000 - acc: 0.4656Epoch 00502: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 6.0020 - acc: 0.4653 - val_loss: 5.8274 - val_acc: 0.4993\n",
      "Epoch 504/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9985 - acc: 0.4653Epoch 00503: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9988 - acc: 0.4653 - val_loss: 5.8260 - val_acc: 0.4993\n",
      "Epoch 505/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0067 - acc: 0.4648Epoch 00504: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 6.0042 - acc: 0.4653 - val_loss: 5.8249 - val_acc: 0.4993\n",
      "Epoch 506/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 6.0013 - acc: 0.4650Epoch 00505: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9993 - acc: 0.4653 - val_loss: 5.8240 - val_acc: 0.4993\n",
      "Epoch 507/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9971 - acc: 0.4652Epoch 00506: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9965 - acc: 0.4653 - val_loss: 5.8227 - val_acc: 0.4993\n",
      "Epoch 508/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9970 - acc: 0.4653Epoch 00507: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 182s - loss: 5.9972 - acc: 0.4653 - val_loss: 5.8217 - val_acc: 0.4993\n",
      "Epoch 509/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9970 - acc: 0.4652Epoch 00508: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9963 - acc: 0.4653 - val_loss: 5.8207 - val_acc: 0.4993\n",
      "Epoch 510/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9965 - acc: 0.4649Epoch 00509: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.9949 - acc: 0.4653 - val_loss: 5.8193 - val_acc: 0.4993\n",
      "Epoch 511/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9924 - acc: 0.4650Epoch 00510: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9908 - acc: 0.4653 - val_loss: 5.8184 - val_acc: 0.4993\n",
      "Epoch 512/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9907 - acc: 0.4653Epoch 00511: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9903 - acc: 0.4653 - val_loss: 5.8170 - val_acc: 0.4993\n",
      "Epoch 513/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9983 - acc: 0.4653Epoch 00512: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9984 - acc: 0.4653 - val_loss: 5.8163 - val_acc: 0.4993\n",
      "Epoch 514/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9992 - acc: 0.4648Epoch 00513: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9972 - acc: 0.4653 - val_loss: 5.8156 - val_acc: 0.4993\n",
      "Epoch 515/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9920 - acc: 0.4649Epoch 00514: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9902 - acc: 0.4653 - val_loss: 5.8145 - val_acc: 0.4993\n",
      "Epoch 516/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9859 - acc: 0.4654Epoch 00515: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9861 - acc: 0.4653 - val_loss: 5.8131 - val_acc: 0.4993\n",
      "Epoch 517/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9914 - acc: 0.4650Epoch 00516: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9899 - acc: 0.4653 - val_loss: 5.8122 - val_acc: 0.4993\n",
      "Epoch 518/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9846 - acc: 0.4661Epoch 00517: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9891 - acc: 0.4653 - val_loss: 5.8113 - val_acc: 0.4993\n",
      "Epoch 519/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9852 - acc: 0.4655Epoch 00518: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9862 - acc: 0.4653 - val_loss: 5.8102 - val_acc: 0.4993\n",
      "Epoch 520/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9880 - acc: 0.4650Epoch 00519: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9863 - acc: 0.4653 - val_loss: 5.8094 - val_acc: 0.4993\n",
      "Epoch 521/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9854 - acc: 0.4657Epoch 00520: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9872 - acc: 0.4653 - val_loss: 5.8084 - val_acc: 0.4993\n",
      "Epoch 522/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9874 - acc: 0.4651Epoch 00521: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9861 - acc: 0.4653 - val_loss: 5.8074 - val_acc: 0.4993\n",
      "Epoch 523/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9811 - acc: 0.4655Epoch 00522: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9824 - acc: 0.4653 - val_loss: 5.8062 - val_acc: 0.4993\n",
      "Epoch 524/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9863 - acc: 0.4649Epoch 00523: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9843 - acc: 0.4653 - val_loss: 5.8055 - val_acc: 0.4993\n",
      "Epoch 525/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9832 - acc: 0.4652Epoch 00524: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9827 - acc: 0.4653 - val_loss: 5.8046 - val_acc: 0.4993\n",
      "Epoch 526/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9781 - acc: 0.4648Epoch 00525: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9759 - acc: 0.4653 - val_loss: 5.8035 - val_acc: 0.4993\n",
      "Epoch 527/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9665 - acc: 0.4660Epoch 00526: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9697 - acc: 0.4653 - val_loss: 5.8018 - val_acc: 0.4993\n",
      "Epoch 528/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9733 - acc: 0.4653Epoch 00527: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9733 - acc: 0.4653 - val_loss: 5.8006 - val_acc: 0.4993\n",
      "Epoch 529/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9783 - acc: 0.4648Epoch 00528: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9757 - acc: 0.4653 - val_loss: 5.8000 - val_acc: 0.4993\n",
      "Epoch 530/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9759 - acc: 0.4652Epoch 00529: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.9751 - acc: 0.4653 - val_loss: 5.7993 - val_acc: 0.4993\n",
      "Epoch 531/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9730 - acc: 0.4654Epoch 00530: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9733 - acc: 0.4653 - val_loss: 5.7982 - val_acc: 0.4993\n",
      "Epoch 532/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9660 - acc: 0.4659Epoch 00531: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9696 - acc: 0.4653 - val_loss: 5.7972 - val_acc: 0.4993\n",
      "Epoch 533/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9696 - acc: 0.4651Epoch 00532: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9693 - acc: 0.4653 - val_loss: 5.7961 - val_acc: 0.4993\n",
      "Epoch 534/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9700 - acc: 0.4655Epoch 00533: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9716 - acc: 0.4653 - val_loss: 5.7952 - val_acc: 0.4993\n",
      "Epoch 535/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9703 - acc: 0.4651Epoch 00534: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.9693 - acc: 0.4653 - val_loss: 5.7941 - val_acc: 0.4993\n",
      "Epoch 536/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9606 - acc: 0.4651Epoch 00535: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.9601 - acc: 0.4653 - val_loss: 5.7929 - val_acc: 0.4993\n",
      "Epoch 537/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9690 - acc: 0.4653Epoch 00536: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 179s - loss: 5.9696 - acc: 0.4653 - val_loss: 5.7920 - val_acc: 0.4993\n",
      "Epoch 538/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9594 - acc: 0.4655Epoch 00537: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9610 - acc: 0.4653 - val_loss: 5.7908 - val_acc: 0.4993\n",
      "Epoch 539/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9666 - acc: 0.4646Epoch 00538: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9627 - acc: 0.4653 - val_loss: 5.7898 - val_acc: 0.4993\n",
      "Epoch 540/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9618 - acc: 0.4656Epoch 00539: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9634 - acc: 0.4653 - val_loss: 5.7889 - val_acc: 0.4993\n",
      "Epoch 541/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9614 - acc: 0.4656Epoch 00540: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9638 - acc: 0.4653 - val_loss: 5.7880 - val_acc: 0.4993\n",
      "Epoch 542/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9683 - acc: 0.4655Epoch 00541: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9697 - acc: 0.4653 - val_loss: 5.7873 - val_acc: 0.4993\n",
      "Epoch 543/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9589 - acc: 0.4655Epoch 00542: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9602 - acc: 0.4653 - val_loss: 5.7865 - val_acc: 0.4993\n",
      "Epoch 544/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9643 - acc: 0.4651Epoch 00543: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9637 - acc: 0.4653 - val_loss: 5.7857 - val_acc: 0.4993\n",
      "Epoch 545/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9621 - acc: 0.4650Epoch 00544: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.9606 - acc: 0.4653 - val_loss: 5.7849 - val_acc: 0.4993\n",
      "Epoch 546/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9579 - acc: 0.4644Epoch 00545: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.9536 - acc: 0.4653 - val_loss: 5.7835 - val_acc: 0.4993\n",
      "Epoch 547/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9603 - acc: 0.4645Epoch 00546: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.9562 - acc: 0.4653 - val_loss: 5.7826 - val_acc: 0.4993\n",
      "Epoch 548/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9528 - acc: 0.4646Epoch 00547: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9494 - acc: 0.4653 - val_loss: 5.7813 - val_acc: 0.4993\n",
      "Epoch 549/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9554 - acc: 0.4647Epoch 00548: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9523 - acc: 0.4653 - val_loss: 5.7804 - val_acc: 0.4993\n",
      "Epoch 550/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9519 - acc: 0.4653Epoch 00549: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.9518 - acc: 0.4653 - val_loss: 5.7794 - val_acc: 0.4993\n",
      "Epoch 551/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9597 - acc: 0.4649Epoch 00550: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.9582 - acc: 0.4652 - val_loss: 5.7789 - val_acc: 0.4993\n",
      "Epoch 552/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9561 - acc: 0.4654Epoch 00551: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 5.9568 - acc: 0.4653 - val_loss: 5.7782 - val_acc: 0.4993\n",
      "Epoch 553/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9510 - acc: 0.4648Epoch 00552: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 209s - loss: 5.9490 - acc: 0.4653 - val_loss: 5.7770 - val_acc: 0.4993\n",
      "Epoch 554/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9456 - acc: 0.4653Epoch 00553: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.9470 - acc: 0.4653 - val_loss: 5.7760 - val_acc: 0.4993\n",
      "Epoch 555/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9554 - acc: 0.4645Epoch 00554: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.9517 - acc: 0.4653 - val_loss: 5.7752 - val_acc: 0.4993\n",
      "Epoch 556/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9520 - acc: 0.4652Epoch 00555: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9518 - acc: 0.4653 - val_loss: 5.7745 - val_acc: 0.4993\n",
      "Epoch 557/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9419 - acc: 0.4652Epoch 00556: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 210s - loss: 5.9418 - acc: 0.4653 - val_loss: 5.7731 - val_acc: 0.4993\n",
      "Epoch 558/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9437 - acc: 0.4651Epoch 00557: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 216s - loss: 5.9423 - acc: 0.4653 - val_loss: 5.7721 - val_acc: 0.4993\n",
      "Epoch 559/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9492 - acc: 0.4654Epoch 00558: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.9495 - acc: 0.4653 - val_loss: 5.7712 - val_acc: 0.4993\n",
      "Epoch 560/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9410 - acc: 0.4653Epoch 00559: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.9413 - acc: 0.4653 - val_loss: 5.7701 - val_acc: 0.4993\n",
      "Epoch 561/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9451 - acc: 0.4652Epoch 00560: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.9457 - acc: 0.4653 - val_loss: 5.7692 - val_acc: 0.4993\n",
      "Epoch 562/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9421 - acc: 0.4652Epoch 00561: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 5.9415 - acc: 0.4653 - val_loss: 5.7685 - val_acc: 0.4993\n",
      "Epoch 563/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9394 - acc: 0.4655Epoch 00562: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 5.9408 - acc: 0.4653 - val_loss: 5.7675 - val_acc: 0.4993\n",
      "Epoch 564/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9444 - acc: 0.4655Epoch 00563: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9458 - acc: 0.4653 - val_loss: 5.7667 - val_acc: 0.4993\n",
      "Epoch 565/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9322 - acc: 0.4654Epoch 00564: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.9326 - acc: 0.4653 - val_loss: 5.7656 - val_acc: 0.4993\n",
      "Epoch 566/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9361 - acc: 0.4656Epoch 00565: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 184s - loss: 5.9379 - acc: 0.4653 - val_loss: 5.7648 - val_acc: 0.4993\n",
      "Epoch 567/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9397 - acc: 0.4650Epoch 00566: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.9376 - acc: 0.4653 - val_loss: 5.7639 - val_acc: 0.4993\n",
      "Epoch 568/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9401 - acc: 0.4655Epoch 00567: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 211s - loss: 5.9418 - acc: 0.4653 - val_loss: 5.7633 - val_acc: 0.4993\n",
      "Epoch 569/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9410 - acc: 0.4646Epoch 00568: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.9371 - acc: 0.4653 - val_loss: 5.7626 - val_acc: 0.4993\n",
      "Epoch 570/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9380 - acc: 0.4645Epoch 00569: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 209s - loss: 5.9338 - acc: 0.4653 - val_loss: 5.7617 - val_acc: 0.4993\n",
      "Epoch 571/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9321 - acc: 0.4656Epoch 00570: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 206s - loss: 5.9340 - acc: 0.4653 - val_loss: 5.7607 - val_acc: 0.4993\n",
      "Epoch 572/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9370 - acc: 0.4653Epoch 00571: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.9369 - acc: 0.4653 - val_loss: 5.7602 - val_acc: 0.4993\n",
      "Epoch 573/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9254 - acc: 0.4656Epoch 00572: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 212s - loss: 5.9278 - acc: 0.4653 - val_loss: 5.7589 - val_acc: 0.4993\n",
      "Epoch 574/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9327 - acc: 0.4654Epoch 00573: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 210s - loss: 5.9337 - acc: 0.4653 - val_loss: 5.7581 - val_acc: 0.4993\n",
      "Epoch 575/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9319 - acc: 0.4653Epoch 00574: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 202s - loss: 5.9324 - acc: 0.4653 - val_loss: 5.7574 - val_acc: 0.4993\n",
      "Epoch 576/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9292 - acc: 0.4655Epoch 00575: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.9303 - acc: 0.4653 - val_loss: 5.7564 - val_acc: 0.4993\n",
      "Epoch 577/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9317 - acc: 0.4646Epoch 00576: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.9284 - acc: 0.4653 - val_loss: 5.7553 - val_acc: 0.4993\n",
      "Epoch 578/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9247 - acc: 0.4652Epoch 00577: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.9241 - acc: 0.4653 - val_loss: 5.7544 - val_acc: 0.4993\n",
      "Epoch 579/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9347 - acc: 0.4650Epoch 00578: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9334 - acc: 0.4652 - val_loss: 5.7535 - val_acc: 0.4993\n",
      "Epoch 580/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9313 - acc: 0.4647Epoch 00579: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9282 - acc: 0.4653 - val_loss: 5.7529 - val_acc: 0.4993\n",
      "Epoch 581/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9365 - acc: 0.4647Epoch 00580: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9330 - acc: 0.4653 - val_loss: 5.7526 - val_acc: 0.4993\n",
      "Epoch 582/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9262 - acc: 0.4652Epoch 00581: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.9263 - acc: 0.4653 - val_loss: 5.7513 - val_acc: 0.4993\n",
      "Epoch 583/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9252 - acc: 0.4652Epoch 00582: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.9250 - acc: 0.4653 - val_loss: 5.7505 - val_acc: 0.4993\n",
      "Epoch 584/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9236 - acc: 0.4655Epoch 00583: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.9244 - acc: 0.4653 - val_loss: 5.7498 - val_acc: 0.4993\n",
      "Epoch 585/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9172 - acc: 0.4661Epoch 00584: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.9216 - acc: 0.4653 - val_loss: 5.7488 - val_acc: 0.4993\n",
      "Epoch 586/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9185 - acc: 0.4647Epoch 00585: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.9152 - acc: 0.4653 - val_loss: 5.7475 - val_acc: 0.4993\n",
      "Epoch 587/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9193 - acc: 0.4653Epoch 00586: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9196 - acc: 0.4653 - val_loss: 5.7467 - val_acc: 0.4993\n",
      "Epoch 588/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9168 - acc: 0.4658Epoch 00587: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.9205 - acc: 0.4653 - val_loss: 5.7457 - val_acc: 0.4993\n",
      "Epoch 589/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9190 - acc: 0.4650Epoch 00588: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.9171 - acc: 0.4653 - val_loss: 5.7447 - val_acc: 0.4993\n",
      "Epoch 590/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9125 - acc: 0.4651Epoch 00589: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.9110 - acc: 0.4653 - val_loss: 5.7437 - val_acc: 0.4993\n",
      "Epoch 591/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9158 - acc: 0.4655Epoch 00590: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.9164 - acc: 0.4653 - val_loss: 5.7427 - val_acc: 0.4993\n",
      "Epoch 592/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9157 - acc: 0.4654Epoch 00591: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 5.9168 - acc: 0.4653 - val_loss: 5.7419 - val_acc: 0.4993\n",
      "Epoch 593/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9098 - acc: 0.4656Epoch 00592: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 211s - loss: 5.9115 - acc: 0.4653 - val_loss: 5.7411 - val_acc: 0.4993\n",
      "Epoch 594/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9159 - acc: 0.4658Epoch 00593: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 203s - loss: 5.9191 - acc: 0.4653 - val_loss: 5.7404 - val_acc: 0.4993\n",
      "Epoch 595/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9149 - acc: 0.4649Epoch 00594: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 200s - loss: 5.9132 - acc: 0.4653 - val_loss: 5.7397 - val_acc: 0.4993\n",
      "Epoch 596/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9067 - acc: 0.4657Epoch 00595: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.9090 - acc: 0.4653 - val_loss: 5.7388 - val_acc: 0.4993\n",
      "Epoch 597/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9093 - acc: 0.4648Epoch 00596: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9072 - acc: 0.4653 - val_loss: 5.7378 - val_acc: 0.4993\n",
      "Epoch 598/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9045 - acc: 0.4664Epoch 00597: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9101 - acc: 0.4653 - val_loss: 5.7370 - val_acc: 0.4993\n",
      "Epoch 599/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9177 - acc: 0.4654Epoch 00598: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9184 - acc: 0.4653 - val_loss: 5.7367 - val_acc: 0.4993\n",
      "Epoch 600/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9102 - acc: 0.4659Epoch 00599: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9134 - acc: 0.4653 - val_loss: 5.7358 - val_acc: 0.4993\n",
      "Epoch 601/2000\n",
      "758/760 [============================>.] - ETA: 4s - loss: 5.9119 - acc: 0.4646Epoch 00600: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1776s - loss: 5.9094 - acc: 0.4653 - val_loss: 5.7349 - val_acc: 0.4993\n",
      "Epoch 602/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9102 - acc: 0.4653Epoch 00601: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.9103 - acc: 0.4653 - val_loss: 5.7340 - val_acc: 0.4993\n",
      "Epoch 603/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9011 - acc: 0.4653Epoch 00602: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.9017 - acc: 0.4653 - val_loss: 5.7328 - val_acc: 0.4993\n",
      "Epoch 604/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9118 - acc: 0.4647Epoch 00603: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.9089 - acc: 0.4653 - val_loss: 5.7322 - val_acc: 0.4993\n",
      "Epoch 605/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9106 - acc: 0.4648Epoch 00604: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.9085 - acc: 0.4653 - val_loss: 5.7316 - val_acc: 0.4993\n",
      "Epoch 606/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8997 - acc: 0.4652Epoch 00605: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 213s - loss: 5.8994 - acc: 0.4653 - val_loss: 5.7305 - val_acc: 0.4993\n",
      "Epoch 607/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9048 - acc: 0.4652Epoch 00606: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.9044 - acc: 0.4653 - val_loss: 5.7298 - val_acc: 0.4993\n",
      "Epoch 608/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8965 - acc: 0.4650Epoch 00607: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8946 - acc: 0.4653 - val_loss: 5.7289 - val_acc: 0.4993\n",
      "Epoch 609/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9027 - acc: 0.4648Epoch 00608: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9001 - acc: 0.4653 - val_loss: 5.7280 - val_acc: 0.4993\n",
      "Epoch 610/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8937 - acc: 0.4657Epoch 00609: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8963 - acc: 0.4653 - val_loss: 5.7272 - val_acc: 0.4993\n",
      "Epoch 611/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9052 - acc: 0.4651Epoch 00610: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.9041 - acc: 0.4653 - val_loss: 5.7264 - val_acc: 0.4993\n",
      "Epoch 612/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.9002 - acc: 0.4650Epoch 00611: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8999 - acc: 0.4652 - val_loss: 5.7256 - val_acc: 0.4993\n",
      "Epoch 613/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8955 - acc: 0.4653Epoch 00612: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.8952 - acc: 0.4653 - val_loss: 5.7247 - val_acc: 0.4993\n",
      "Epoch 614/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8926 - acc: 0.4654Epoch 00613: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8928 - acc: 0.4653 - val_loss: 5.7238 - val_acc: 0.4993\n",
      "Epoch 615/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8983 - acc: 0.4649Epoch 00614: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8960 - acc: 0.4653 - val_loss: 5.7229 - val_acc: 0.4993\n",
      "Epoch 616/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8975 - acc: 0.4649Epoch 00615: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8975 - acc: 0.4653 - val_loss: 5.7224 - val_acc: 0.4993\n",
      "Epoch 617/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8981 - acc: 0.4654Epoch 00616: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8988 - acc: 0.4653 - val_loss: 5.7218 - val_acc: 0.4993\n",
      "Epoch 618/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8958 - acc: 0.4653Epoch 00617: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8961 - acc: 0.4653 - val_loss: 5.7211 - val_acc: 0.4993\n",
      "Epoch 619/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8912 - acc: 0.4653Epoch 00618: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8914 - acc: 0.4653 - val_loss: 5.7203 - val_acc: 0.4993\n",
      "Epoch 620/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8869 - acc: 0.4656Epoch 00619: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8884 - acc: 0.4653 - val_loss: 5.7193 - val_acc: 0.4993\n",
      "Epoch 621/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8904 - acc: 0.4656Epoch 00620: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8920 - acc: 0.4653 - val_loss: 5.7185 - val_acc: 0.4993\n",
      "Epoch 622/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8910 - acc: 0.4649Epoch 00621: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8890 - acc: 0.4653 - val_loss: 5.7177 - val_acc: 0.4993\n",
      "Epoch 623/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8938 - acc: 0.4654Epoch 00622: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8953 - acc: 0.4653 - val_loss: 5.7173 - val_acc: 0.4993\n",
      "Epoch 624/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8803 - acc: 0.4656Epoch 00623: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 180s - loss: 5.8821 - acc: 0.4653 - val_loss: 5.7161 - val_acc: 0.4993\n",
      "Epoch 625/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8864 - acc: 0.4659Epoch 00624: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8894 - acc: 0.4653 - val_loss: 5.7155 - val_acc: 0.4993\n",
      "Epoch 626/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8894 - acc: 0.4654Epoch 00625: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8903 - acc: 0.4653 - val_loss: 5.7147 - val_acc: 0.4993\n",
      "Epoch 627/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8821 - acc: 0.4651Epoch 00626: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8812 - acc: 0.4653 - val_loss: 5.7136 - val_acc: 0.4993\n",
      "Epoch 628/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8861 - acc: 0.4651Epoch 00627: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.8847 - acc: 0.4653 - val_loss: 5.7129 - val_acc: 0.4993\n",
      "Epoch 629/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8873 - acc: 0.4653Epoch 00628: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8875 - acc: 0.4653 - val_loss: 5.7126 - val_acc: 0.4993\n",
      "Epoch 630/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8911 - acc: 0.4653Epoch 00629: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8917 - acc: 0.4653 - val_loss: 5.7121 - val_acc: 0.4993\n",
      "Epoch 631/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8836 - acc: 0.4654Epoch 00630: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8849 - acc: 0.4653 - val_loss: 5.7114 - val_acc: 0.4993\n",
      "Epoch 632/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8829 - acc: 0.4651Epoch 00631: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8822 - acc: 0.4653 - val_loss: 5.7102 - val_acc: 0.4993\n",
      "Epoch 633/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8788 - acc: 0.4654Epoch 00632: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8799 - acc: 0.4653 - val_loss: 5.7094 - val_acc: 0.4993\n",
      "Epoch 634/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8823 - acc: 0.4645Epoch 00633: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8786 - acc: 0.4653 - val_loss: 5.7085 - val_acc: 0.4993\n",
      "Epoch 635/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8744 - acc: 0.4653Epoch 00634: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8749 - acc: 0.4653 - val_loss: 5.7078 - val_acc: 0.4993\n",
      "Epoch 636/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8825 - acc: 0.4651Epoch 00635: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8825 - acc: 0.4653 - val_loss: 5.7070 - val_acc: 0.4993\n",
      "Epoch 637/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8726 - acc: 0.4657Epoch 00636: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8747 - acc: 0.4653 - val_loss: 5.7061 - val_acc: 0.4993\n",
      "Epoch 638/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8867 - acc: 0.4650Epoch 00637: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8853 - acc: 0.4653 - val_loss: 5.7057 - val_acc: 0.4993\n",
      "Epoch 639/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8744 - acc: 0.4654Epoch 00638: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8748 - acc: 0.4653 - val_loss: 5.7050 - val_acc: 0.4993\n",
      "Epoch 640/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8721 - acc: 0.4656Epoch 00639: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.8739 - acc: 0.4653 - val_loss: 5.7043 - val_acc: 0.4993\n",
      "Epoch 641/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8714 - acc: 0.4656Epoch 00640: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8734 - acc: 0.4653 - val_loss: 5.7035 - val_acc: 0.4993\n",
      "Epoch 642/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8762 - acc: 0.4648Epoch 00641: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8736 - acc: 0.4653 - val_loss: 5.7028 - val_acc: 0.4993\n",
      "Epoch 643/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8741 - acc: 0.4650Epoch 00642: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8726 - acc: 0.4653 - val_loss: 5.7019 - val_acc: 0.4993\n",
      "Epoch 644/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8753 - acc: 0.4648Epoch 00643: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8729 - acc: 0.4653 - val_loss: 5.7009 - val_acc: 0.4993\n",
      "Epoch 645/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8664 - acc: 0.4657Epoch 00644: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8692 - acc: 0.4653 - val_loss: 5.7000 - val_acc: 0.4993\n",
      "Epoch 646/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8680 - acc: 0.4647Epoch 00645: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8647 - acc: 0.4653 - val_loss: 5.6990 - val_acc: 0.4993\n",
      "Epoch 647/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8709 - acc: 0.4647Epoch 00646: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.8680 - acc: 0.4653 - val_loss: 5.6984 - val_acc: 0.4993\n",
      "Epoch 648/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8683 - acc: 0.4654Epoch 00647: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.8693 - acc: 0.4653 - val_loss: 5.6976 - val_acc: 0.4993\n",
      "Epoch 649/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8796 - acc: 0.4650Epoch 00648: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.8783 - acc: 0.4653 - val_loss: 5.6972 - val_acc: 0.4993\n",
      "Epoch 650/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8652 - acc: 0.4650Epoch 00649: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.8641 - acc: 0.4653 - val_loss: 5.6964 - val_acc: 0.4993\n",
      "Epoch 651/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8750 - acc: 0.4654Epoch 00650: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.8756 - acc: 0.4653 - val_loss: 5.6959 - val_acc: 0.4993\n",
      "Epoch 652/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8731 - acc: 0.4650Epoch 00651: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.8716 - acc: 0.4653 - val_loss: 5.6951 - val_acc: 0.4993\n",
      "Epoch 653/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8569 - acc: 0.4661Epoch 00652: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 194s - loss: 5.8613 - acc: 0.4653 - val_loss: 5.6942 - val_acc: 0.4993\n",
      "Epoch 654/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8640 - acc: 0.4649Epoch 00653: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.8626 - acc: 0.4653 - val_loss: 5.6932 - val_acc: 0.4993\n",
      "Epoch 655/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8599 - acc: 0.4654Epoch 00654: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.8608 - acc: 0.4653 - val_loss: 5.6926 - val_acc: 0.4993\n",
      "Epoch 656/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8648 - acc: 0.4649Epoch 00655: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.8627 - acc: 0.4653 - val_loss: 5.6920 - val_acc: 0.4993\n",
      "Epoch 657/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8672 - acc: 0.4655Epoch 00656: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.8688 - acc: 0.4653 - val_loss: 5.6915 - val_acc: 0.4993\n",
      "Epoch 658/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8664 - acc: 0.4650Epoch 00657: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.8648 - acc: 0.4653 - val_loss: 5.6909 - val_acc: 0.4993\n",
      "Epoch 659/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8696 - acc: 0.4653Epoch 00658: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.8700 - acc: 0.4653 - val_loss: 5.6905 - val_acc: 0.4993\n",
      "Epoch 660/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8535 - acc: 0.4654Epoch 00659: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.8544 - acc: 0.4653 - val_loss: 5.6895 - val_acc: 0.4993\n",
      "Epoch 661/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8558 - acc: 0.4654Epoch 00660: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8561 - acc: 0.4653 - val_loss: 5.6887 - val_acc: 0.4993\n",
      "Epoch 662/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8529 - acc: 0.4654Epoch 00661: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8541 - acc: 0.4653 - val_loss: 5.6881 - val_acc: 0.4993\n",
      "Epoch 663/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8591 - acc: 0.4655Epoch 00662: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.8603 - acc: 0.4653 - val_loss: 5.6876 - val_acc: 0.4993\n",
      "Epoch 664/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8554 - acc: 0.4654Epoch 00663: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8562 - acc: 0.4653 - val_loss: 5.6868 - val_acc: 0.4993\n",
      "Epoch 665/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8667 - acc: 0.4650Epoch 00664: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.8651 - acc: 0.4653 - val_loss: 5.6864 - val_acc: 0.4993\n",
      "Epoch 666/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8555 - acc: 0.4653Epoch 00665: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.8548 - acc: 0.4653 - val_loss: 5.6856 - val_acc: 0.4993\n",
      "Epoch 667/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8591 - acc: 0.4654Epoch 00666: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.8596 - acc: 0.4653 - val_loss: 5.6850 - val_acc: 0.4993\n",
      "Epoch 668/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8609 - acc: 0.4650Epoch 00667: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 204s - loss: 5.8596 - acc: 0.4653 - val_loss: 5.6843 - val_acc: 0.4993\n",
      "Epoch 669/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8542 - acc: 0.4652Epoch 00668: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 208s - loss: 5.8538 - acc: 0.4653 - val_loss: 5.6836 - val_acc: 0.4993\n",
      "Epoch 670/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8538 - acc: 0.4647Epoch 00669: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.8508 - acc: 0.4653 - val_loss: 5.6828 - val_acc: 0.4993\n",
      "Epoch 671/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8544 - acc: 0.4656Epoch 00670: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.8558 - acc: 0.4653 - val_loss: 5.6822 - val_acc: 0.4993\n",
      "Epoch 672/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8486 - acc: 0.4654Epoch 00671: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 201s - loss: 5.8494 - acc: 0.4653 - val_loss: 5.6816 - val_acc: 0.4993\n",
      "Epoch 673/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8492 - acc: 0.4651Epoch 00672: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.8488 - acc: 0.4653 - val_loss: 5.6809 - val_acc: 0.4993\n",
      "Epoch 674/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8508 - acc: 0.4657Epoch 00673: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.8532 - acc: 0.4653 - val_loss: 5.6802 - val_acc: 0.4993\n",
      "Epoch 675/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8499 - acc: 0.4655Epoch 00674: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.8516 - acc: 0.4653 - val_loss: 5.6795 - val_acc: 0.4993\n",
      "Epoch 676/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8490 - acc: 0.4648Epoch 00675: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.8468 - acc: 0.4653 - val_loss: 5.6788 - val_acc: 0.4993\n",
      "Epoch 677/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8450 - acc: 0.4658Epoch 00676: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.8486 - acc: 0.4653 - val_loss: 5.6782 - val_acc: 0.4993\n",
      "Epoch 678/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8558 - acc: 0.4653Epoch 00677: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.8562 - acc: 0.4653 - val_loss: 5.6779 - val_acc: 0.4993\n",
      "Epoch 679/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8468 - acc: 0.4652Epoch 00678: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.8463 - acc: 0.4653 - val_loss: 5.6768 - val_acc: 0.4993\n",
      "Epoch 680/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8423 - acc: 0.4655Epoch 00679: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.8433 - acc: 0.4653 - val_loss: 5.6760 - val_acc: 0.4993\n",
      "Epoch 681/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8423 - acc: 0.4656Epoch 00680: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.8441 - acc: 0.4653 - val_loss: 5.6755 - val_acc: 0.4993\n",
      "Epoch 682/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8429 - acc: 0.4655Epoch 00681: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 191s - loss: 5.8436 - acc: 0.4653 - val_loss: 5.6747 - val_acc: 0.4993\n",
      "Epoch 683/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8426 - acc: 0.4653Epoch 00682: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8428 - acc: 0.4653 - val_loss: 5.6739 - val_acc: 0.4993\n",
      "Epoch 684/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8421 - acc: 0.4648Epoch 00683: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8398 - acc: 0.4653 - val_loss: 5.6732 - val_acc: 0.4993\n",
      "Epoch 685/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8386 - acc: 0.4655Epoch 00684: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8404 - acc: 0.4653 - val_loss: 5.6724 - val_acc: 0.4993\n",
      "Epoch 686/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8410 - acc: 0.4656Epoch 00685: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8429 - acc: 0.4653 - val_loss: 5.6718 - val_acc: 0.4993\n",
      "Epoch 687/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8428 - acc: 0.4650Epoch 00686: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8407 - acc: 0.4653 - val_loss: 5.6711 - val_acc: 0.4993\n",
      "Epoch 688/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8498 - acc: 0.4651Epoch 00687: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8489 - acc: 0.4653 - val_loss: 5.6706 - val_acc: 0.4993\n",
      "Epoch 689/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8362 - acc: 0.4657Epoch 00688: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8387 - acc: 0.4653 - val_loss: 5.6698 - val_acc: 0.4993\n",
      "Epoch 690/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8468 - acc: 0.4651Epoch 00689: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8459 - acc: 0.4653 - val_loss: 5.6693 - val_acc: 0.4993\n",
      "Epoch 691/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8401 - acc: 0.4650Epoch 00690: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8386 - acc: 0.4653 - val_loss: 5.6687 - val_acc: 0.4993\n",
      "Epoch 692/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8384 - acc: 0.4653Epoch 00691: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8384 - acc: 0.4653 - val_loss: 5.6681 - val_acc: 0.4993\n",
      "Epoch 693/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8396 - acc: 0.4652Epoch 00692: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8391 - acc: 0.4653 - val_loss: 5.6675 - val_acc: 0.4993\n",
      "Epoch 694/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8347 - acc: 0.4655Epoch 00693: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8357 - acc: 0.4653 - val_loss: 5.6665 - val_acc: 0.4993\n",
      "Epoch 695/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8394 - acc: 0.4651Epoch 00694: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8391 - acc: 0.4653 - val_loss: 5.6660 - val_acc: 0.4993\n",
      "Epoch 696/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8381 - acc: 0.4651Epoch 00695: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8397 - acc: 0.4653 - val_loss: 5.6656 - val_acc: 0.4993\n",
      "Epoch 697/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8379 - acc: 0.4656Epoch 00696: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8401 - acc: 0.4653 - val_loss: 5.6650 - val_acc: 0.4993\n",
      "Epoch 698/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8358 - acc: 0.4654Epoch 00697: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8362 - acc: 0.4653 - val_loss: 5.6642 - val_acc: 0.4993\n",
      "Epoch 699/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8412 - acc: 0.4653Epoch 00698: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8414 - acc: 0.4653 - val_loss: 5.6637 - val_acc: 0.4993\n",
      "Epoch 700/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8308 - acc: 0.4656Epoch 00699: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8335 - acc: 0.4653 - val_loss: 5.6630 - val_acc: 0.4993\n",
      "Epoch 701/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8345 - acc: 0.4654Epoch 00700: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8358 - acc: 0.4653 - val_loss: 5.6626 - val_acc: 0.4993\n",
      "Epoch 702/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8334 - acc: 0.4652Epoch 00701: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8327 - acc: 0.4653 - val_loss: 5.6620 - val_acc: 0.4993\n",
      "Epoch 703/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8396 - acc: 0.4653Epoch 00702: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8399 - acc: 0.4653 - val_loss: 5.6617 - val_acc: 0.4993\n",
      "Epoch 704/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8241 - acc: 0.4655Epoch 00703: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8255 - acc: 0.4653 - val_loss: 5.6606 - val_acc: 0.4993\n",
      "Epoch 705/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8291 - acc: 0.4652Epoch 00704: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8288 - acc: 0.4653 - val_loss: 5.6599 - val_acc: 0.4993\n",
      "Epoch 706/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8244 - acc: 0.4652Epoch 00705: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8240 - acc: 0.4653 - val_loss: 5.6589 - val_acc: 0.4993\n",
      "Epoch 707/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8317 - acc: 0.4649Epoch 00706: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8299 - acc: 0.4653 - val_loss: 5.6584 - val_acc: 0.4993\n",
      "Epoch 708/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8318 - acc: 0.4656Epoch 00707: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8333 - acc: 0.4653 - val_loss: 5.6579 - val_acc: 0.4993\n",
      "Epoch 709/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8301 - acc: 0.4652Epoch 00708: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8291 - acc: 0.4653 - val_loss: 5.6571 - val_acc: 0.4993\n",
      "Epoch 710/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8253 - acc: 0.4655Epoch 00709: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8263 - acc: 0.4653 - val_loss: 5.6564 - val_acc: 0.4993\n",
      "Epoch 711/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8246 - acc: 0.4651Epoch 00710: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 177s - loss: 5.8241 - acc: 0.4653 - val_loss: 5.6556 - val_acc: 0.4993\n",
      "Epoch 712/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8360 - acc: 0.4647Epoch 00711: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8323 - acc: 0.4653 - val_loss: 5.6555 - val_acc: 0.4993\n",
      "Epoch 713/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8203 - acc: 0.4653Epoch 00712: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8202 - acc: 0.4653 - val_loss: 5.6545 - val_acc: 0.4993\n",
      "Epoch 714/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8205 - acc: 0.4656Epoch 00713: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8230 - acc: 0.4653 - val_loss: 5.6540 - val_acc: 0.4993\n",
      "Epoch 715/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8322 - acc: 0.4648Epoch 00714: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8300 - acc: 0.4653 - val_loss: 5.6536 - val_acc: 0.4993\n",
      "Epoch 716/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8283 - acc: 0.4649Epoch 00715: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8260 - acc: 0.4653 - val_loss: 5.6532 - val_acc: 0.4993\n",
      "Epoch 717/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8232 - acc: 0.4651Epoch 00716: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8222 - acc: 0.4653 - val_loss: 5.6525 - val_acc: 0.4993\n",
      "Epoch 718/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8203 - acc: 0.4648Epoch 00717: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8184 - acc: 0.4653 - val_loss: 5.6518 - val_acc: 0.4993\n",
      "Epoch 719/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8308 - acc: 0.4647Epoch 00718: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8279 - acc: 0.4653 - val_loss: 5.6514 - val_acc: 0.4993\n",
      "Epoch 720/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8195 - acc: 0.4659Epoch 00719: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8230 - acc: 0.4653 - val_loss: 5.6510 - val_acc: 0.4993\n",
      "Epoch 721/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8202 - acc: 0.4659Epoch 00720: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8232 - acc: 0.4653 - val_loss: 5.6506 - val_acc: 0.4993\n",
      "Epoch 722/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8180 - acc: 0.4654Epoch 00721: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8185 - acc: 0.4653 - val_loss: 5.6497 - val_acc: 0.4993\n",
      "Epoch 723/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8236 - acc: 0.4649Epoch 00722: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8216 - acc: 0.4653 - val_loss: 5.6492 - val_acc: 0.4993\n",
      "Epoch 724/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8146 - acc: 0.4656Epoch 00723: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8168 - acc: 0.4653 - val_loss: 5.6485 - val_acc: 0.4993\n",
      "Epoch 725/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8145 - acc: 0.4655Epoch 00724: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8163 - acc: 0.4653 - val_loss: 5.6480 - val_acc: 0.4993\n",
      "Epoch 726/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8201 - acc: 0.4651Epoch 00725: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8192 - acc: 0.4653 - val_loss: 5.6474 - val_acc: 0.4993\n",
      "Epoch 727/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8128 - acc: 0.4655Epoch 00726: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8142 - acc: 0.4653 - val_loss: 5.6465 - val_acc: 0.4993\n",
      "Epoch 728/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8133 - acc: 0.4654Epoch 00727: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8143 - acc: 0.4653 - val_loss: 5.6459 - val_acc: 0.4993\n",
      "Epoch 729/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8192 - acc: 0.4653Epoch 00728: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8191 - acc: 0.4653 - val_loss: 5.6454 - val_acc: 0.4993\n",
      "Epoch 730/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8101 - acc: 0.4653Epoch 00729: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8104 - acc: 0.4653 - val_loss: 5.6446 - val_acc: 0.4993\n",
      "Epoch 731/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8162 - acc: 0.4650Epoch 00730: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8150 - acc: 0.4653 - val_loss: 5.6438 - val_acc: 0.4993\n",
      "Epoch 732/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8114 - acc: 0.4649Epoch 00731: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8089 - acc: 0.4653 - val_loss: 5.6428 - val_acc: 0.4993\n",
      "Epoch 733/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8186 - acc: 0.4650Epoch 00732: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8173 - acc: 0.4653 - val_loss: 5.6424 - val_acc: 0.4993\n",
      "Epoch 734/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8139 - acc: 0.4654Epoch 00733: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8153 - acc: 0.4653 - val_loss: 5.6419 - val_acc: 0.4993\n",
      "Epoch 735/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8112 - acc: 0.4651Epoch 00734: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8105 - acc: 0.4653 - val_loss: 5.6412 - val_acc: 0.4993\n",
      "Epoch 736/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8081 - acc: 0.4655Epoch 00735: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8097 - acc: 0.4653 - val_loss: 5.6406 - val_acc: 0.4993\n",
      "Epoch 737/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8139 - acc: 0.4652Epoch 00736: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8136 - acc: 0.4653 - val_loss: 5.6400 - val_acc: 0.4993\n",
      "Epoch 738/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8080 - acc: 0.4657Epoch 00737: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8100 - acc: 0.4653 - val_loss: 5.6395 - val_acc: 0.4993\n",
      "Epoch 739/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8042 - acc: 0.4651Epoch 00738: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8033 - acc: 0.4653 - val_loss: 5.6386 - val_acc: 0.4993\n",
      "Epoch 740/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8081 - acc: 0.4657Epoch 00739: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 177s - loss: 5.8101 - acc: 0.4653 - val_loss: 5.6382 - val_acc: 0.4993\n",
      "Epoch 741/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8024 - acc: 0.4660Epoch 00740: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8064 - acc: 0.4653 - val_loss: 5.6375 - val_acc: 0.4993\n",
      "Epoch 742/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8099 - acc: 0.4649Epoch 00741: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8085 - acc: 0.4653 - val_loss: 5.6372 - val_acc: 0.4993\n",
      "Epoch 743/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8007 - acc: 0.4657Epoch 00742: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.8032 - acc: 0.4653 - val_loss: 5.6363 - val_acc: 0.4993\n",
      "Epoch 744/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8188 - acc: 0.4652Epoch 00743: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.8180 - acc: 0.4653 - val_loss: 5.6361 - val_acc: 0.4993\n",
      "Epoch 745/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8034 - acc: 0.4653Epoch 00744: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8037 - acc: 0.4653 - val_loss: 5.6357 - val_acc: 0.4993\n",
      "Epoch 746/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8078 - acc: 0.4655Epoch 00745: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8088 - acc: 0.4653 - val_loss: 5.6353 - val_acc: 0.4993\n",
      "Epoch 747/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8009 - acc: 0.4652Epoch 00746: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8002 - acc: 0.4653 - val_loss: 5.6345 - val_acc: 0.4993\n",
      "Epoch 748/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8054 - acc: 0.4646Epoch 00747: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8023 - acc: 0.4653 - val_loss: 5.6337 - val_acc: 0.4993\n",
      "Epoch 749/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8000 - acc: 0.4649Epoch 00748: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7983 - acc: 0.4653 - val_loss: 5.6328 - val_acc: 0.4993\n",
      "Epoch 750/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8018 - acc: 0.4655Epoch 00749: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8028 - acc: 0.4653 - val_loss: 5.6325 - val_acc: 0.4993\n",
      "Epoch 751/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8035 - acc: 0.4655Epoch 00750: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8045 - acc: 0.4653 - val_loss: 5.6318 - val_acc: 0.4993\n",
      "Epoch 752/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7973 - acc: 0.4651Epoch 00751: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7965 - acc: 0.4653 - val_loss: 5.6309 - val_acc: 0.4993\n",
      "Epoch 753/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8024 - acc: 0.4654Epoch 00752: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8032 - acc: 0.4653 - val_loss: 5.6305 - val_acc: 0.4993\n",
      "Epoch 754/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8023 - acc: 0.4650Epoch 00753: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.8009 - acc: 0.4653 - val_loss: 5.6298 - val_acc: 0.4993\n",
      "Epoch 755/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8005 - acc: 0.4654Epoch 00754: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8010 - acc: 0.4653 - val_loss: 5.6294 - val_acc: 0.4993\n",
      "Epoch 756/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8012 - acc: 0.4649Epoch 00755: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7992 - acc: 0.4653 - val_loss: 5.6289 - val_acc: 0.4993\n",
      "Epoch 757/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7977 - acc: 0.4651Epoch 00756: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7968 - acc: 0.4653 - val_loss: 5.6284 - val_acc: 0.4993\n",
      "Epoch 758/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7997 - acc: 0.4654Epoch 00757: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.8009 - acc: 0.4653 - val_loss: 5.6278 - val_acc: 0.4993\n",
      "Epoch 759/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7967 - acc: 0.4653Epoch 00758: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7973 - acc: 0.4653 - val_loss: 5.6273 - val_acc: 0.4993\n",
      "Epoch 760/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7924 - acc: 0.4653Epoch 00759: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7923 - acc: 0.4653 - val_loss: 5.6267 - val_acc: 0.4993\n",
      "Epoch 761/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.8000 - acc: 0.4651Epoch 00760: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7991 - acc: 0.4653 - val_loss: 5.6263 - val_acc: 0.4993\n",
      "Epoch 762/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7939 - acc: 0.4649Epoch 00761: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7919 - acc: 0.4653 - val_loss: 5.6256 - val_acc: 0.4993\n",
      "Epoch 763/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7949 - acc: 0.4649Epoch 00762: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7929 - acc: 0.4653 - val_loss: 5.6250 - val_acc: 0.4993\n",
      "Epoch 764/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7964 - acc: 0.4652Epoch 00763: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7961 - acc: 0.4653 - val_loss: 5.6244 - val_acc: 0.4993\n",
      "Epoch 765/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7936 - acc: 0.4656Epoch 00764: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7960 - acc: 0.4653 - val_loss: 5.6239 - val_acc: 0.4993\n",
      "Epoch 766/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7933 - acc: 0.4654Epoch 00765: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7942 - acc: 0.4653 - val_loss: 5.6235 - val_acc: 0.4993\n",
      "Epoch 767/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7907 - acc: 0.4654Epoch 00766: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7917 - acc: 0.4653 - val_loss: 5.6230 - val_acc: 0.4993\n",
      "Epoch 768/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7942 - acc: 0.4648Epoch 00767: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7919 - acc: 0.4653 - val_loss: 5.6225 - val_acc: 0.4993\n",
      "Epoch 769/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7937 - acc: 0.4654Epoch 00768: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 177s - loss: 5.7948 - acc: 0.4653 - val_loss: 5.6219 - val_acc: 0.4993\n",
      "Epoch 770/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7891 - acc: 0.4653Epoch 00769: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7890 - acc: 0.4653 - val_loss: 5.6211 - val_acc: 0.4993\n",
      "Epoch 771/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7861 - acc: 0.4661Epoch 00770: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7905 - acc: 0.4653 - val_loss: 5.6206 - val_acc: 0.4993\n",
      "Epoch 772/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7930 - acc: 0.4652Epoch 00771: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7927 - acc: 0.4653 - val_loss: 5.6201 - val_acc: 0.4993\n",
      "Epoch 773/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7864 - acc: 0.4652Epoch 00772: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7863 - acc: 0.4653 - val_loss: 5.6193 - val_acc: 0.4993\n",
      "Epoch 774/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7870 - acc: 0.4654Epoch 00773: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7877 - acc: 0.4653 - val_loss: 5.6187 - val_acc: 0.4993\n",
      "Epoch 775/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7882 - acc: 0.4651Epoch 00774: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7874 - acc: 0.4653 - val_loss: 5.6181 - val_acc: 0.4993\n",
      "Epoch 776/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7878 - acc: 0.4649Epoch 00775: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7857 - acc: 0.4653 - val_loss: 5.6177 - val_acc: 0.4993\n",
      "Epoch 777/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7839 - acc: 0.4657Epoch 00776: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7865 - acc: 0.4653 - val_loss: 5.6170 - val_acc: 0.4993\n",
      "Epoch 778/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7892 - acc: 0.4654Epoch 00777: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7906 - acc: 0.4653 - val_loss: 5.6166 - val_acc: 0.4993\n",
      "Epoch 779/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7819 - acc: 0.4651Epoch 00778: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7806 - acc: 0.4653 - val_loss: 5.6158 - val_acc: 0.4993\n",
      "Epoch 780/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7834 - acc: 0.4651Epoch 00779: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7827 - acc: 0.4653 - val_loss: 5.6154 - val_acc: 0.4993\n",
      "Epoch 781/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7943 - acc: 0.4651Epoch 00780: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7932 - acc: 0.4652 - val_loss: 5.6150 - val_acc: 0.4993\n",
      "Epoch 782/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7800 - acc: 0.4653Epoch 00781: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7801 - acc: 0.4653 - val_loss: 5.6143 - val_acc: 0.4993\n",
      "Epoch 783/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7859 - acc: 0.4653Epoch 00782: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7861 - acc: 0.4653 - val_loss: 5.6139 - val_acc: 0.4993\n",
      "Epoch 784/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7828 - acc: 0.4648Epoch 00783: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7805 - acc: 0.4653 - val_loss: 5.6133 - val_acc: 0.4993\n",
      "Epoch 785/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7775 - acc: 0.4651Epoch 00784: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7763 - acc: 0.4653 - val_loss: 5.6125 - val_acc: 0.4993\n",
      "Epoch 786/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7797 - acc: 0.4654Epoch 00785: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7803 - acc: 0.4653 - val_loss: 5.6122 - val_acc: 0.4993\n",
      "Epoch 787/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7821 - acc: 0.4654Epoch 00786: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7830 - acc: 0.4653 - val_loss: 5.6119 - val_acc: 0.4993\n",
      "Epoch 788/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7882 - acc: 0.4651Epoch 00787: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7878 - acc: 0.4653 - val_loss: 5.6116 - val_acc: 0.4993\n",
      "Epoch 789/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7905 - acc: 0.4645Epoch 00788: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7862 - acc: 0.4653 - val_loss: 5.6113 - val_acc: 0.4993\n",
      "Epoch 790/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7795 - acc: 0.4652Epoch 00789: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7786 - acc: 0.4653 - val_loss: 5.6109 - val_acc: 0.4993\n",
      "Epoch 791/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7757 - acc: 0.4653Epoch 00790: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7763 - acc: 0.4653 - val_loss: 5.6102 - val_acc: 0.4993\n",
      "Epoch 792/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7781 - acc: 0.4649Epoch 00791: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7762 - acc: 0.4653 - val_loss: 5.6095 - val_acc: 0.4993\n",
      "Epoch 793/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7829 - acc: 0.4652Epoch 00792: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7827 - acc: 0.4653 - val_loss: 5.6090 - val_acc: 0.4993\n",
      "Epoch 794/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7760 - acc: 0.4650Epoch 00793: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7749 - acc: 0.4653 - val_loss: 5.6083 - val_acc: 0.4993\n",
      "Epoch 795/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7796 - acc: 0.4649Epoch 00794: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7775 - acc: 0.4653 - val_loss: 5.6080 - val_acc: 0.4993\n",
      "Epoch 796/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7820 - acc: 0.4650Epoch 00795: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7808 - acc: 0.4653 - val_loss: 5.6075 - val_acc: 0.4993\n",
      "Epoch 797/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7783 - acc: 0.4648Epoch 00796: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7759 - acc: 0.4653 - val_loss: 5.6070 - val_acc: 0.4993\n",
      "Epoch 798/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7706 - acc: 0.4655Epoch 00797: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 176s - loss: 5.7717 - acc: 0.4653 - val_loss: 5.6063 - val_acc: 0.4993\n",
      "Epoch 799/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7788 - acc: 0.4653Epoch 00798: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7789 - acc: 0.4653 - val_loss: 5.6058 - val_acc: 0.4993\n",
      "Epoch 800/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7695 - acc: 0.4655Epoch 00799: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7711 - acc: 0.4653 - val_loss: 5.6051 - val_acc: 0.4993\n",
      "Epoch 801/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7786 - acc: 0.4651Epoch 00800: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7777 - acc: 0.4653 - val_loss: 5.6046 - val_acc: 0.4993\n",
      "Epoch 802/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7730 - acc: 0.4651Epoch 00801: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7726 - acc: 0.4653 - val_loss: 5.6042 - val_acc: 0.4993\n",
      "Epoch 803/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7780 - acc: 0.4648Epoch 00802: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7766 - acc: 0.4650 - val_loss: 5.6038 - val_acc: 0.4993\n",
      "Epoch 804/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7732 - acc: 0.4649Epoch 00803: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7725 - acc: 0.4651 - val_loss: 5.6032 - val_acc: 0.4993\n",
      "Epoch 805/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7708 - acc: 0.4654Epoch 00804: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7716 - acc: 0.4653 - val_loss: 5.6027 - val_acc: 0.4993\n",
      "Epoch 806/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7775 - acc: 0.4650Epoch 00805: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7759 - acc: 0.4653 - val_loss: 5.6021 - val_acc: 0.4993\n",
      "Epoch 807/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7706 - acc: 0.4652Epoch 00806: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7703 - acc: 0.4653 - val_loss: 5.6015 - val_acc: 0.4993\n",
      "Epoch 808/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7718 - acc: 0.4654Epoch 00807: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7725 - acc: 0.4653 - val_loss: 5.6011 - val_acc: 0.4993\n",
      "Epoch 809/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7731 - acc: 0.4653Epoch 00808: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7735 - acc: 0.4653 - val_loss: 5.6006 - val_acc: 0.4993\n",
      "Epoch 810/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7714 - acc: 0.4651Epoch 00809: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7705 - acc: 0.4653 - val_loss: 5.6003 - val_acc: 0.4993\n",
      "Epoch 811/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7738 - acc: 0.4656Epoch 00810: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7758 - acc: 0.4653 - val_loss: 5.6000 - val_acc: 0.4993\n",
      "Epoch 812/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7676 - acc: 0.4655Epoch 00811: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7687 - acc: 0.4653 - val_loss: 5.5995 - val_acc: 0.4993\n",
      "Epoch 813/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7728 - acc: 0.4650Epoch 00812: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7709 - acc: 0.4653 - val_loss: 5.5990 - val_acc: 0.4993\n",
      "Epoch 814/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7697 - acc: 0.4651Epoch 00813: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7692 - acc: 0.4653 - val_loss: 5.5987 - val_acc: 0.4993\n",
      "Epoch 815/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7679 - acc: 0.4650Epoch 00814: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7662 - acc: 0.4653 - val_loss: 5.5980 - val_acc: 0.4993\n",
      "Epoch 816/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7672 - acc: 0.4655Epoch 00815: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7683 - acc: 0.4653 - val_loss: 5.5975 - val_acc: 0.4993\n",
      "Epoch 817/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7540 - acc: 0.4653Epoch 00816: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7539 - acc: 0.4653 - val_loss: 5.5967 - val_acc: 0.4993\n",
      "Epoch 818/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7627 - acc: 0.4651Epoch 00817: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7615 - acc: 0.4653 - val_loss: 5.5960 - val_acc: 0.4993\n",
      "Epoch 819/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7641 - acc: 0.4653Epoch 00818: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7641 - acc: 0.4653 - val_loss: 5.5956 - val_acc: 0.4993\n",
      "Epoch 820/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7683 - acc: 0.4651Epoch 00819: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7677 - acc: 0.4653 - val_loss: 5.5952 - val_acc: 0.4993\n",
      "Epoch 821/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7657 - acc: 0.4653Epoch 00820: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7661 - acc: 0.4653 - val_loss: 5.5947 - val_acc: 0.4993\n",
      "Epoch 822/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7647 - acc: 0.4652Epoch 00821: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7650 - acc: 0.4653 - val_loss: 5.5944 - val_acc: 0.4993\n",
      "Epoch 823/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7598 - acc: 0.4658Epoch 00822: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7623 - acc: 0.4653 - val_loss: 5.5936 - val_acc: 0.4993\n",
      "Epoch 824/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7610 - acc: 0.4652Epoch 00823: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7603 - acc: 0.4653 - val_loss: 5.5933 - val_acc: 0.4993\n",
      "Epoch 825/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7639 - acc: 0.4648Epoch 00824: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7609 - acc: 0.4653 - val_loss: 5.5928 - val_acc: 0.4993\n",
      "Epoch 826/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7693 - acc: 0.4648Epoch 00825: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7666 - acc: 0.4653 - val_loss: 5.5924 - val_acc: 0.4993\n",
      "Epoch 827/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7618 - acc: 0.4656Epoch 00826: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 176s - loss: 5.7642 - acc: 0.4653 - val_loss: 5.5919 - val_acc: 0.4993\n",
      "Epoch 828/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7593 - acc: 0.4651Epoch 00827: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7582 - acc: 0.4653 - val_loss: 5.5913 - val_acc: 0.4993\n",
      "Epoch 829/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7635 - acc: 0.4658Epoch 00828: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7671 - acc: 0.4653 - val_loss: 5.5910 - val_acc: 0.4993\n",
      "Epoch 830/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7650 - acc: 0.4647Epoch 00829: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7625 - acc: 0.4653 - val_loss: 5.5905 - val_acc: 0.4993\n",
      "Epoch 831/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7593 - acc: 0.4654Epoch 00830: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7598 - acc: 0.4653 - val_loss: 5.5902 - val_acc: 0.4993\n",
      "Epoch 832/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7610 - acc: 0.4655Epoch 00831: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7616 - acc: 0.4653 - val_loss: 5.5899 - val_acc: 0.4993\n",
      "Epoch 833/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7588 - acc: 0.4648Epoch 00832: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7570 - acc: 0.4653 - val_loss: 5.5893 - val_acc: 0.4993\n",
      "Epoch 834/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7608 - acc: 0.4646Epoch 00833: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7574 - acc: 0.4653 - val_loss: 5.5890 - val_acc: 0.4993\n",
      "Epoch 835/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7681 - acc: 0.4648Epoch 00834: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7653 - acc: 0.4653 - val_loss: 5.5888 - val_acc: 0.4993\n",
      "Epoch 836/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7580 - acc: 0.4651Epoch 00835: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7579 - acc: 0.4651 - val_loss: 5.5881 - val_acc: 0.4993\n",
      "Epoch 837/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7540 - acc: 0.4653Epoch 00836: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7544 - acc: 0.4653 - val_loss: 5.5874 - val_acc: 0.4993\n",
      "Epoch 838/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7573 - acc: 0.4651Epoch 00837: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7566 - acc: 0.4653 - val_loss: 5.5872 - val_acc: 0.4993\n",
      "Epoch 839/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7535 - acc: 0.4652Epoch 00838: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7535 - acc: 0.4653 - val_loss: 5.5866 - val_acc: 0.4993\n",
      "Epoch 840/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7647 - acc: 0.4650Epoch 00839: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7631 - acc: 0.4653 - val_loss: 5.5864 - val_acc: 0.4993\n",
      "Epoch 841/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7512 - acc: 0.4657Epoch 00840: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7533 - acc: 0.4653 - val_loss: 5.5859 - val_acc: 0.4993\n",
      "Epoch 842/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7617 - acc: 0.4655Epoch 00841: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7623 - acc: 0.4653 - val_loss: 5.5858 - val_acc: 0.4993\n",
      "Epoch 843/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7539 - acc: 0.4652Epoch 00842: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.7536 - acc: 0.4653 - val_loss: 5.5852 - val_acc: 0.4993\n",
      "Epoch 844/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7571 - acc: 0.4652Epoch 00843: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7567 - acc: 0.4653 - val_loss: 5.5851 - val_acc: 0.4993\n",
      "Epoch 845/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7526 - acc: 0.4654Epoch 00844: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7535 - acc: 0.4653 - val_loss: 5.5845 - val_acc: 0.4993\n",
      "Epoch 846/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7572 - acc: 0.4653Epoch 00845: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7576 - acc: 0.4653 - val_loss: 5.5841 - val_acc: 0.4993\n",
      "Epoch 847/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7535 - acc: 0.4648Epoch 00846: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7511 - acc: 0.4653 - val_loss: 5.5835 - val_acc: 0.4993\n",
      "Epoch 848/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7541 - acc: 0.4648Epoch 00847: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7509 - acc: 0.4653 - val_loss: 5.5830 - val_acc: 0.4993\n",
      "Epoch 849/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7570 - acc: 0.4653Epoch 00848: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7574 - acc: 0.4653 - val_loss: 5.5827 - val_acc: 0.4993\n",
      "Epoch 850/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7502 - acc: 0.4650Epoch 00849: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7494 - acc: 0.4653 - val_loss: 5.5823 - val_acc: 0.4993\n",
      "Epoch 851/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7470 - acc: 0.4653Epoch 00850: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7469 - acc: 0.4653 - val_loss: 5.5816 - val_acc: 0.4993\n",
      "Epoch 852/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7471 - acc: 0.4655Epoch 00851: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7482 - acc: 0.4653 - val_loss: 5.5811 - val_acc: 0.4993\n",
      "Epoch 853/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7464 - acc: 0.4651Epoch 00852: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7456 - acc: 0.4653 - val_loss: 5.5805 - val_acc: 0.4993\n",
      "Epoch 854/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7506 - acc: 0.4650Epoch 00853: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7495 - acc: 0.4653 - val_loss: 5.5801 - val_acc: 0.4993\n",
      "Epoch 855/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7493 - acc: 0.4651Epoch 00854: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7481 - acc: 0.4653 - val_loss: 5.5796 - val_acc: 0.4993\n",
      "Epoch 856/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7513 - acc: 0.4651Epoch 00855: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 179s - loss: 5.7503 - acc: 0.4653 - val_loss: 5.5792 - val_acc: 0.4993\n",
      "Epoch 857/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7444 - acc: 0.4651Epoch 00856: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7433 - acc: 0.4653 - val_loss: 5.5786 - val_acc: 0.4993\n",
      "Epoch 858/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7423 - acc: 0.4649Epoch 00857: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7403 - acc: 0.4653 - val_loss: 5.5778 - val_acc: 0.4993\n",
      "Epoch 859/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7492 - acc: 0.4654Epoch 00858: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7500 - acc: 0.4653 - val_loss: 5.5775 - val_acc: 0.4993\n",
      "Epoch 860/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7500 - acc: 0.4651Epoch 00859: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7490 - acc: 0.4653 - val_loss: 5.5770 - val_acc: 0.4993\n",
      "Epoch 861/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7452 - acc: 0.4650Epoch 00860: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7437 - acc: 0.4653 - val_loss: 5.5764 - val_acc: 0.4993\n",
      "Epoch 862/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7503 - acc: 0.4652Epoch 00861: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7504 - acc: 0.4653 - val_loss: 5.5763 - val_acc: 0.4993\n",
      "Epoch 863/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7464 - acc: 0.4651Epoch 00862: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7451 - acc: 0.4653 - val_loss: 5.5757 - val_acc: 0.4993\n",
      "Epoch 864/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7450 - acc: 0.4654Epoch 00863: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7459 - acc: 0.4653 - val_loss: 5.5756 - val_acc: 0.4993\n",
      "Epoch 865/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7391 - acc: 0.4656Epoch 00864: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7407 - acc: 0.4653 - val_loss: 5.5748 - val_acc: 0.4993\n",
      "Epoch 866/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7439 - acc: 0.4650Epoch 00865: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7426 - acc: 0.4653 - val_loss: 5.5745 - val_acc: 0.4993\n",
      "Epoch 867/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7360 - acc: 0.4655Epoch 00866: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7370 - acc: 0.4653 - val_loss: 5.5737 - val_acc: 0.4993\n",
      "Epoch 868/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7463 - acc: 0.4653Epoch 00867: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7464 - acc: 0.4653 - val_loss: 5.5733 - val_acc: 0.4993\n",
      "Epoch 869/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7462 - acc: 0.4651Epoch 00868: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7449 - acc: 0.4653 - val_loss: 5.5731 - val_acc: 0.4993\n",
      "Epoch 870/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7398 - acc: 0.4654Epoch 00869: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7402 - acc: 0.4653 - val_loss: 5.5726 - val_acc: 0.4993\n",
      "Epoch 871/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7416 - acc: 0.4651Epoch 00870: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7406 - acc: 0.4653 - val_loss: 5.5723 - val_acc: 0.4993\n",
      "Epoch 872/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7439 - acc: 0.4652Epoch 00871: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7428 - acc: 0.4653 - val_loss: 5.5718 - val_acc: 0.4993\n",
      "Epoch 873/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7400 - acc: 0.4656Epoch 00872: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7418 - acc: 0.4653 - val_loss: 5.5716 - val_acc: 0.4993\n",
      "Epoch 874/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7360 - acc: 0.4654Epoch 00873: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7368 - acc: 0.4653 - val_loss: 5.5711 - val_acc: 0.4993\n",
      "Epoch 875/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7425 - acc: 0.4646Epoch 00874: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7390 - acc: 0.4653 - val_loss: 5.5706 - val_acc: 0.4993\n",
      "Epoch 876/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7412 - acc: 0.4651Epoch 00875: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7405 - acc: 0.4653 - val_loss: 5.5701 - val_acc: 0.4993\n",
      "Epoch 877/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7366 - acc: 0.4655Epoch 00876: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7382 - acc: 0.4653 - val_loss: 5.5697 - val_acc: 0.4993\n",
      "Epoch 878/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7393 - acc: 0.4648Epoch 00877: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7373 - acc: 0.4653 - val_loss: 5.5692 - val_acc: 0.4993\n",
      "Epoch 879/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7408 - acc: 0.4642Epoch 00878: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7358 - acc: 0.4653 - val_loss: 5.5688 - val_acc: 0.4993\n",
      "Epoch 880/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7429 - acc: 0.4650Epoch 00879: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7411 - acc: 0.4653 - val_loss: 5.5683 - val_acc: 0.4993\n",
      "Epoch 881/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7319 - acc: 0.4652Epoch 00880: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.7312 - acc: 0.4653 - val_loss: 5.5676 - val_acc: 0.4993\n",
      "Epoch 882/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7365 - acc: 0.4651Epoch 00881: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7357 - acc: 0.4653 - val_loss: 5.5670 - val_acc: 0.4993\n",
      "Epoch 883/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7362 - acc: 0.4657Epoch 00882: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7383 - acc: 0.4653 - val_loss: 5.5667 - val_acc: 0.4993\n",
      "Epoch 884/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7326 - acc: 0.4650Epoch 00883: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7310 - acc: 0.4653 - val_loss: 5.5661 - val_acc: 0.4993\n",
      "Epoch 885/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7251 - acc: 0.4658Epoch 00884: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 179s - loss: 5.7279 - acc: 0.4653 - val_loss: 5.5655 - val_acc: 0.4993\n",
      "Epoch 886/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7323 - acc: 0.4654Epoch 00885: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7327 - acc: 0.4653 - val_loss: 5.5651 - val_acc: 0.4993\n",
      "Epoch 887/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7364 - acc: 0.4654Epoch 00886: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7373 - acc: 0.4653 - val_loss: 5.5648 - val_acc: 0.4993\n",
      "Epoch 888/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7368 - acc: 0.4651Epoch 00887: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7361 - acc: 0.4653 - val_loss: 5.5644 - val_acc: 0.4993\n",
      "Epoch 889/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7322 - acc: 0.4652Epoch 00888: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7329 - acc: 0.4653 - val_loss: 5.5640 - val_acc: 0.4993\n",
      "Epoch 890/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7302 - acc: 0.4658Epoch 00889: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7336 - acc: 0.4653 - val_loss: 5.5636 - val_acc: 0.4993\n",
      "Epoch 891/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7376 - acc: 0.4651Epoch 00890: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7370 - acc: 0.4653 - val_loss: 5.5634 - val_acc: 0.4993\n",
      "Epoch 892/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7230 - acc: 0.4658Epoch 00891: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7259 - acc: 0.4653 - val_loss: 5.5627 - val_acc: 0.4993\n",
      "Epoch 893/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7306 - acc: 0.4646Epoch 00892: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7270 - acc: 0.4653 - val_loss: 5.5621 - val_acc: 0.4993\n",
      "Epoch 894/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7296 - acc: 0.4652Epoch 00893: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7295 - acc: 0.4653 - val_loss: 5.5619 - val_acc: 0.4993\n",
      "Epoch 895/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7402 - acc: 0.4655Epoch 00894: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7412 - acc: 0.4653 - val_loss: 5.5618 - val_acc: 0.4993\n",
      "Epoch 896/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7310 - acc: 0.4652Epoch 00895: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7304 - acc: 0.4653 - val_loss: 5.5613 - val_acc: 0.4993\n",
      "Epoch 897/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7308 - acc: 0.4656Epoch 00896: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7325 - acc: 0.4653 - val_loss: 5.5610 - val_acc: 0.4993\n",
      "Epoch 898/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7301 - acc: 0.4656Epoch 00897: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7326 - acc: 0.4653 - val_loss: 5.5607 - val_acc: 0.4993\n",
      "Epoch 899/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7213 - acc: 0.4651Epoch 00898: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7203 - acc: 0.4653 - val_loss: 5.5600 - val_acc: 0.4993\n",
      "Epoch 900/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7257 - acc: 0.4652Epoch 00899: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.7255 - acc: 0.4653 - val_loss: 5.5593 - val_acc: 0.4993\n",
      "Epoch 901/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7308 - acc: 0.4651Epoch 00900: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7294 - acc: 0.4653 - val_loss: 5.5591 - val_acc: 0.4993\n",
      "Epoch 902/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7288 - acc: 0.4648Epoch 00901: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7266 - acc: 0.4653 - val_loss: 5.5586 - val_acc: 0.4993\n",
      "Epoch 903/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7357 - acc: 0.4657Epoch 00902: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7375 - acc: 0.4653 - val_loss: 5.5587 - val_acc: 0.4993\n",
      "Epoch 904/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7187 - acc: 0.4655Epoch 00903: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7208 - acc: 0.4653 - val_loss: 5.5581 - val_acc: 0.4993\n",
      "Epoch 905/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7213 - acc: 0.4661Epoch 00904: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7250 - acc: 0.4653 - val_loss: 5.5576 - val_acc: 0.4993\n",
      "Epoch 906/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7185 - acc: 0.4655Epoch 00905: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7203 - acc: 0.4653 - val_loss: 5.5570 - val_acc: 0.4993\n",
      "Epoch 907/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7308 - acc: 0.4656Epoch 00906: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.7330 - acc: 0.4653 - val_loss: 5.5571 - val_acc: 0.4993\n",
      "Epoch 908/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7232 - acc: 0.4649Epoch 00907: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7215 - acc: 0.4653 - val_loss: 5.5565 - val_acc: 0.4993\n",
      "Epoch 909/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7210 - acc: 0.4656Epoch 00908: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7232 - acc: 0.4653 - val_loss: 5.5559 - val_acc: 0.4993\n",
      "Epoch 910/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7214 - acc: 0.4653Epoch 00909: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7216 - acc: 0.4653 - val_loss: 5.5554 - val_acc: 0.4993\n",
      "Epoch 911/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7275 - acc: 0.4653Epoch 00910: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 5.7278 - acc: 0.4653 - val_loss: 5.5552 - val_acc: 0.4993\n",
      "Epoch 912/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7281 - acc: 0.4648Epoch 00911: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 209s - loss: 5.7248 - acc: 0.4653 - val_loss: 5.5550 - val_acc: 0.4993\n",
      "Epoch 913/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7222 - acc: 0.4650Epoch 00912: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 210s - loss: 5.7209 - acc: 0.4653 - val_loss: 5.5546 - val_acc: 0.4993\n",
      "Epoch 914/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7145 - acc: 0.4656Epoch 00913: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 213s - loss: 5.7161 - acc: 0.4653 - val_loss: 5.5541 - val_acc: 0.4993\n",
      "Epoch 915/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7245 - acc: 0.4647Epoch 00914: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 206s - loss: 5.7217 - acc: 0.4653 - val_loss: 5.5537 - val_acc: 0.4993\n",
      "Epoch 916/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7284 - acc: 0.4648Epoch 00915: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.7258 - acc: 0.4653 - val_loss: 5.5535 - val_acc: 0.4993\n",
      "Epoch 917/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7182 - acc: 0.4651Epoch 00916: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.7170 - acc: 0.4653 - val_loss: 5.5529 - val_acc: 0.4993\n",
      "Epoch 918/2000\n",
      "758/760 [============================>.] - ETA: 4s - loss: 5.7187 - acc: 0.4651Epoch 00917: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1687s - loss: 5.7181 - acc: 0.4653 - val_loss: 5.5523 - val_acc: 0.4993\n",
      "Epoch 919/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7188 - acc: 0.4658Epoch 00918: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.7214 - acc: 0.4653 - val_loss: 5.5520 - val_acc: 0.4993\n",
      "Epoch 920/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7193 - acc: 0.4653Epoch 00919: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.7193 - acc: 0.4653 - val_loss: 5.5517 - val_acc: 0.4993\n",
      "Epoch 921/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7195 - acc: 0.4648Epoch 00920: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7170 - acc: 0.4653 - val_loss: 5.5511 - val_acc: 0.4993\n",
      "Epoch 922/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7218 - acc: 0.4650Epoch 00921: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7204 - acc: 0.4653 - val_loss: 5.5509 - val_acc: 0.4993\n",
      "Epoch 923/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7183 - acc: 0.4655Epoch 00922: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7199 - acc: 0.4653 - val_loss: 5.5506 - val_acc: 0.4993\n",
      "Epoch 924/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7169 - acc: 0.4655Epoch 00923: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.7176 - acc: 0.4653 - val_loss: 5.5500 - val_acc: 0.4993\n",
      "Epoch 925/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7231 - acc: 0.4648Epoch 00924: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.7207 - acc: 0.4653 - val_loss: 5.5496 - val_acc: 0.4993\n",
      "Epoch 926/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7149 - acc: 0.4651Epoch 00925: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.7140 - acc: 0.4653 - val_loss: 5.5491 - val_acc: 0.4993\n",
      "Epoch 927/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7173 - acc: 0.4653Epoch 00926: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 201s - loss: 5.7189 - acc: 0.4651 - val_loss: 5.5489 - val_acc: 0.4993\n",
      "Epoch 928/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7134 - acc: 0.4651Epoch 00927: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.7122 - acc: 0.4653 - val_loss: 5.5484 - val_acc: 0.4993\n",
      "Epoch 929/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7260 - acc: 0.4648Epoch 00928: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 5.7237 - acc: 0.4653 - val_loss: 5.5482 - val_acc: 0.4993\n",
      "Epoch 930/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7171 - acc: 0.4655Epoch 00929: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7180 - acc: 0.4653 - val_loss: 5.5479 - val_acc: 0.4993\n",
      "Epoch 931/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7109 - acc: 0.4655Epoch 00930: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.7123 - acc: 0.4653 - val_loss: 5.5475 - val_acc: 0.4993\n",
      "Epoch 932/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7173 - acc: 0.4655Epoch 00931: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.7180 - acc: 0.4653 - val_loss: 5.5473 - val_acc: 0.4993\n",
      "Epoch 933/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7180 - acc: 0.4656Epoch 00932: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.7201 - acc: 0.4653 - val_loss: 5.5471 - val_acc: 0.4993\n",
      "Epoch 934/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7092 - acc: 0.4654Epoch 00933: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.7102 - acc: 0.4653 - val_loss: 5.5466 - val_acc: 0.4993\n",
      "Epoch 935/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7077 - acc: 0.4654Epoch 00934: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7091 - acc: 0.4653 - val_loss: 5.5460 - val_acc: 0.4993\n",
      "Epoch 936/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7152 - acc: 0.4651Epoch 00935: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.7144 - acc: 0.4653 - val_loss: 5.5458 - val_acc: 0.4993\n",
      "Epoch 937/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7080 - acc: 0.4660Epoch 00936: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.7123 - acc: 0.4653 - val_loss: 5.5454 - val_acc: 0.4993\n",
      "Epoch 938/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7075 - acc: 0.4656Epoch 00937: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.7086 - acc: 0.4653 - val_loss: 5.5449 - val_acc: 0.4993\n",
      "Epoch 939/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7153 - acc: 0.4653Epoch 00938: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.7158 - acc: 0.4653 - val_loss: 5.5445 - val_acc: 0.4993\n",
      "Epoch 940/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7167 - acc: 0.4649Epoch 00939: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7154 - acc: 0.4653 - val_loss: 5.5444 - val_acc: 0.4993\n",
      "Epoch 941/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7147 - acc: 0.4645Epoch 00940: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.7111 - acc: 0.4653 - val_loss: 5.5441 - val_acc: 0.4993\n",
      "Epoch 942/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7110 - acc: 0.4653Epoch 00941: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.7109 - acc: 0.4653 - val_loss: 5.5436 - val_acc: 0.4993\n",
      "Epoch 943/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7109 - acc: 0.4650Epoch 00942: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 186s - loss: 5.7094 - acc: 0.4653 - val_loss: 5.5433 - val_acc: 0.4993\n",
      "Epoch 944/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7050 - acc: 0.4656Epoch 00943: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7063 - acc: 0.4653 - val_loss: 5.5429 - val_acc: 0.4993\n",
      "Epoch 945/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7133 - acc: 0.4647Epoch 00944: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7098 - acc: 0.4653 - val_loss: 5.5423 - val_acc: 0.4993\n",
      "Epoch 946/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7111 - acc: 0.4659Epoch 00945: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7147 - acc: 0.4653 - val_loss: 5.5422 - val_acc: 0.4993\n",
      "Epoch 947/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7067 - acc: 0.4655Epoch 00946: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.7078 - acc: 0.4653 - val_loss: 5.5417 - val_acc: 0.4993\n",
      "Epoch 948/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7092 - acc: 0.4652Epoch 00947: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 5.7085 - acc: 0.4653 - val_loss: 5.5412 - val_acc: 0.4993\n",
      "Epoch 949/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7113 - acc: 0.4651Epoch 00948: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.7106 - acc: 0.4653 - val_loss: 5.5408 - val_acc: 0.4993\n",
      "Epoch 950/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7052 - acc: 0.4655Epoch 00949: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.7068 - acc: 0.4652 - val_loss: 5.5403 - val_acc: 0.4993\n",
      "Epoch 951/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7161 - acc: 0.4646Epoch 00950: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.7133 - acc: 0.4653 - val_loss: 5.5402 - val_acc: 0.4993\n",
      "Epoch 952/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7038 - acc: 0.4653Epoch 00951: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.7040 - acc: 0.4653 - val_loss: 5.5397 - val_acc: 0.4993\n",
      "Epoch 953/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7088 - acc: 0.4649Epoch 00952: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7068 - acc: 0.4653 - val_loss: 5.5394 - val_acc: 0.4993\n",
      "Epoch 954/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7067 - acc: 0.4660Epoch 00953: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7105 - acc: 0.4653 - val_loss: 5.5393 - val_acc: 0.4993\n",
      "Epoch 955/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7047 - acc: 0.4653Epoch 00954: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7047 - acc: 0.4653 - val_loss: 5.5388 - val_acc: 0.4993\n",
      "Epoch 956/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7040 - acc: 0.4660Epoch 00955: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7074 - acc: 0.4653 - val_loss: 5.5385 - val_acc: 0.4993\n",
      "Epoch 957/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7031 - acc: 0.4656Epoch 00956: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7052 - acc: 0.4653 - val_loss: 5.5381 - val_acc: 0.4993\n",
      "Epoch 958/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7084 - acc: 0.4651Epoch 00957: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.7077 - acc: 0.4653 - val_loss: 5.5379 - val_acc: 0.4993\n",
      "Epoch 959/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7086 - acc: 0.4654Epoch 00958: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.7093 - acc: 0.4653 - val_loss: 5.5376 - val_acc: 0.4993\n",
      "Epoch 960/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7064 - acc: 0.4651Epoch 00959: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.7055 - acc: 0.4653 - val_loss: 5.5371 - val_acc: 0.4993\n",
      "Epoch 961/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7090 - acc: 0.4651Epoch 00960: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 201s - loss: 5.7084 - acc: 0.4652 - val_loss: 5.5368 - val_acc: 0.4993\n",
      "Epoch 962/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7053 - acc: 0.4657Epoch 00961: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.7072 - acc: 0.4653 - val_loss: 5.5366 - val_acc: 0.4993\n",
      "Epoch 963/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7051 - acc: 0.4656Epoch 00962: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7069 - acc: 0.4653 - val_loss: 5.5364 - val_acc: 0.4993\n",
      "Epoch 964/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7008 - acc: 0.4656Epoch 00963: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.7027 - acc: 0.4653 - val_loss: 5.5361 - val_acc: 0.4993\n",
      "Epoch 965/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7050 - acc: 0.4652Epoch 00964: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.7045 - acc: 0.4653 - val_loss: 5.5357 - val_acc: 0.4993\n",
      "Epoch 966/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7038 - acc: 0.4654Epoch 00965: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 202s - loss: 5.7045 - acc: 0.4653 - val_loss: 5.5355 - val_acc: 0.4993\n",
      "Epoch 967/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7059 - acc: 0.4654Epoch 00966: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.7068 - acc: 0.4653 - val_loss: 5.5352 - val_acc: 0.4993\n",
      "Epoch 968/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7034 - acc: 0.4656Epoch 00967: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.7054 - acc: 0.4653 - val_loss: 5.5347 - val_acc: 0.4993\n",
      "Epoch 969/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7001 - acc: 0.4652Epoch 00968: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.7001 - acc: 0.4653 - val_loss: 5.5343 - val_acc: 0.4993\n",
      "Epoch 970/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7026 - acc: 0.4653Epoch 00969: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.7026 - acc: 0.4653 - val_loss: 5.5340 - val_acc: 0.4993\n",
      "Epoch 971/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6976 - acc: 0.4659Epoch 00970: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.7004 - acc: 0.4653 - val_loss: 5.5336 - val_acc: 0.4993\n",
      "Epoch 972/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7053 - acc: 0.4649Epoch 00971: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 182s - loss: 5.7031 - acc: 0.4653 - val_loss: 5.5334 - val_acc: 0.4993\n",
      "Epoch 973/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7079 - acc: 0.4649Epoch 00972: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7061 - acc: 0.4653 - val_loss: 5.5330 - val_acc: 0.4993\n",
      "Epoch 974/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6985 - acc: 0.4650Epoch 00973: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6971 - acc: 0.4653 - val_loss: 5.5325 - val_acc: 0.4993\n",
      "Epoch 975/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6994 - acc: 0.4653Epoch 00974: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7001 - acc: 0.4653 - val_loss: 5.5321 - val_acc: 0.4993\n",
      "Epoch 976/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7022 - acc: 0.4649Epoch 00975: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7006 - acc: 0.4652 - val_loss: 5.5318 - val_acc: 0.4993\n",
      "Epoch 977/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6936 - acc: 0.4654Epoch 00976: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6943 - acc: 0.4653 - val_loss: 5.5315 - val_acc: 0.4993\n",
      "Epoch 978/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6909 - acc: 0.4657Epoch 00977: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6928 - acc: 0.4653 - val_loss: 5.5311 - val_acc: 0.4993\n",
      "Epoch 979/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7029 - acc: 0.4648Epoch 00978: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7002 - acc: 0.4653 - val_loss: 5.5307 - val_acc: 0.4993\n",
      "Epoch 980/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6943 - acc: 0.4656Epoch 00979: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6957 - acc: 0.4653 - val_loss: 5.5302 - val_acc: 0.4993\n",
      "Epoch 981/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7032 - acc: 0.4653Epoch 00980: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.7039 - acc: 0.4652 - val_loss: 5.5300 - val_acc: 0.4993\n",
      "Epoch 982/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7012 - acc: 0.4651Epoch 00981: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.7004 - acc: 0.4653 - val_loss: 5.5299 - val_acc: 0.4993\n",
      "Epoch 983/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6954 - acc: 0.4652Epoch 00982: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6954 - acc: 0.4653 - val_loss: 5.5295 - val_acc: 0.4993\n",
      "Epoch 984/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6953 - acc: 0.4653Epoch 00983: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6957 - acc: 0.4653 - val_loss: 5.5291 - val_acc: 0.4993\n",
      "Epoch 985/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6934 - acc: 0.4653Epoch 00984: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6933 - acc: 0.4653 - val_loss: 5.5287 - val_acc: 0.4993\n",
      "Epoch 986/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6949 - acc: 0.4660Epoch 00985: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6992 - acc: 0.4653 - val_loss: 5.5283 - val_acc: 0.4993\n",
      "Epoch 987/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6905 - acc: 0.4656Epoch 00986: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6928 - acc: 0.4653 - val_loss: 5.5280 - val_acc: 0.4993\n",
      "Epoch 988/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6981 - acc: 0.4650Epoch 00987: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6967 - acc: 0.4653 - val_loss: 5.5276 - val_acc: 0.4993\n",
      "Epoch 989/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6881 - acc: 0.4652Epoch 00988: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6873 - acc: 0.4653 - val_loss: 5.5270 - val_acc: 0.4993\n",
      "Epoch 990/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6999 - acc: 0.4648Epoch 00989: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.6973 - acc: 0.4653 - val_loss: 5.5267 - val_acc: 0.4993\n",
      "Epoch 991/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.7056 - acc: 0.4654Epoch 00990: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.7064 - acc: 0.4653 - val_loss: 5.5267 - val_acc: 0.4993\n",
      "Epoch 992/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6907 - acc: 0.4654Epoch 00991: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.6911 - acc: 0.4653 - val_loss: 5.5262 - val_acc: 0.4993\n",
      "Epoch 993/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6904 - acc: 0.4658Epoch 00992: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.6937 - acc: 0.4653 - val_loss: 5.5259 - val_acc: 0.4993\n",
      "Epoch 994/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6970 - acc: 0.4651Epoch 00993: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6959 - acc: 0.4653 - val_loss: 5.5256 - val_acc: 0.4993\n",
      "Epoch 995/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6943 - acc: 0.4656Epoch 00994: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6964 - acc: 0.4652 - val_loss: 5.5254 - val_acc: 0.4993\n",
      "Epoch 996/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6933 - acc: 0.4648Epoch 00995: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6907 - acc: 0.4653 - val_loss: 5.5250 - val_acc: 0.4993\n",
      "Epoch 997/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6846 - acc: 0.4651Epoch 00996: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.6838 - acc: 0.4653 - val_loss: 5.5245 - val_acc: 0.4993\n",
      "Epoch 998/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6872 - acc: 0.4656Epoch 00997: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.6893 - acc: 0.4653 - val_loss: 5.5240 - val_acc: 0.4993\n",
      "Epoch 999/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6937 - acc: 0.4650Epoch 00998: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6924 - acc: 0.4653 - val_loss: 5.5238 - val_acc: 0.4993\n",
      "Epoch 1000/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6928 - acc: 0.4653Epoch 00999: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.6933 - acc: 0.4653 - val_loss: 5.5235 - val_acc: 0.4993\n",
      "Epoch 1001/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6889 - acc: 0.4650Epoch 01000: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 189s - loss: 5.6873 - acc: 0.4653 - val_loss: 5.5230 - val_acc: 0.4993\n",
      "Epoch 1002/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6879 - acc: 0.4656Epoch 01001: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.6899 - acc: 0.4653 - val_loss: 5.5226 - val_acc: 0.4993\n",
      "Epoch 1003/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6909 - acc: 0.4655Epoch 01002: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6925 - acc: 0.4653 - val_loss: 5.5225 - val_acc: 0.4993\n",
      "Epoch 1004/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6856 - acc: 0.4652Epoch 01003: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.6849 - acc: 0.4653 - val_loss: 5.5219 - val_acc: 0.4993\n",
      "Epoch 1005/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6867 - acc: 0.4647Epoch 01004: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 5.6834 - acc: 0.4653 - val_loss: 5.5214 - val_acc: 0.4993\n",
      "Epoch 1006/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6893 - acc: 0.4653Epoch 01005: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6899 - acc: 0.4653 - val_loss: 5.5210 - val_acc: 0.4993\n",
      "Epoch 1007/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6905 - acc: 0.4647Epoch 01006: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6874 - acc: 0.4653 - val_loss: 5.5206 - val_acc: 0.4993\n",
      "Epoch 1008/2000\n",
      "242/760 [========>.....................] - ETA: 498s - loss: 5.7579 - acc: 0.4513- ETA: 223s - loss: 5.7143 - acc - ETA: 446s - loss: 5.7258 - acc: 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (2.134364). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/760 [========>.....................] - ETA: 489s - loss: 5.7626 - acc: 0.4503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (2.096748). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "248/760 [========>.....................] - ETA: 484s - loss: 5.7664 - acc: 0.4498"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.023647). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/760 [========================>.....] - ETA: 207s - loss: 5.7049 - acc: 0.4620ETA: 65s - loss: 5.7099 - acc: 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.913789). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658/760 [========================>.....] - ETA: 194s - loss: 5.7054 - acc: 0.4618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.447011). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "660/760 [=========================>....] - ETA: 190s - loss: 5.7057 - acc: 0.4617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.419776). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 3s - loss: 5.6918 - acc: 0.4648Epoch 01007: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1307s - loss: 5.6908 - acc: 0.4653 - val_loss: 5.5205 - val_acc: 0.4993\n",
      "Epoch 1009/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6847 - acc: 0.4650Epoch 01008: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6831 - acc: 0.4653 - val_loss: 5.5201 - val_acc: 0.4993\n",
      "Epoch 1010/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6821 - acc: 0.4655Epoch 01009: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.6832 - acc: 0.4653 - val_loss: 5.5197 - val_acc: 0.4993\n",
      "Epoch 1011/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6897 - acc: 0.4654Epoch 01010: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 201s - loss: 5.6902 - acc: 0.4653 - val_loss: 5.5197 - val_acc: 0.4993\n",
      "Epoch 1012/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6833 - acc: 0.4652Epoch 01011: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.6830 - acc: 0.4653 - val_loss: 5.5193 - val_acc: 0.4993\n",
      "Epoch 1013/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6895 - acc: 0.4648Epoch 01012: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6872 - acc: 0.4653 - val_loss: 5.5189 - val_acc: 0.4993\n",
      "Epoch 1014/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6829 - acc: 0.4656Epoch 01013: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.6841 - acc: 0.4653 - val_loss: 5.5186 - val_acc: 0.4993\n",
      "Epoch 1015/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6870 - acc: 0.4654Epoch 01014: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.6882 - acc: 0.4653 - val_loss: 5.5183 - val_acc: 0.4993\n",
      "Epoch 1016/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6842 - acc: 0.4649Epoch 01015: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6827 - acc: 0.4653 - val_loss: 5.5180 - val_acc: 0.4993\n",
      "Epoch 1017/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6861 - acc: 0.4651Epoch 01016: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.6850 - acc: 0.4653 - val_loss: 5.5176 - val_acc: 0.4993\n",
      "Epoch 1018/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6897 - acc: 0.4653Epoch 01017: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6901 - acc: 0.4653 - val_loss: 5.5175 - val_acc: 0.4993\n",
      "Epoch 1019/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6837 - acc: 0.4650Epoch 01018: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6824 - acc: 0.4653 - val_loss: 5.5171 - val_acc: 0.4993\n",
      "Epoch 1020/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6865 - acc: 0.4653Epoch 01019: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.6878 - acc: 0.4653 - val_loss: 5.5169 - val_acc: 0.4993\n",
      "Epoch 1021/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6827 - acc: 0.4655Epoch 01020: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6836 - acc: 0.4653 - val_loss: 5.5165 - val_acc: 0.4993\n",
      "Epoch 1022/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6839 - acc: 0.4655Epoch 01021: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.6854 - acc: 0.4653 - val_loss: 5.5163 - val_acc: 0.4993\n",
      "Epoch 1023/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6773 - acc: 0.4654Epoch 01022: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.6786 - acc: 0.4653 - val_loss: 5.5158 - val_acc: 0.4993\n",
      "Epoch 1024/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6831 - acc: 0.4651Epoch 01023: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6825 - acc: 0.4653 - val_loss: 5.5154 - val_acc: 0.4993\n",
      "Epoch 1025/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6789 - acc: 0.4655Epoch 01024: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 200s - loss: 5.6801 - acc: 0.4653 - val_loss: 5.5151 - val_acc: 0.4993\n",
      "Epoch 1026/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6707 - acc: 0.4659Epoch 01025: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.6743 - acc: 0.4653 - val_loss: 5.5145 - val_acc: 0.4993\n",
      "Epoch 1027/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6792 - acc: 0.4652Epoch 01026: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.6791 - acc: 0.4653 - val_loss: 5.5142 - val_acc: 0.4993\n",
      "Epoch 1028/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6901 - acc: 0.4647Epoch 01027: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6876 - acc: 0.4653 - val_loss: 5.5141 - val_acc: 0.4993\n",
      "Epoch 1029/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6842 - acc: 0.4647Epoch 01028: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6811 - acc: 0.4653 - val_loss: 5.5138 - val_acc: 0.4993\n",
      "Epoch 1030/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6815 - acc: 0.4648Epoch 01029: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6791 - acc: 0.4653 - val_loss: 5.5133 - val_acc: 0.4993\n",
      "Epoch 1031/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6732 - acc: 0.4652Epoch 01030: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.6730 - acc: 0.4653 - val_loss: 5.5129 - val_acc: 0.4993\n",
      "Epoch 1032/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6834 - acc: 0.4651Epoch 01031: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6821 - acc: 0.4653 - val_loss: 5.5126 - val_acc: 0.4993\n",
      "Epoch 1033/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6753 - acc: 0.4653Epoch 01032: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 203s - loss: 5.6756 - acc: 0.4653 - val_loss: 5.5123 - val_acc: 0.4993\n",
      "Epoch 1034/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6764 - acc: 0.4659Epoch 01033: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.6800 - acc: 0.4653 - val_loss: 5.5118 - val_acc: 0.4993\n",
      "Epoch 1035/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6820 - acc: 0.4653Epoch 01034: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6825 - acc: 0.4652 - val_loss: 5.5117 - val_acc: 0.4993\n",
      "Epoch 1036/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6757 - acc: 0.4654Epoch 01035: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.6766 - acc: 0.4653 - val_loss: 5.5112 - val_acc: 0.4993\n",
      "Epoch 1037/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6794 - acc: 0.4653Epoch 01036: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.6799 - acc: 0.4653 - val_loss: 5.5109 - val_acc: 0.4993\n",
      "Epoch 1038/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6726 - acc: 0.4650Epoch 01037: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6714 - acc: 0.4653 - val_loss: 5.5105 - val_acc: 0.4993\n",
      "Epoch 1039/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6803 - acc: 0.4652Epoch 01038: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6802 - acc: 0.4653 - val_loss: 5.5104 - val_acc: 0.4993\n",
      "Epoch 1040/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6783 - acc: 0.4652Epoch 01039: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6776 - acc: 0.4653 - val_loss: 5.5102 - val_acc: 0.4993\n",
      "Epoch 1041/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6795 - acc: 0.4647Epoch 01040: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.6768 - acc: 0.4653 - val_loss: 5.5099 - val_acc: 0.4993\n",
      "Epoch 1042/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6826 - acc: 0.4651Epoch 01041: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.6815 - acc: 0.4653 - val_loss: 5.5097 - val_acc: 0.4993\n",
      "Epoch 1043/2000\n",
      "758/760 [============================>.] - ETA: 4s - loss: 5.6772 - acc: 0.4651Epoch 01042: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1777s - loss: 5.6765 - acc: 0.4653 - val_loss: 5.5095 - val_acc: 0.4993\n",
      "Epoch 1044/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6850 - acc: 0.4646Epoch 01043: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6815 - acc: 0.4653 - val_loss: 5.5093 - val_acc: 0.4993\n",
      "Epoch 1045/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6743 - acc: 0.4648Epoch 01044: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6713 - acc: 0.4653 - val_loss: 5.5090 - val_acc: 0.4993\n",
      "Epoch 1046/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6770 - acc: 0.4657Epoch 01045: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6800 - acc: 0.4653 - val_loss: 5.5087 - val_acc: 0.4993\n",
      "Epoch 1047/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6685 - acc: 0.4656Epoch 01046: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.6709 - acc: 0.4653 - val_loss: 5.5081 - val_acc: 0.4993\n",
      "Epoch 1048/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6738 - acc: 0.4661Epoch 01047: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.6777 - acc: 0.4653 - val_loss: 5.5078 - val_acc: 0.4993\n",
      "Epoch 1049/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6753 - acc: 0.4654Epoch 01048: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 5.6756 - acc: 0.4653 - val_loss: 5.5073 - val_acc: 0.4993\n",
      "Epoch 1050/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6710 - acc: 0.4657Epoch 01049: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6729 - acc: 0.4653 - val_loss: 5.5071 - val_acc: 0.4993\n",
      "Epoch 1051/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6723 - acc: 0.4658Epoch 01050: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6741 - acc: 0.4653 - val_loss: 5.5067 - val_acc: 0.4993\n",
      "Epoch 1052/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6671 - acc: 0.4656Epoch 01051: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6688 - acc: 0.4653 - val_loss: 5.5063 - val_acc: 0.4993\n",
      "Epoch 1053/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6711 - acc: 0.4653Epoch 01052: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6714 - acc: 0.4653 - val_loss: 5.5062 - val_acc: 0.4993\n",
      "Epoch 1054/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6751 - acc: 0.4647Epoch 01053: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6720 - acc: 0.4653 - val_loss: 5.5059 - val_acc: 0.4993\n",
      "Epoch 1055/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6797 - acc: 0.4652Epoch 01054: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6793 - acc: 0.4653 - val_loss: 5.5058 - val_acc: 0.4993\n",
      "Epoch 1056/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6747 - acc: 0.4658Epoch 01055: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6772 - acc: 0.4653 - val_loss: 5.5056 - val_acc: 0.4993\n",
      "Epoch 1057/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6711 - acc: 0.4651Epoch 01056: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6706 - acc: 0.4653 - val_loss: 5.5052 - val_acc: 0.4993\n",
      "Epoch 1058/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6806 - acc: 0.4644Epoch 01057: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6777 - acc: 0.4650 - val_loss: 5.5049 - val_acc: 0.4993\n",
      "Epoch 1059/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6648 - acc: 0.4650Epoch 01058: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6629 - acc: 0.4653 - val_loss: 5.5045 - val_acc: 0.4993\n",
      "Epoch 1060/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6693 - acc: 0.4650Epoch 01059: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6682 - acc: 0.4653 - val_loss: 5.5044 - val_acc: 0.4993\n",
      "Epoch 1061/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6779 - acc: 0.4648Epoch 01060: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6758 - acc: 0.4653 - val_loss: 5.5043 - val_acc: 0.4993\n",
      "Epoch 1062/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6710 - acc: 0.4649Epoch 01061: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6688 - acc: 0.4653 - val_loss: 5.5040 - val_acc: 0.4993\n",
      "Epoch 1063/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6686 - acc: 0.4653Epoch 01062: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6692 - acc: 0.4653 - val_loss: 5.5036 - val_acc: 0.4993\n",
      "Epoch 1064/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6637 - acc: 0.4654Epoch 01063: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6649 - acc: 0.4653 - val_loss: 5.5032 - val_acc: 0.4993\n",
      "Epoch 1065/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.6743 - acc: 0.4643Epoch 01064: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6694 - acc: 0.4653 - val_loss: 5.5028 - val_acc: 0.4993\n",
      "Epoch 1066/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6735 - acc: 0.4653Epoch 01065: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 203s - loss: 5.6735 - acc: 0.4653 - val_loss: 5.5026 - val_acc: 0.4993\n",
      "Epoch 1067/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6674 - acc: 0.4658Epoch 01066: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.6704 - acc: 0.4653 - val_loss: 5.5025 - val_acc: 0.4993\n",
      "Epoch 1068/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6741 - acc: 0.4658Epoch 01067: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.6771 - acc: 0.4653 - val_loss: 5.5022 - val_acc: 0.4993\n",
      "Epoch 1069/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6750 - acc: 0.4645Epoch 01068: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.6710 - acc: 0.4653 - val_loss: 5.5020 - val_acc: 0.4993\n",
      "Epoch 1070/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6664 - acc: 0.4656Epoch 01069: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.6675 - acc: 0.4653 - val_loss: 5.5017 - val_acc: 0.4993\n",
      "Epoch 1071/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6677 - acc: 0.4654Epoch 01070: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6680 - acc: 0.4653 - val_loss: 5.5014 - val_acc: 0.4993\n",
      "Epoch 1072/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6666 - acc: 0.4648Epoch 01071: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6645 - acc: 0.4653 - val_loss: 5.5010 - val_acc: 0.4993\n",
      "Epoch 1073/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6697 - acc: 0.4653Epoch 01072: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6698 - acc: 0.4653 - val_loss: 5.5007 - val_acc: 0.4993\n",
      "Epoch 1074/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6667 - acc: 0.4651Epoch 01073: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6656 - acc: 0.4653 - val_loss: 5.5004 - val_acc: 0.4993\n",
      "Epoch 1075/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6632 - acc: 0.4650Epoch 01074: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.6622 - acc: 0.4653 - val_loss: 5.5000 - val_acc: 0.4993\n",
      "Epoch 1076/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6628 - acc: 0.4650Epoch 01075: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.6614 - acc: 0.4653 - val_loss: 5.4996 - val_acc: 0.4993\n",
      "Epoch 1077/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6647 - acc: 0.4650Epoch 01076: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6636 - acc: 0.4653 - val_loss: 5.4993 - val_acc: 0.4993\n",
      "Epoch 1078/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6601 - acc: 0.4661Epoch 01077: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6642 - acc: 0.4653 - val_loss: 5.4989 - val_acc: 0.4993\n",
      "Epoch 1079/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6613 - acc: 0.4649Epoch 01078: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6593 - acc: 0.4653 - val_loss: 5.4984 - val_acc: 0.4993\n",
      "Epoch 1080/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6616 - acc: 0.4655Epoch 01079: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6620 - acc: 0.4653 - val_loss: 5.4980 - val_acc: 0.4993\n",
      "Epoch 1081/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6599 - acc: 0.4657Epoch 01080: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6623 - acc: 0.4653 - val_loss: 5.4976 - val_acc: 0.4993\n",
      "Epoch 1082/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6635 - acc: 0.4652Epoch 01081: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6637 - acc: 0.4653 - val_loss: 5.4973 - val_acc: 0.4993\n",
      "Epoch 1083/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6682 - acc: 0.4655Epoch 01082: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6697 - acc: 0.4653 - val_loss: 5.4972 - val_acc: 0.4993\n",
      "Epoch 1084/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6702 - acc: 0.4654Epoch 01083: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6706 - acc: 0.4653 - val_loss: 5.4972 - val_acc: 0.4993\n",
      "Epoch 1085/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6546 - acc: 0.4658Epoch 01084: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6579 - acc: 0.4653 - val_loss: 5.4966 - val_acc: 0.4993\n",
      "Epoch 1086/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6623 - acc: 0.4652Epoch 01085: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6622 - acc: 0.4653 - val_loss: 5.4963 - val_acc: 0.4993\n",
      "Epoch 1087/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6640 - acc: 0.4655Epoch 01086: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6660 - acc: 0.4653 - val_loss: 5.4961 - val_acc: 0.4993\n",
      "Epoch 1088/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6573 - acc: 0.4657Epoch 01087: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6599 - acc: 0.4653 - val_loss: 5.4958 - val_acc: 0.4993\n",
      "Epoch 1089/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6615 - acc: 0.4655Epoch 01088: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.6629 - acc: 0.4653 - val_loss: 5.4956 - val_acc: 0.4993\n",
      "Epoch 1090/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6566 - acc: 0.4650Epoch 01089: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6555 - acc: 0.4653 - val_loss: 5.4950 - val_acc: 0.4993\n",
      "Epoch 1091/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6574 - acc: 0.4655Epoch 01090: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.6590 - acc: 0.4653 - val_loss: 5.4947 - val_acc: 0.4993\n",
      "Epoch 1092/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6559 - acc: 0.4656Epoch 01091: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6574 - acc: 0.4653 - val_loss: 5.4943 - val_acc: 0.4993\n",
      "Epoch 1093/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6675 - acc: 0.4659Epoch 01092: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.6711 - acc: 0.4653 - val_loss: 5.4944 - val_acc: 0.4993\n",
      "Epoch 1094/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6632 - acc: 0.4651Epoch 01093: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6623 - acc: 0.4653 - val_loss: 5.4943 - val_acc: 0.4993\n",
      "Epoch 1095/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6617 - acc: 0.4651Epoch 01094: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6611 - acc: 0.4653 - val_loss: 5.4940 - val_acc: 0.4993\n",
      "Epoch 1096/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6560 - acc: 0.4655Epoch 01095: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6575 - acc: 0.4653 - val_loss: 5.4937 - val_acc: 0.4993\n",
      "Epoch 1097/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6632 - acc: 0.4649Epoch 01096: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6612 - acc: 0.4653 - val_loss: 5.4935 - val_acc: 0.4993\n",
      "Epoch 1098/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6604 - acc: 0.4649Epoch 01097: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.6582 - acc: 0.4653 - val_loss: 5.4933 - val_acc: 0.4993\n",
      "Epoch 1099/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6531 - acc: 0.4659Epoch 01098: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6565 - acc: 0.4653 - val_loss: 5.4929 - val_acc: 0.4993\n",
      "Epoch 1100/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6641 - acc: 0.4650Epoch 01099: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.6626 - acc: 0.4653 - val_loss: 5.4928 - val_acc: 0.4993\n",
      "Epoch 1101/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6680 - acc: 0.4656Epoch 01100: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6694 - acc: 0.4653 - val_loss: 5.4927 - val_acc: 0.4993\n",
      "Epoch 1102/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6649 - acc: 0.4656Epoch 01101: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6670 - acc: 0.4652 - val_loss: 5.4926 - val_acc: 0.4993\n",
      "Epoch 1103/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6546 - acc: 0.4650Epoch 01102: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6531 - acc: 0.4653 - val_loss: 5.4922 - val_acc: 0.4993\n",
      "Epoch 1104/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6660 - acc: 0.4645Epoch 01103: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6620 - acc: 0.4653 - val_loss: 5.4921 - val_acc: 0.4993\n",
      "Epoch 1105/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6598 - acc: 0.4649Epoch 01104: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6579 - acc: 0.4653 - val_loss: 5.4918 - val_acc: 0.4993\n",
      "Epoch 1106/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6475 - acc: 0.4655Epoch 01105: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6481 - acc: 0.4653 - val_loss: 5.4913 - val_acc: 0.4993\n",
      "Epoch 1107/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6602 - acc: 0.4645Epoch 01106: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6566 - acc: 0.4653 - val_loss: 5.4910 - val_acc: 0.4993\n",
      "Epoch 1108/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6597 - acc: 0.4652Epoch 01107: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6594 - acc: 0.4653 - val_loss: 5.4907 - val_acc: 0.4993\n",
      "Epoch 1109/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6577 - acc: 0.4652Epoch 01108: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6572 - acc: 0.4653 - val_loss: 5.4905 - val_acc: 0.4993\n",
      "Epoch 1110/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6547 - acc: 0.4647Epoch 01109: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.6520 - acc: 0.4653 - val_loss: 5.4900 - val_acc: 0.4993\n",
      "Epoch 1111/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6607 - acc: 0.4651Epoch 01110: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 203s - loss: 5.6597 - acc: 0.4653 - val_loss: 5.4898 - val_acc: 0.4993\n",
      "Epoch 1112/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6576 - acc: 0.4653Epoch 01111: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.6577 - acc: 0.4653 - val_loss: 5.4896 - val_acc: 0.4993\n",
      "Epoch 1113/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6532 - acc: 0.4652Epoch 01112: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6527 - acc: 0.4653 - val_loss: 5.4892 - val_acc: 0.4993\n",
      "Epoch 1114/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6630 - acc: 0.4650Epoch 01113: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6615 - acc: 0.4653 - val_loss: 5.4891 - val_acc: 0.4993\n",
      "Epoch 1115/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6577 - acc: 0.4661Epoch 01114: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6618 - acc: 0.4653 - val_loss: 5.4889 - val_acc: 0.4993\n",
      "Epoch 1116/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6544 - acc: 0.4657Epoch 01115: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6564 - acc: 0.4653 - val_loss: 5.4888 - val_acc: 0.4993\n",
      "Epoch 1117/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6512 - acc: 0.4656Epoch 01116: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6524 - acc: 0.4653 - val_loss: 5.4884 - val_acc: 0.4993\n",
      "Epoch 1118/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6570 - acc: 0.4650Epoch 01117: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6554 - acc: 0.4653 - val_loss: 5.4880 - val_acc: 0.4993\n",
      "Epoch 1119/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6539 - acc: 0.4650Epoch 01118: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6524 - acc: 0.4653 - val_loss: 5.4878 - val_acc: 0.4993\n",
      "Epoch 1120/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6579 - acc: 0.4654Epoch 01119: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6577 - acc: 0.4653 - val_loss: 5.4877 - val_acc: 0.4993\n",
      "Epoch 1121/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6597 - acc: 0.4649Epoch 01120: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6575 - acc: 0.4653 - val_loss: 5.4877 - val_acc: 0.4993\n",
      "Epoch 1122/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.6509 - acc: 0.4651Epoch 01121: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6499 - acc: 0.4653 - val_loss: 5.4873 - val_acc: 0.4993\n",
      "Epoch 1123/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6548 - acc: 0.4655Epoch 01122: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6559 - acc: 0.4653 - val_loss: 5.4870 - val_acc: 0.4993\n",
      "Epoch 1124/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6445 - acc: 0.4655Epoch 01123: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6462 - acc: 0.4653 - val_loss: 5.4865 - val_acc: 0.4993\n",
      "Epoch 1125/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6477 - acc: 0.4653Epoch 01124: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6480 - acc: 0.4653 - val_loss: 5.4862 - val_acc: 0.4993\n",
      "Epoch 1126/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6516 - acc: 0.4652Epoch 01125: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6517 - acc: 0.4653 - val_loss: 5.4860 - val_acc: 0.4993\n",
      "Epoch 1127/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6457 - acc: 0.4650Epoch 01126: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6441 - acc: 0.4653 - val_loss: 5.4853 - val_acc: 0.4993\n",
      "Epoch 1128/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6518 - acc: 0.4654Epoch 01127: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6522 - acc: 0.4653 - val_loss: 5.4851 - val_acc: 0.4993\n",
      "Epoch 1129/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6518 - acc: 0.4647Epoch 01128: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6487 - acc: 0.4653 - val_loss: 5.4849 - val_acc: 0.4993\n",
      "Epoch 1130/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6456 - acc: 0.4660Epoch 01129: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6489 - acc: 0.4653 - val_loss: 5.4846 - val_acc: 0.4993\n",
      "Epoch 1131/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6576 - acc: 0.4646Epoch 01130: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6540 - acc: 0.4653 - val_loss: 5.4845 - val_acc: 0.4993\n",
      "Epoch 1132/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6478 - acc: 0.4655Epoch 01131: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6494 - acc: 0.4653 - val_loss: 5.4841 - val_acc: 0.4993\n",
      "Epoch 1133/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6519 - acc: 0.4654Epoch 01132: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6527 - acc: 0.4653 - val_loss: 5.4840 - val_acc: 0.4993\n",
      "Epoch 1134/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6502 - acc: 0.4655Epoch 01133: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.6514 - acc: 0.4653 - val_loss: 5.4839 - val_acc: 0.4993\n",
      "Epoch 1135/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6462 - acc: 0.4650Epoch 01134: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.6450 - acc: 0.4651 - val_loss: 5.4835 - val_acc: 0.4993\n",
      "Epoch 1136/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6512 - acc: 0.4654Epoch 01135: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6517 - acc: 0.4653 - val_loss: 5.4833 - val_acc: 0.4993\n",
      "Epoch 1137/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6511 - acc: 0.4648Epoch 01136: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6483 - acc: 0.4653 - val_loss: 5.4831 - val_acc: 0.4993\n",
      "Epoch 1138/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6418 - acc: 0.4651Epoch 01137: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6409 - acc: 0.4653 - val_loss: 5.4825 - val_acc: 0.4993\n",
      "Epoch 1139/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6509 - acc: 0.4650Epoch 01138: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6488 - acc: 0.4653 - val_loss: 5.4822 - val_acc: 0.4993\n",
      "Epoch 1140/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6466 - acc: 0.4650Epoch 01139: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6455 - acc: 0.4653 - val_loss: 5.4820 - val_acc: 0.4993\n",
      "Epoch 1141/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6468 - acc: 0.4654Epoch 01140: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.6473 - acc: 0.4653 - val_loss: 5.4817 - val_acc: 0.4993\n",
      "Epoch 1142/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6481 - acc: 0.4655Epoch 01141: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6493 - acc: 0.4653 - val_loss: 5.4814 - val_acc: 0.4993\n",
      "Epoch 1143/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6467 - acc: 0.4649Epoch 01142: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6441 - acc: 0.4653 - val_loss: 5.4812 - val_acc: 0.4993\n",
      "Epoch 1144/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6466 - acc: 0.4649Epoch 01143: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6450 - acc: 0.4653 - val_loss: 5.4809 - val_acc: 0.4993\n",
      "Epoch 1145/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6511 - acc: 0.4648Epoch 01144: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6483 - acc: 0.4653 - val_loss: 5.4807 - val_acc: 0.4993\n",
      "Epoch 1146/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6455 - acc: 0.4654Epoch 01145: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6458 - acc: 0.4653 - val_loss: 5.4803 - val_acc: 0.4993\n",
      "Epoch 1147/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6434 - acc: 0.4657Epoch 01146: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6462 - acc: 0.4653 - val_loss: 5.4801 - val_acc: 0.4993\n",
      "Epoch 1148/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6476 - acc: 0.4655Epoch 01147: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6491 - acc: 0.4653 - val_loss: 5.4800 - val_acc: 0.4993\n",
      "Epoch 1149/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6480 - acc: 0.4647Epoch 01148: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6450 - acc: 0.4653 - val_loss: 5.4797 - val_acc: 0.4993\n",
      "Epoch 1150/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6490 - acc: 0.4655Epoch 01149: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6495 - acc: 0.4653 - val_loss: 5.4794 - val_acc: 0.4993\n",
      "Epoch 1151/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6529 - acc: 0.4649Epoch 01150: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6504 - acc: 0.4653 - val_loss: 5.4793 - val_acc: 0.4993\n",
      "Epoch 1152/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6394 - acc: 0.4651Epoch 01151: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6382 - acc: 0.4653 - val_loss: 5.4789 - val_acc: 0.4993\n",
      "Epoch 1153/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6498 - acc: 0.4652Epoch 01152: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6494 - acc: 0.4653 - val_loss: 5.4787 - val_acc: 0.4993\n",
      "Epoch 1154/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6404 - acc: 0.4652Epoch 01153: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6394 - acc: 0.4653 - val_loss: 5.4783 - val_acc: 0.4993\n",
      "Epoch 1155/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6465 - acc: 0.4652Epoch 01154: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6462 - acc: 0.4653 - val_loss: 5.4782 - val_acc: 0.4993\n",
      "Epoch 1156/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6400 - acc: 0.4648Epoch 01155: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6374 - acc: 0.4653 - val_loss: 5.4777 - val_acc: 0.4993\n",
      "Epoch 1157/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6502 - acc: 0.4649Epoch 01156: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6484 - acc: 0.4653 - val_loss: 5.4775 - val_acc: 0.4993\n",
      "Epoch 1158/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6427 - acc: 0.4656Epoch 01157: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6455 - acc: 0.4651 - val_loss: 5.4773 - val_acc: 0.4993\n",
      "Epoch 1159/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6529 - acc: 0.4652Epoch 01158: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6527 - acc: 0.4653 - val_loss: 5.4774 - val_acc: 0.4993\n",
      "Epoch 1160/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6451 - acc: 0.4655Epoch 01159: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6466 - acc: 0.4653 - val_loss: 5.4772 - val_acc: 0.4993\n",
      "Epoch 1161/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6446 - acc: 0.4651Epoch 01160: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6439 - acc: 0.4653 - val_loss: 5.4771 - val_acc: 0.4993\n",
      "Epoch 1162/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6447 - acc: 0.4656Epoch 01161: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6467 - acc: 0.4653 - val_loss: 5.4767 - val_acc: 0.4993\n",
      "Epoch 1163/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6433 - acc: 0.4657Epoch 01162: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6458 - acc: 0.4653 - val_loss: 5.4765 - val_acc: 0.4993\n",
      "Epoch 1164/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6411 - acc: 0.4654Epoch 01163: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6414 - acc: 0.4653 - val_loss: 5.4763 - val_acc: 0.4993\n",
      "Epoch 1165/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6439 - acc: 0.4658Epoch 01164: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6459 - acc: 0.4653 - val_loss: 5.4760 - val_acc: 0.4993\n",
      "Epoch 1166/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6372 - acc: 0.4650Epoch 01165: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6357 - acc: 0.4653 - val_loss: 5.4756 - val_acc: 0.4993\n",
      "Epoch 1167/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6414 - acc: 0.4648Epoch 01166: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6392 - acc: 0.4653 - val_loss: 5.4755 - val_acc: 0.4993\n",
      "Epoch 1168/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6381 - acc: 0.4656Epoch 01167: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6398 - acc: 0.4653 - val_loss: 5.4751 - val_acc: 0.4993\n",
      "Epoch 1169/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6430 - acc: 0.4648Epoch 01168: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6423 - acc: 0.4649 - val_loss: 5.4748 - val_acc: 0.4993\n",
      "Epoch 1170/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6423 - acc: 0.4654Epoch 01169: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6425 - acc: 0.4653 - val_loss: 5.4746 - val_acc: 0.4993\n",
      "Epoch 1171/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6471 - acc: 0.4654Epoch 01170: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6482 - acc: 0.4653 - val_loss: 5.4746 - val_acc: 0.4993\n",
      "Epoch 1172/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6365 - acc: 0.4650Epoch 01171: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6346 - acc: 0.4653 - val_loss: 5.4742 - val_acc: 0.4993\n",
      "Epoch 1173/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6486 - acc: 0.4647Epoch 01172: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6451 - acc: 0.4653 - val_loss: 5.4740 - val_acc: 0.4993\n",
      "Epoch 1174/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6368 - acc: 0.4654Epoch 01173: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6372 - acc: 0.4653 - val_loss: 5.4739 - val_acc: 0.4993\n",
      "Epoch 1175/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6415 - acc: 0.4649Epoch 01174: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6403 - acc: 0.4653 - val_loss: 5.4736 - val_acc: 0.4993\n",
      "Epoch 1176/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6321 - acc: 0.4658Epoch 01175: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6347 - acc: 0.4653 - val_loss: 5.4732 - val_acc: 0.4993\n",
      "Epoch 1177/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6387 - acc: 0.4651Epoch 01176: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6381 - acc: 0.4653 - val_loss: 5.4730 - val_acc: 0.4993\n",
      "Epoch 1178/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6388 - acc: 0.4649Epoch 01177: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6371 - acc: 0.4653 - val_loss: 5.4729 - val_acc: 0.4993\n",
      "Epoch 1179/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.6429 - acc: 0.4650Epoch 01178: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6413 - acc: 0.4653 - val_loss: 5.4727 - val_acc: 0.4993\n",
      "Epoch 1180/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6329 - acc: 0.4657Epoch 01179: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6353 - acc: 0.4653 - val_loss: 5.4723 - val_acc: 0.4993\n",
      "Epoch 1181/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6347 - acc: 0.4654Epoch 01180: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6352 - acc: 0.4653 - val_loss: 5.4721 - val_acc: 0.4993\n",
      "Epoch 1182/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6425 - acc: 0.4651Epoch 01181: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6413 - acc: 0.4653 - val_loss: 5.4720 - val_acc: 0.4993\n",
      "Epoch 1183/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6415 - acc: 0.4652Epoch 01182: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6413 - acc: 0.4653 - val_loss: 5.4719 - val_acc: 0.4993\n",
      "Epoch 1184/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6392 - acc: 0.4655Epoch 01183: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6407 - acc: 0.4653 - val_loss: 5.4716 - val_acc: 0.4993\n",
      "Epoch 1185/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6334 - acc: 0.4657Epoch 01184: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6356 - acc: 0.4653 - val_loss: 5.4714 - val_acc: 0.4993\n",
      "Epoch 1186/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6335 - acc: 0.4650Epoch 01185: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6321 - acc: 0.4653 - val_loss: 5.4709 - val_acc: 0.4993\n",
      "Epoch 1187/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6325 - acc: 0.4650Epoch 01186: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6312 - acc: 0.4653 - val_loss: 5.4706 - val_acc: 0.4993\n",
      "Epoch 1188/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6343 - acc: 0.4656Epoch 01187: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6362 - acc: 0.4653 - val_loss: 5.4703 - val_acc: 0.4993\n",
      "Epoch 1189/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6366 - acc: 0.4654Epoch 01188: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6377 - acc: 0.4653 - val_loss: 5.4701 - val_acc: 0.4993\n",
      "Epoch 1190/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6371 - acc: 0.4650Epoch 01189: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6371 - acc: 0.4651 - val_loss: 5.4698 - val_acc: 0.4993\n",
      "Epoch 1191/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6410 - acc: 0.4650Epoch 01190: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6396 - acc: 0.4653 - val_loss: 5.4697 - val_acc: 0.4993\n",
      "Epoch 1192/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6350 - acc: 0.4650Epoch 01191: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6337 - acc: 0.4653 - val_loss: 5.4695 - val_acc: 0.4993\n",
      "Epoch 1193/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6386 - acc: 0.4656Epoch 01192: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6407 - acc: 0.4653 - val_loss: 5.4694 - val_acc: 0.4993\n",
      "Epoch 1194/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6430 - acc: 0.4648Epoch 01193: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6405 - acc: 0.4653 - val_loss: 5.4693 - val_acc: 0.4993\n",
      "Epoch 1195/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6279 - acc: 0.4658Epoch 01194: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6304 - acc: 0.4653 - val_loss: 5.4689 - val_acc: 0.4993\n",
      "Epoch 1196/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6276 - acc: 0.4653Epoch 01195: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6277 - acc: 0.4653 - val_loss: 5.4686 - val_acc: 0.4993\n",
      "Epoch 1197/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6310 - acc: 0.4649Epoch 01196: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6295 - acc: 0.4653 - val_loss: 5.4683 - val_acc: 0.4993\n",
      "Epoch 1198/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6330 - acc: 0.4654Epoch 01197: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6340 - acc: 0.4653 - val_loss: 5.4680 - val_acc: 0.4993\n",
      "Epoch 1199/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6330 - acc: 0.4659Epoch 01198: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6357 - acc: 0.4653 - val_loss: 5.4679 - val_acc: 0.4993\n",
      "Epoch 1200/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6349 - acc: 0.4650Epoch 01199: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6334 - acc: 0.4653 - val_loss: 5.4678 - val_acc: 0.4993\n",
      "Epoch 1201/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6360 - acc: 0.4650Epoch 01200: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6346 - acc: 0.4653 - val_loss: 5.4676 - val_acc: 0.4993\n",
      "Epoch 1202/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6381 - acc: 0.4653Epoch 01201: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6375 - acc: 0.4653 - val_loss: 5.4675 - val_acc: 0.4993\n",
      "Epoch 1203/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6343 - acc: 0.4651Epoch 01202: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6335 - acc: 0.4653 - val_loss: 5.4672 - val_acc: 0.4993\n",
      "Epoch 1204/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6256 - acc: 0.4658Epoch 01203: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6286 - acc: 0.4653 - val_loss: 5.4669 - val_acc: 0.4993\n",
      "Epoch 1205/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6361 - acc: 0.4655Epoch 01204: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6366 - acc: 0.4653 - val_loss: 5.4668 - val_acc: 0.4993\n",
      "Epoch 1206/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6269 - acc: 0.4656Epoch 01205: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6281 - acc: 0.4653 - val_loss: 5.4666 - val_acc: 0.4993\n",
      "Epoch 1207/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6349 - acc: 0.4653Epoch 01206: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6356 - acc: 0.4652 - val_loss: 5.4664 - val_acc: 0.4993\n",
      "Epoch 1208/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6378 - acc: 0.4653Epoch 01207: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6388 - acc: 0.4652 - val_loss: 5.4663 - val_acc: 0.4993\n",
      "Epoch 1209/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6319 - acc: 0.4652Epoch 01208: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6309 - acc: 0.4653 - val_loss: 5.4661 - val_acc: 0.4993\n",
      "Epoch 1210/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6300 - acc: 0.4653Epoch 01209: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6298 - acc: 0.4653 - val_loss: 5.4658 - val_acc: 0.4993\n",
      "Epoch 1211/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6310 - acc: 0.4650Epoch 01210: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6297 - acc: 0.4653 - val_loss: 5.4655 - val_acc: 0.4993\n",
      "Epoch 1212/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6250 - acc: 0.4652Epoch 01211: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6251 - acc: 0.4653 - val_loss: 5.4652 - val_acc: 0.4993\n",
      "Epoch 1213/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6324 - acc: 0.4651Epoch 01212: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6312 - acc: 0.4653 - val_loss: 5.4650 - val_acc: 0.4993\n",
      "Epoch 1214/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6307 - acc: 0.4652Epoch 01213: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6311 - acc: 0.4653 - val_loss: 5.4647 - val_acc: 0.4993\n",
      "Epoch 1215/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6282 - acc: 0.4651Epoch 01214: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6278 - acc: 0.4653 - val_loss: 5.4644 - val_acc: 0.4993\n",
      "Epoch 1216/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6394 - acc: 0.4654Epoch 01215: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6404 - acc: 0.4653 - val_loss: 5.4645 - val_acc: 0.4993\n",
      "Epoch 1217/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6292 - acc: 0.4657Epoch 01216: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6316 - acc: 0.4653 - val_loss: 5.4643 - val_acc: 0.4993\n",
      "Epoch 1218/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6283 - acc: 0.4656Epoch 01217: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6301 - acc: 0.4653 - val_loss: 5.4640 - val_acc: 0.4993\n",
      "Epoch 1219/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6282 - acc: 0.4654Epoch 01218: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6290 - acc: 0.4653 - val_loss: 5.4638 - val_acc: 0.4993\n",
      "Epoch 1220/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6266 - acc: 0.4649Epoch 01219: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6248 - acc: 0.4653 - val_loss: 5.4636 - val_acc: 0.4993\n",
      "Epoch 1221/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6361 - acc: 0.4648Epoch 01220: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6340 - acc: 0.4653 - val_loss: 5.4635 - val_acc: 0.4993\n",
      "Epoch 1222/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6249 - acc: 0.4651Epoch 01221: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6239 - acc: 0.4653 - val_loss: 5.4631 - val_acc: 0.4993\n",
      "Epoch 1223/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6278 - acc: 0.4656Epoch 01222: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6303 - acc: 0.4653 - val_loss: 5.4629 - val_acc: 0.4993\n",
      "Epoch 1224/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6274 - acc: 0.4652Epoch 01223: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6272 - acc: 0.4653 - val_loss: 5.4626 - val_acc: 0.4993\n",
      "Epoch 1225/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6268 - acc: 0.4652Epoch 01224: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6266 - acc: 0.4653 - val_loss: 5.4624 - val_acc: 0.4993\n",
      "Epoch 1226/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6305 - acc: 0.4654Epoch 01225: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6321 - acc: 0.4653 - val_loss: 5.4623 - val_acc: 0.4993\n",
      "Epoch 1227/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6291 - acc: 0.4653Epoch 01226: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6293 - acc: 0.4653 - val_loss: 5.4622 - val_acc: 0.4993\n",
      "Epoch 1228/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6310 - acc: 0.4652Epoch 01227: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6306 - acc: 0.4653 - val_loss: 5.4620 - val_acc: 0.4993\n",
      "Epoch 1229/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6310 - acc: 0.4645Epoch 01228: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6267 - acc: 0.4653 - val_loss: 5.4617 - val_acc: 0.4993\n",
      "Epoch 1230/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6185 - acc: 0.4655Epoch 01229: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6200 - acc: 0.4653 - val_loss: 5.4613 - val_acc: 0.4993\n",
      "Epoch 1231/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6304 - acc: 0.4653Epoch 01230: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6310 - acc: 0.4653 - val_loss: 5.4613 - val_acc: 0.4993\n",
      "Epoch 1232/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6247 - acc: 0.4654Epoch 01231: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6263 - acc: 0.4653 - val_loss: 5.4611 - val_acc: 0.4993\n",
      "Epoch 1233/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6252 - acc: 0.4657Epoch 01232: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6277 - acc: 0.4653 - val_loss: 5.4608 - val_acc: 0.4993\n",
      "Epoch 1234/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6267 - acc: 0.4650Epoch 01233: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6254 - acc: 0.4653 - val_loss: 5.4606 - val_acc: 0.4993\n",
      "Epoch 1235/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6257 - acc: 0.4653Epoch 01234: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6256 - acc: 0.4653 - val_loss: 5.4603 - val_acc: 0.4993\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.6184 - acc: 0.4655Epoch 01235: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6205 - acc: 0.4653 - val_loss: 5.4600 - val_acc: 0.4993\n",
      "Epoch 1237/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6229 - acc: 0.4649Epoch 01236: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6212 - acc: 0.4653 - val_loss: 5.4597 - val_acc: 0.4993\n",
      "Epoch 1238/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6250 - acc: 0.4652Epoch 01237: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6245 - acc: 0.4653 - val_loss: 5.4595 - val_acc: 0.4993\n",
      "Epoch 1239/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6315 - acc: 0.4656Epoch 01238: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6336 - acc: 0.4653 - val_loss: 5.4596 - val_acc: 0.4993\n",
      "Epoch 1240/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6211 - acc: 0.4661Epoch 01239: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6259 - acc: 0.4653 - val_loss: 5.4594 - val_acc: 0.4993\n",
      "Epoch 1241/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6276 - acc: 0.4650Epoch 01240: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6266 - acc: 0.4653 - val_loss: 5.4592 - val_acc: 0.4993\n",
      "Epoch 1242/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6283 - acc: 0.4652Epoch 01241: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6284 - acc: 0.4653 - val_loss: 5.4590 - val_acc: 0.4993\n",
      "Epoch 1243/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6225 - acc: 0.4657Epoch 01242: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6250 - acc: 0.4653 - val_loss: 5.4589 - val_acc: 0.4993\n",
      "Epoch 1244/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6281 - acc: 0.4649Epoch 01243: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6259 - acc: 0.4653 - val_loss: 5.4587 - val_acc: 0.4993\n",
      "Epoch 1245/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6166 - acc: 0.4654Epoch 01244: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6172 - acc: 0.4653 - val_loss: 5.4583 - val_acc: 0.4993\n",
      "Epoch 1246/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6222 - acc: 0.4653Epoch 01245: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6219 - acc: 0.4653 - val_loss: 5.4580 - val_acc: 0.4993\n",
      "Epoch 1247/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6166 - acc: 0.4650Epoch 01246: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6153 - acc: 0.4653 - val_loss: 5.4577 - val_acc: 0.4993\n",
      "Epoch 1248/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6117 - acc: 0.4655Epoch 01247: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6130 - acc: 0.4653 - val_loss: 5.4572 - val_acc: 0.4993\n",
      "Epoch 1249/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6224 - acc: 0.4655Epoch 01248: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6228 - acc: 0.4653 - val_loss: 5.4570 - val_acc: 0.4993\n",
      "Epoch 1250/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6151 - acc: 0.4648Epoch 01249: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6124 - acc: 0.4653 - val_loss: 5.4566 - val_acc: 0.4993\n",
      "Epoch 1251/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6182 - acc: 0.4651Epoch 01250: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6170 - acc: 0.4653 - val_loss: 5.4563 - val_acc: 0.4993\n",
      "Epoch 1252/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6245 - acc: 0.4652Epoch 01251: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6244 - acc: 0.4653 - val_loss: 5.4562 - val_acc: 0.4993\n",
      "Epoch 1253/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6240 - acc: 0.4648Epoch 01252: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6217 - acc: 0.4653 - val_loss: 5.4560 - val_acc: 0.4993\n",
      "Epoch 1254/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6184 - acc: 0.4655Epoch 01253: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6199 - acc: 0.4653 - val_loss: 5.4560 - val_acc: 0.4993\n",
      "Epoch 1255/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6236 - acc: 0.4654Epoch 01254: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6238 - acc: 0.4653 - val_loss: 5.4558 - val_acc: 0.4993\n",
      "Epoch 1256/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6185 - acc: 0.4648Epoch 01255: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6164 - acc: 0.4653 - val_loss: 5.4556 - val_acc: 0.4993\n",
      "Epoch 1257/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6245 - acc: 0.4650Epoch 01256: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6228 - acc: 0.4653 - val_loss: 5.4554 - val_acc: 0.4993\n",
      "Epoch 1258/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6168 - acc: 0.4655Epoch 01257: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6181 - acc: 0.4653 - val_loss: 5.4550 - val_acc: 0.4993\n",
      "Epoch 1259/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6263 - acc: 0.4650Epoch 01258: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6254 - acc: 0.4652 - val_loss: 5.4549 - val_acc: 0.4993\n",
      "Epoch 1260/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6148 - acc: 0.4653Epoch 01259: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6152 - acc: 0.4653 - val_loss: 5.4546 - val_acc: 0.4993\n",
      "Epoch 1261/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6224 - acc: 0.4659Epoch 01260: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6259 - acc: 0.4653 - val_loss: 5.4547 - val_acc: 0.4993\n",
      "Epoch 1262/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6155 - acc: 0.4650Epoch 01261: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6148 - acc: 0.4653 - val_loss: 5.4544 - val_acc: 0.4993\n",
      "Epoch 1263/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6225 - acc: 0.4649Epoch 01262: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6209 - acc: 0.4653 - val_loss: 5.4542 - val_acc: 0.4993\n",
      "Epoch 1264/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6135 - acc: 0.4655Epoch 01263: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6144 - acc: 0.4653 - val_loss: 5.4540 - val_acc: 0.4993\n",
      "Epoch 1265/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6181 - acc: 0.4653Epoch 01264: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6186 - acc: 0.4653 - val_loss: 5.4536 - val_acc: 0.4993\n",
      "Epoch 1266/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6199 - acc: 0.4650Epoch 01265: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6186 - acc: 0.4653 - val_loss: 5.4533 - val_acc: 0.4993\n",
      "Epoch 1267/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6178 - acc: 0.4654Epoch 01266: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6186 - acc: 0.4653 - val_loss: 5.4532 - val_acc: 0.4993\n",
      "Epoch 1268/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6249 - acc: 0.4650Epoch 01267: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6241 - acc: 0.4653 - val_loss: 5.4532 - val_acc: 0.4993\n",
      "Epoch 1269/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6167 - acc: 0.4654Epoch 01268: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6178 - acc: 0.4653 - val_loss: 5.4529 - val_acc: 0.4993\n",
      "Epoch 1270/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6276 - acc: 0.4652Epoch 01269: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6270 - acc: 0.4653 - val_loss: 5.4529 - val_acc: 0.4993\n",
      "Epoch 1271/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6196 - acc: 0.4649Epoch 01270: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6179 - acc: 0.4653 - val_loss: 5.4527 - val_acc: 0.4993\n",
      "Epoch 1272/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6188 - acc: 0.4649Epoch 01271: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6177 - acc: 0.4652 - val_loss: 5.4525 - val_acc: 0.4993\n",
      "Epoch 1273/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6140 - acc: 0.4650Epoch 01272: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6129 - acc: 0.4653 - val_loss: 5.4522 - val_acc: 0.4993\n",
      "Epoch 1274/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6172 - acc: 0.4648Epoch 01273: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6144 - acc: 0.4653 - val_loss: 5.4520 - val_acc: 0.4993\n",
      "Epoch 1275/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6215 - acc: 0.4655Epoch 01274: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6227 - acc: 0.4653 - val_loss: 5.4519 - val_acc: 0.4993\n",
      "Epoch 1276/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6158 - acc: 0.4652Epoch 01275: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6151 - acc: 0.4653 - val_loss: 5.4518 - val_acc: 0.4993\n",
      "Epoch 1277/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6075 - acc: 0.4659Epoch 01276: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6108 - acc: 0.4653 - val_loss: 5.4514 - val_acc: 0.4993\n",
      "Epoch 1278/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6159 - acc: 0.4649Epoch 01277: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6142 - acc: 0.4653 - val_loss: 5.4512 - val_acc: 0.4993\n",
      "Epoch 1279/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6166 - acc: 0.4650Epoch 01278: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6150 - acc: 0.4653 - val_loss: 5.4510 - val_acc: 0.4993\n",
      "Epoch 1280/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6215 - acc: 0.4646Epoch 01279: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6178 - acc: 0.4653 - val_loss: 5.4508 - val_acc: 0.4993\n",
      "Epoch 1281/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6173 - acc: 0.4656Epoch 01280: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6191 - acc: 0.4653 - val_loss: 5.4506 - val_acc: 0.4993\n",
      "Epoch 1282/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6071 - acc: 0.4658Epoch 01281: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6099 - acc: 0.4653 - val_loss: 5.4503 - val_acc: 0.4993\n",
      "Epoch 1283/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6285 - acc: 0.4646Epoch 01282: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6272 - acc: 0.4649 - val_loss: 5.4504 - val_acc: 0.4993\n",
      "Epoch 1284/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6181 - acc: 0.4654Epoch 01283: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.6190 - acc: 0.4653 - val_loss: 5.4502 - val_acc: 0.4993\n",
      "Epoch 1285/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6154 - acc: 0.4655Epoch 01284: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6169 - acc: 0.4653 - val_loss: 5.4500 - val_acc: 0.4993\n",
      "Epoch 1286/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6144 - acc: 0.4656Epoch 01285: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6163 - acc: 0.4653 - val_loss: 5.4498 - val_acc: 0.4993\n",
      "Epoch 1287/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6096 - acc: 0.4652Epoch 01286: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6092 - acc: 0.4653 - val_loss: 5.4495 - val_acc: 0.4993\n",
      "Epoch 1288/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6268 - acc: 0.4652Epoch 01287: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6269 - acc: 0.4653 - val_loss: 5.4494 - val_acc: 0.4993\n",
      "Epoch 1289/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6126 - acc: 0.4654Epoch 01288: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6134 - acc: 0.4653 - val_loss: 5.4493 - val_acc: 0.4993\n",
      "Epoch 1290/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6130 - acc: 0.4651Epoch 01289: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6113 - acc: 0.4653 - val_loss: 5.4489 - val_acc: 0.4993\n",
      "Epoch 1291/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6177 - acc: 0.4651Epoch 01290: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6170 - acc: 0.4653 - val_loss: 5.4488 - val_acc: 0.4993\n",
      "Epoch 1292/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6173 - acc: 0.4646Epoch 01291: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6138 - acc: 0.4653 - val_loss: 5.4487 - val_acc: 0.4993\n",
      "Epoch 1293/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.6162 - acc: 0.4651Epoch 01292: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6155 - acc: 0.4653 - val_loss: 5.4485 - val_acc: 0.4993\n",
      "Epoch 1294/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6146 - acc: 0.4645Epoch 01293: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6109 - acc: 0.4653 - val_loss: 5.4483 - val_acc: 0.4993\n",
      "Epoch 1295/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6104 - acc: 0.4650Epoch 01294: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6085 - acc: 0.4653 - val_loss: 5.4479 - val_acc: 0.4993\n",
      "Epoch 1296/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6174 - acc: 0.4653Epoch 01295: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6172 - acc: 0.4653 - val_loss: 5.4479 - val_acc: 0.4993\n",
      "Epoch 1297/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6081 - acc: 0.4655Epoch 01296: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6094 - acc: 0.4653 - val_loss: 5.4476 - val_acc: 0.4993\n",
      "Epoch 1298/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6090 - acc: 0.4653Epoch 01297: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6092 - acc: 0.4653 - val_loss: 5.4473 - val_acc: 0.4993\n",
      "Epoch 1299/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6059 - acc: 0.4653Epoch 01298: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6057 - acc: 0.4653 - val_loss: 5.4469 - val_acc: 0.4993\n",
      "Epoch 1300/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6115 - acc: 0.4657Epoch 01299: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6140 - acc: 0.4653 - val_loss: 5.4468 - val_acc: 0.4993\n",
      "Epoch 1301/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6111 - acc: 0.4656Epoch 01300: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6127 - acc: 0.4653 - val_loss: 5.4467 - val_acc: 0.4993\n",
      "Epoch 1302/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6144 - acc: 0.4653Epoch 01301: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6145 - acc: 0.4653 - val_loss: 5.4466 - val_acc: 0.4993\n",
      "Epoch 1303/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6225 - acc: 0.4645Epoch 01302: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6184 - acc: 0.4653 - val_loss: 5.4465 - val_acc: 0.4993\n",
      "Epoch 1304/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6081 - acc: 0.4652Epoch 01303: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6078 - acc: 0.4653 - val_loss: 5.4462 - val_acc: 0.4993\n",
      "Epoch 1305/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6071 - acc: 0.4658Epoch 01304: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6098 - acc: 0.4653 - val_loss: 5.4460 - val_acc: 0.4993\n",
      "Epoch 1306/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6098 - acc: 0.4656Epoch 01305: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6116 - acc: 0.4653 - val_loss: 5.4458 - val_acc: 0.4993\n",
      "Epoch 1307/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6068 - acc: 0.4653Epoch 01306: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6076 - acc: 0.4653 - val_loss: 5.4456 - val_acc: 0.4993\n",
      "Epoch 1308/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6052 - acc: 0.4658Epoch 01307: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6081 - acc: 0.4653 - val_loss: 5.4453 - val_acc: 0.4993\n",
      "Epoch 1309/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6076 - acc: 0.4650Epoch 01308: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6064 - acc: 0.4653 - val_loss: 5.4450 - val_acc: 0.4993\n",
      "Epoch 1310/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6110 - acc: 0.4649Epoch 01309: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6091 - acc: 0.4653 - val_loss: 5.4448 - val_acc: 0.4993\n",
      "Epoch 1311/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6129 - acc: 0.4657Epoch 01310: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6150 - acc: 0.4653 - val_loss: 5.4447 - val_acc: 0.4993\n",
      "Epoch 1312/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6077 - acc: 0.4650Epoch 01311: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6066 - acc: 0.4653 - val_loss: 5.4444 - val_acc: 0.4993\n",
      "Epoch 1313/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6081 - acc: 0.4651Epoch 01312: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6077 - acc: 0.4653 - val_loss: 5.4442 - val_acc: 0.4993\n",
      "Epoch 1314/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6048 - acc: 0.4652Epoch 01313: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6048 - acc: 0.4653 - val_loss: 5.4439 - val_acc: 0.4993\n",
      "Epoch 1315/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5972 - acc: 0.4660Epoch 01314: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6010 - acc: 0.4653 - val_loss: 5.4436 - val_acc: 0.4993\n",
      "Epoch 1316/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6101 - acc: 0.4649Epoch 01315: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6079 - acc: 0.4653 - val_loss: 5.4433 - val_acc: 0.4993\n",
      "Epoch 1317/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6034 - acc: 0.4655Epoch 01316: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6046 - acc: 0.4653 - val_loss: 5.4429 - val_acc: 0.4993\n",
      "Epoch 1318/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6050 - acc: 0.4653Epoch 01317: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6050 - acc: 0.4653 - val_loss: 5.4426 - val_acc: 0.4993\n",
      "Epoch 1319/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6093 - acc: 0.4652Epoch 01318: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6089 - acc: 0.4653 - val_loss: 5.4425 - val_acc: 0.4993\n",
      "Epoch 1320/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6078 - acc: 0.4652Epoch 01319: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6070 - acc: 0.4653 - val_loss: 5.4423 - val_acc: 0.4993\n",
      "Epoch 1321/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6060 - acc: 0.4642Epoch 01320: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6005 - acc: 0.4653 - val_loss: 5.4420 - val_acc: 0.4993\n",
      "Epoch 1322/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6080 - acc: 0.4652Epoch 01321: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6079 - acc: 0.4653 - val_loss: 5.4418 - val_acc: 0.4993\n",
      "Epoch 1323/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6003 - acc: 0.4650Epoch 01322: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.5990 - acc: 0.4653 - val_loss: 5.4414 - val_acc: 0.4993\n",
      "Epoch 1324/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5997 - acc: 0.4653Epoch 01323: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6000 - acc: 0.4653 - val_loss: 5.4411 - val_acc: 0.4993\n",
      "Epoch 1325/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6117 - acc: 0.4645Epoch 01324: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6081 - acc: 0.4653 - val_loss: 5.4409 - val_acc: 0.4993\n",
      "Epoch 1326/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6070 - acc: 0.4652Epoch 01325: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6061 - acc: 0.4653 - val_loss: 5.4407 - val_acc: 0.4993\n",
      "Epoch 1327/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5981 - acc: 0.4657Epoch 01326: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6010 - acc: 0.4653 - val_loss: 5.4405 - val_acc: 0.4993\n",
      "Epoch 1328/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6027 - acc: 0.4653Epoch 01327: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6029 - acc: 0.4653 - val_loss: 5.4403 - val_acc: 0.4993\n",
      "Epoch 1329/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5997 - acc: 0.4651Epoch 01328: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.5990 - acc: 0.4653 - val_loss: 5.4402 - val_acc: 0.4993\n",
      "Epoch 1330/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6031 - acc: 0.4656Epoch 01329: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6049 - acc: 0.4653 - val_loss: 5.4399 - val_acc: 0.4993\n",
      "Epoch 1331/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6111 - acc: 0.4651Epoch 01330: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6100 - acc: 0.4652 - val_loss: 5.4397 - val_acc: 0.4993\n",
      "Epoch 1332/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6000 - acc: 0.4654Epoch 01331: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6006 - acc: 0.4653 - val_loss: 5.4395 - val_acc: 0.4993\n",
      "Epoch 1333/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6004 - acc: 0.4659Epoch 01332: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6037 - acc: 0.4653 - val_loss: 5.4394 - val_acc: 0.4993\n",
      "Epoch 1334/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6080 - acc: 0.4648Epoch 01333: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6057 - acc: 0.4653 - val_loss: 5.4393 - val_acc: 0.4993\n",
      "Epoch 1335/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6133 - acc: 0.4657Epoch 01334: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6152 - acc: 0.4653 - val_loss: 5.4393 - val_acc: 0.4993\n",
      "Epoch 1336/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6037 - acc: 0.4653Epoch 01335: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6035 - acc: 0.4653 - val_loss: 5.4392 - val_acc: 0.4993\n",
      "Epoch 1337/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5937 - acc: 0.4661Epoch 01336: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.5978 - acc: 0.4653 - val_loss: 5.4389 - val_acc: 0.4993\n",
      "Epoch 1338/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6113 - acc: 0.4649Epoch 01337: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6092 - acc: 0.4653 - val_loss: 5.4389 - val_acc: 0.4993\n",
      "Epoch 1339/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6085 - acc: 0.4654Epoch 01338: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6095 - acc: 0.4653 - val_loss: 5.4389 - val_acc: 0.4993\n",
      "Epoch 1340/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6001 - acc: 0.4653Epoch 01339: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.5999 - acc: 0.4653 - val_loss: 5.4388 - val_acc: 0.4993\n",
      "Epoch 1341/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6016 - acc: 0.4654Epoch 01340: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6027 - acc: 0.4653 - val_loss: 5.4385 - val_acc: 0.4993\n",
      "Epoch 1342/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6055 - acc: 0.4649Epoch 01341: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6040 - acc: 0.4653 - val_loss: 5.4383 - val_acc: 0.4993\n",
      "Epoch 1343/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6018 - acc: 0.4656Epoch 01342: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6032 - acc: 0.4653 - val_loss: 5.4382 - val_acc: 0.4993\n",
      "Epoch 1344/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6033 - acc: 0.4653Epoch 01343: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6038 - acc: 0.4653 - val_loss: 5.4379 - val_acc: 0.4993\n",
      "Epoch 1345/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6045 - acc: 0.4653Epoch 01344: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6052 - acc: 0.4653 - val_loss: 5.4378 - val_acc: 0.4993\n",
      "Epoch 1346/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6077 - acc: 0.4653Epoch 01345: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6078 - acc: 0.4653 - val_loss: 5.4377 - val_acc: 0.4993\n",
      "Epoch 1347/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6074 - acc: 0.4646Epoch 01346: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6041 - acc: 0.4653 - val_loss: 5.4377 - val_acc: 0.4993\n",
      "Epoch 1348/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6121 - acc: 0.4652Epoch 01347: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6112 - acc: 0.4653 - val_loss: 5.4375 - val_acc: 0.4993\n",
      "Epoch 1349/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6046 - acc: 0.4656Epoch 01348: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6065 - acc: 0.4653 - val_loss: 5.4375 - val_acc: 0.4993\n",
      "Epoch 1350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.5996 - acc: 0.4654Epoch 01349: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6001 - acc: 0.4653 - val_loss: 5.4372 - val_acc: 0.4993\n",
      "Epoch 1351/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6049 - acc: 0.4652Epoch 01350: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6051 - acc: 0.4653 - val_loss: 5.4371 - val_acc: 0.4993\n",
      "Epoch 1352/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5963 - acc: 0.4654Epoch 01351: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.5964 - acc: 0.4653 - val_loss: 5.4368 - val_acc: 0.4993\n",
      "Epoch 1353/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5952 - acc: 0.4656Epoch 01352: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.5972 - acc: 0.4653 - val_loss: 5.4365 - val_acc: 0.4993\n",
      "Epoch 1354/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6014 - acc: 0.4653Epoch 01353: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.6019 - acc: 0.4653 - val_loss: 5.4363 - val_acc: 0.4993\n",
      "Epoch 1355/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6075 - acc: 0.4653Epoch 01354: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 176s - loss: 5.6083 - acc: 0.4652 - val_loss: 5.4362 - val_acc: 0.4993\n",
      "Epoch 1356/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6007 - acc: 0.4654Epoch 01355: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 177s - loss: 5.6015 - acc: 0.4653 - val_loss: 5.4362 - val_acc: 0.4993\n",
      "Epoch 1357/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6017 - acc: 0.4656Epoch 01356: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 202s - loss: 5.6032 - acc: 0.4653 - val_loss: 5.4360 - val_acc: 0.4993\n",
      "Epoch 1358/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6043 - acc: 0.4650Epoch 01357: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.6031 - acc: 0.4653 - val_loss: 5.4359 - val_acc: 0.4993\n",
      "Epoch 1359/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6006 - acc: 0.4650Epoch 01358: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.5992 - acc: 0.4653 - val_loss: 5.4356 - val_acc: 0.4993\n",
      "Epoch 1360/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6021 - acc: 0.4651Epoch 01359: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 195s - loss: 5.6007 - acc: 0.4653 - val_loss: 5.4354 - val_acc: 0.4993\n",
      "Epoch 1361/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6046 - acc: 0.4644Epoch 01360: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.6006 - acc: 0.4653 - val_loss: 5.4354 - val_acc: 0.4993\n",
      "Epoch 1362/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6027 - acc: 0.4652Epoch 01361: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.6027 - acc: 0.4653 - val_loss: 5.4352 - val_acc: 0.4993\n",
      "Epoch 1363/2000\n",
      "758/760 [============================>.] - ETA: 5s - loss: 5.6046 - acc: 0.4644 Epoch 01362: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 2008s - loss: 5.6002 - acc: 0.4653 - val_loss: 5.4351 - val_acc: 0.4993\n",
      "Epoch 1364/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6054 - acc: 0.4646Epoch 01363: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.6015 - acc: 0.4653 - val_loss: 5.4350 - val_acc: 0.4993\n",
      "Epoch 1365/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5990 - acc: 0.4651Epoch 01364: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5984 - acc: 0.4653 - val_loss: 5.4346 - val_acc: 0.4993\n",
      "Epoch 1366/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6100 - acc: 0.4649Epoch 01365: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.6090 - acc: 0.4653 - val_loss: 5.4346 - val_acc: 0.4993\n",
      "Epoch 1367/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5960 - acc: 0.4653Epoch 01366: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.5956 - acc: 0.4653 - val_loss: 5.4344 - val_acc: 0.4993\n",
      "Epoch 1368/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5948 - acc: 0.4654Epoch 01367: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.5960 - acc: 0.4653 - val_loss: 5.4342 - val_acc: 0.4993\n",
      "Epoch 1369/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5979 - acc: 0.4653Epoch 01368: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.5986 - acc: 0.4653 - val_loss: 5.4341 - val_acc: 0.4993\n",
      "Epoch 1370/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5909 - acc: 0.4648Epoch 01369: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.5891 - acc: 0.4653 - val_loss: 5.4337 - val_acc: 0.4993\n",
      "Epoch 1371/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5980 - acc: 0.4649Epoch 01370: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.5963 - acc: 0.4653 - val_loss: 5.4335 - val_acc: 0.4993\n",
      "Epoch 1372/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6014 - acc: 0.4652Epoch 01371: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6011 - acc: 0.4653 - val_loss: 5.4334 - val_acc: 0.4993\n",
      "Epoch 1373/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5900 - acc: 0.4659Epoch 01372: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.5931 - acc: 0.4653 - val_loss: 5.4333 - val_acc: 0.4993\n",
      "Epoch 1374/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5923 - acc: 0.4657Epoch 01373: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5948 - acc: 0.4653 - val_loss: 5.4330 - val_acc: 0.4993\n",
      "Epoch 1375/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5979 - acc: 0.4652Epoch 01374: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.5982 - acc: 0.4653 - val_loss: 5.4329 - val_acc: 0.4993\n",
      "Epoch 1376/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5978 - acc: 0.4648Epoch 01375: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.5953 - acc: 0.4653 - val_loss: 5.4326 - val_acc: 0.4993\n",
      "Epoch 1377/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6001 - acc: 0.4653Epoch 01376: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.6003 - acc: 0.4653 - val_loss: 5.4326 - val_acc: 0.4993\n",
      "Epoch 1378/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5898 - acc: 0.4656Epoch 01377: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.5919 - acc: 0.4653 - val_loss: 5.4321 - val_acc: 0.4993\n",
      "Epoch 1379/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5961 - acc: 0.4650Epoch 01378: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.5942 - acc: 0.4653 - val_loss: 5.4320 - val_acc: 0.4993\n",
      "Epoch 1380/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6025 - acc: 0.4652Epoch 01379: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6024 - acc: 0.4653 - val_loss: 5.4320 - val_acc: 0.4993\n",
      "Epoch 1381/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5983 - acc: 0.4658Epoch 01380: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.6006 - acc: 0.4653 - val_loss: 5.4319 - val_acc: 0.4993\n",
      "Epoch 1382/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5957 - acc: 0.4652Epoch 01381: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 205s - loss: 5.5954 - acc: 0.4653 - val_loss: 5.4316 - val_acc: 0.4993\n",
      "Epoch 1383/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5991 - acc: 0.4645Epoch 01382: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 204s - loss: 5.5954 - acc: 0.4652 - val_loss: 5.4315 - val_acc: 0.4993\n",
      "Epoch 1384/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5930 - acc: 0.4651Epoch 01383: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.5923 - acc: 0.4653 - val_loss: 5.4312 - val_acc: 0.4993\n",
      "Epoch 1385/2000\n",
      "758/760 [============================>.] - ETA: 1s - loss: 5.5939 - acc: 0.4656Epoch 01384: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 736s - loss: 5.5957 - acc: 0.4653 - val_loss: 5.4311 - val_acc: 0.4993\n",
      "Epoch 1386/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5865 - acc: 0.4655Epoch 01385: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.5871 - acc: 0.4653 - val_loss: 5.4308 - val_acc: 0.4993\n",
      "Epoch 1387/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5968 - acc: 0.4650Epoch 01386: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.5943 - acc: 0.4653 - val_loss: 5.4306 - val_acc: 0.4993\n",
      "Epoch 1388/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6023 - acc: 0.4653Epoch 01387: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 178s - loss: 5.6022 - acc: 0.4653 - val_loss: 5.4306 - val_acc: 0.4993\n",
      "Epoch 1389/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5925 - acc: 0.4653Epoch 01388: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.5931 - acc: 0.4653 - val_loss: 5.4305 - val_acc: 0.4993\n",
      "Epoch 1390/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6050 - acc: 0.4652Epoch 01389: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 179s - loss: 5.6050 - acc: 0.4653 - val_loss: 5.4306 - val_acc: 0.4993\n",
      "Epoch 1391/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6064 - acc: 0.4648Epoch 01390: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.6042 - acc: 0.4653 - val_loss: 5.4305 - val_acc: 0.4993\n",
      "Epoch 1392/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5989 - acc: 0.4648Epoch 01391: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.5970 - acc: 0.4653 - val_loss: 5.4305 - val_acc: 0.4993\n",
      "Epoch 1393/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5870 - acc: 0.4654Epoch 01392: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.5876 - acc: 0.4653 - val_loss: 5.4300 - val_acc: 0.4993\n",
      "Epoch 1394/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5959 - acc: 0.4655Epoch 01393: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.5965 - acc: 0.4653 - val_loss: 5.4298 - val_acc: 0.4993\n",
      "Epoch 1395/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5867 - acc: 0.4653Epoch 01394: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.5869 - acc: 0.4653 - val_loss: 5.4295 - val_acc: 0.4993\n",
      "Epoch 1396/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5971 - acc: 0.4647Epoch 01395: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.5941 - acc: 0.4652 - val_loss: 5.4293 - val_acc: 0.4993\n",
      "Epoch 1397/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5893 - acc: 0.4650Epoch 01396: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 188s - loss: 5.5874 - acc: 0.4653 - val_loss: 5.4290 - val_acc: 0.4993\n",
      "Epoch 1398/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5905 - acc: 0.4649Epoch 01397: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.5890 - acc: 0.4653 - val_loss: 5.4287 - val_acc: 0.4993\n",
      "Epoch 1399/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5946 - acc: 0.4654Epoch 01398: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.5951 - acc: 0.4653 - val_loss: 5.4286 - val_acc: 0.4993\n",
      "Epoch 1400/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5921 - acc: 0.4657Epoch 01399: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.5941 - acc: 0.4653 - val_loss: 5.4286 - val_acc: 0.4993\n",
      "Epoch 1401/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5939 - acc: 0.4655Epoch 01400: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 181s - loss: 5.5954 - acc: 0.4653 - val_loss: 5.4285 - val_acc: 0.4993\n",
      "Epoch 1402/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5929 - acc: 0.4651Epoch 01401: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 187s - loss: 5.5926 - acc: 0.4653 - val_loss: 5.4283 - val_acc: 0.4993\n",
      "Epoch 1403/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5904 - acc: 0.4653Epoch 01402: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5908 - acc: 0.4653 - val_loss: 5.4282 - val_acc: 0.4993\n",
      "Epoch 1404/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5957 - acc: 0.4650Epoch 01403: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.5938 - acc: 0.4653 - val_loss: 5.4279 - val_acc: 0.4993\n",
      "Epoch 1405/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.6054 - acc: 0.4651Epoch 01404: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 184s - loss: 5.6042 - acc: 0.4653 - val_loss: 5.4279 - val_acc: 0.4993\n",
      "Epoch 1406/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5877 - acc: 0.4660Epoch 01405: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 194s - loss: 5.5914 - acc: 0.4653 - val_loss: 5.4278 - val_acc: 0.4993\n",
      "Epoch 1407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.5890 - acc: 0.4652Epoch 01406: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 180s - loss: 5.5888 - acc: 0.4653 - val_loss: 5.4275 - val_acc: 0.4993\n",
      "Epoch 1408/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5841 - acc: 0.4658Epoch 01407: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.5863 - acc: 0.4653 - val_loss: 5.4273 - val_acc: 0.4993\n",
      "Epoch 1409/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5964 - acc: 0.4654Epoch 01408: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.5973 - acc: 0.4653 - val_loss: 5.4273 - val_acc: 0.4993\n",
      "Epoch 1410/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5987 - acc: 0.4651Epoch 01409: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.5975 - acc: 0.4653 - val_loss: 5.4272 - val_acc: 0.4993\n",
      "Epoch 1411/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5868 - acc: 0.4659Epoch 01410: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5902 - acc: 0.4653 - val_loss: 5.4269 - val_acc: 0.4993\n",
      "Epoch 1412/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5951 - acc: 0.4648Epoch 01411: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.5927 - acc: 0.4653 - val_loss: 5.4268 - val_acc: 0.4993\n",
      "Epoch 1413/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5867 - acc: 0.4655Epoch 01412: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 5.5884 - acc: 0.4653 - val_loss: 5.4265 - val_acc: 0.4993\n",
      "Epoch 1414/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5871 - acc: 0.4657Epoch 01413: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 5.5893 - acc: 0.4653 - val_loss: 5.4264 - val_acc: 0.4993\n",
      "Epoch 1415/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5899 - acc: 0.4646Epoch 01414: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 5.5863 - acc: 0.4653 - val_loss: 5.4262 - val_acc: 0.4993\n",
      "Epoch 1416/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5919 - acc: 0.4657Epoch 01415: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5935 - acc: 0.4653 - val_loss: 5.4261 - val_acc: 0.4993\n",
      "Epoch 1417/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5872 - acc: 0.4659Epoch 01416: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5903 - acc: 0.4653 - val_loss: 5.4260 - val_acc: 0.4993\n",
      "Epoch 1418/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5875 - acc: 0.4649Epoch 01417: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5859 - acc: 0.4653 - val_loss: 5.4256 - val_acc: 0.4993\n",
      "Epoch 1419/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5904 - acc: 0.4652Epoch 01418: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5901 - acc: 0.4653 - val_loss: 5.4254 - val_acc: 0.4993\n",
      "Epoch 1420/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5805 - acc: 0.4659Epoch 01419: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 175s - loss: 5.5839 - acc: 0.4653 - val_loss: 5.4252 - val_acc: 0.4993\n",
      "Epoch 1421/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5933 - acc: 0.4649Epoch 01420: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5915 - acc: 0.4653 - val_loss: 5.4250 - val_acc: 0.4993\n",
      "Epoch 1422/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5928 - acc: 0.4655Epoch 01421: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5939 - acc: 0.4653 - val_loss: 5.4250 - val_acc: 0.4993\n",
      "Epoch 1423/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5967 - acc: 0.4648Epoch 01422: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 174s - loss: 5.5944 - acc: 0.4653 - val_loss: 5.4249 - val_acc: 0.4993\n",
      "Epoch 1424/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5891 - acc: 0.4657Epoch 01423: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5909 - acc: 0.4653 - val_loss: 5.4249 - val_acc: 0.4993\n",
      "Epoch 1425/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5908 - acc: 0.4656Epoch 01424: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5924 - acc: 0.4653 - val_loss: 5.4247 - val_acc: 0.4993\n",
      "Epoch 1426/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5895 - acc: 0.4655Epoch 01425: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 172s - loss: 5.5905 - acc: 0.4653 - val_loss: 5.4245 - val_acc: 0.4993\n",
      "Epoch 1427/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5885 - acc: 0.4653Epoch 01426: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5886 - acc: 0.4653 - val_loss: 5.4245 - val_acc: 0.4993\n",
      "Epoch 1428/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5905 - acc: 0.4648Epoch 01427: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5879 - acc: 0.4653 - val_loss: 5.4242 - val_acc: 0.4993\n",
      "Epoch 1429/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5803 - acc: 0.4660Epoch 01428: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5844 - acc: 0.4653 - val_loss: 5.4240 - val_acc: 0.4993\n",
      "Epoch 1430/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5932 - acc: 0.4648Epoch 01429: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 172s - loss: 5.5907 - acc: 0.4653 - val_loss: 5.4238 - val_acc: 0.4993\n",
      "Epoch 1431/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5880 - acc: 0.4650Epoch 01430: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5874 - acc: 0.4652 - val_loss: 5.4236 - val_acc: 0.4993\n",
      "Epoch 1432/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5828 - acc: 0.4649Epoch 01431: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 172s - loss: 5.5808 - acc: 0.4653 - val_loss: 5.4234 - val_acc: 0.4993\n",
      "Epoch 1433/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5913 - acc: 0.4653Epoch 01432: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5909 - acc: 0.4653 - val_loss: 5.4232 - val_acc: 0.4993\n",
      "Epoch 1434/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5847 - acc: 0.4654Epoch 01433: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 172s - loss: 5.5861 - acc: 0.4653 - val_loss: 5.4231 - val_acc: 0.4993\n",
      "Epoch 1435/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5909 - acc: 0.4653Epoch 01434: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 173s - loss: 5.5912 - acc: 0.4653 - val_loss: 5.4231 - val_acc: 0.4993\n",
      "Epoch 1436/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5879 - acc: 0.4650Epoch 01435: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.5864 - acc: 0.4653 - val_loss: 5.4229 - val_acc: 0.4993\n",
      "Epoch 1437/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5871 - acc: 0.4654Epoch 01436: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 182s - loss: 5.5881 - acc: 0.4653 - val_loss: 5.4228 - val_acc: 0.4993\n",
      "Epoch 1438/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5833 - acc: 0.4647Epoch 01437: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 5.5805 - acc: 0.4653 - val_loss: 5.4225 - val_acc: 0.4993\n",
      "Epoch 1439/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5840 - acc: 0.4648Epoch 01438: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.5814 - acc: 0.4653 - val_loss: 5.4223 - val_acc: 0.4993\n",
      "Epoch 1440/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5909 - acc: 0.4653Epoch 01439: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 186s - loss: 5.5911 - acc: 0.4653 - val_loss: 5.4222 - val_acc: 0.4993\n",
      "Epoch 1441/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5888 - acc: 0.4654Epoch 01440: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.5897 - acc: 0.4653 - val_loss: 5.4221 - val_acc: 0.4993\n",
      "Epoch 1442/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5881 - acc: 0.4650Epoch 01441: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.5863 - acc: 0.4653 - val_loss: 5.4218 - val_acc: 0.4993\n",
      "Epoch 1443/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5849 - acc: 0.4657Epoch 01442: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 190s - loss: 5.5877 - acc: 0.4653 - val_loss: 5.4217 - val_acc: 0.4993\n",
      "Epoch 1444/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5874 - acc: 0.4652Epoch 01443: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 192s - loss: 5.5870 - acc: 0.4653 - val_loss: 5.4217 - val_acc: 0.4993\n",
      "Epoch 1445/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5863 - acc: 0.4652Epoch 01444: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5853 - acc: 0.4653 - val_loss: 5.4214 - val_acc: 0.4993\n",
      "Epoch 1446/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5859 - acc: 0.4654Epoch 01445: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.5863 - acc: 0.4653 - val_loss: 5.4213 - val_acc: 0.4993\n",
      "Epoch 1447/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5901 - acc: 0.4649Epoch 01446: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 189s - loss: 5.5881 - acc: 0.4653 - val_loss: 5.4213 - val_acc: 0.4993\n",
      "Epoch 1448/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5809 - acc: 0.4656Epoch 01447: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 196s - loss: 5.5828 - acc: 0.4653 - val_loss: 5.4212 - val_acc: 0.4993\n",
      "Epoch 1449/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5824 - acc: 0.4656Epoch 01448: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 185s - loss: 5.5847 - acc: 0.4653 - val_loss: 5.4211 - val_acc: 0.4993\n",
      "Epoch 1450/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5893 - acc: 0.4653Epoch 01449: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 191s - loss: 5.5891 - acc: 0.4653 - val_loss: 5.4210 - val_acc: 0.4993\n",
      "Epoch 1451/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5812 - acc: 0.4651Epoch 01450: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5799 - acc: 0.4653 - val_loss: 5.4207 - val_acc: 0.4993\n",
      "Epoch 1452/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5795 - acc: 0.4650Epoch 01451: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.5785 - acc: 0.4653 - val_loss: 5.4205 - val_acc: 0.4993\n",
      "Epoch 1453/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5851 - acc: 0.4646Epoch 01452: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 199s - loss: 5.5820 - acc: 0.4653 - val_loss: 5.4203 - val_acc: 0.4993\n",
      "Epoch 1454/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5855 - acc: 0.4651Epoch 01453: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 197s - loss: 5.5847 - acc: 0.4653 - val_loss: 5.4202 - val_acc: 0.4993\n",
      "Epoch 1455/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5848 - acc: 0.4654Epoch 01454: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.5856 - acc: 0.4653 - val_loss: 5.4202 - val_acc: 0.4993\n",
      "Epoch 1456/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5836 - acc: 0.4646Epoch 01455: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 208s - loss: 5.5804 - acc: 0.4653 - val_loss: 5.4198 - val_acc: 0.4993\n",
      "Epoch 1457/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5841 - acc: 0.4653Epoch 01456: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 204s - loss: 5.5845 - acc: 0.4653 - val_loss: 5.4198 - val_acc: 0.4993\n",
      "Epoch 1458/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5803 - acc: 0.4654Epoch 01457: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 198s - loss: 5.5805 - acc: 0.4653 - val_loss: 5.4196 - val_acc: 0.4993\n",
      "Epoch 1459/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5887 - acc: 0.4657Epoch 01458: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 193s - loss: 5.5906 - acc: 0.4653 - val_loss: 5.4195 - val_acc: 0.4993\n",
      "Epoch 1460/2000\n",
      "758/760 [============================>.] - ETA: 0s - loss: 5.5846 - acc: 0.4652Epoch 01459: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 213s - loss: 5.5841 - acc: 0.4653 - val_loss: 5.4193 - val_acc: 0.4993\n",
      "Epoch 1461/2000\n",
      " 38/760 [>.............................] - ETA: 4340s - loss: 5.6449 - acc: 0.4586 ETA: 4182s - loss: 5.8682 - ETA: 4492s - loss: 5.67"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.955837). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42/760 [>.............................] - ETA: 3954s - loss: 5.5914 - acc: 0.4708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.605856). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 44/760 [>.............................] - ETA: 3776s - loss: 5.5638 - acc: 0.4744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.096212). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 46/760 [>.............................] - ETA: 3608s - loss: 5.5904 - acc: 0.4701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.654366). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/760 [================>.............] - ETA: 820s - loss: 5.6145 - acc: 0.4603- ETA: 352s - loss - ETA: 725s - loss: 5.6082 - acc: - ETA: 787s - loss: 5.6277 - acc: 0.45 - ETA: 788s - loss: 5.6223 - acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.846838). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "448/760 [================>.............] - ETA: 812s - loss: 5.6164 - acc: 0.4599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.794470). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "450/760 [================>.............] - ETA: 803s - loss: 5.6204 - acc: 0.4592"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.931150). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 3s - loss: 5.5824 - acc: 0.4649Epoch 01460: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 1294s - loss: 5.5803 - acc: 0.4653 - val_loss: 5.4192 - val_acc: 0.4993\n",
      "Epoch 1462/2000\n",
      " 12/760 [..............................] - ETA: 3027s - loss: 5.5668 - acc: 0.4667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.592260). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 14/760 [..............................] - ETA: 2621s - loss: 5.6886 - acc: 0.4429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.088369). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 16/760 [..............................] - ETA: 2308s - loss: 5.7326 - acc: 0.4344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.087277). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 18/760 [..............................] - ETA: 2064s - loss: 5.6734 - acc: 0.4472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.086186). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 20/760 [..............................] - ETA: 1869s - loss: 5.6715 - acc: 0.4475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.543769). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.5803 - acc: 0.4657Epoch 01461: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 281s - loss: 5.5828 - acc: 0.4653 - val_loss: 5.4190 - val_acc: 0.4993\n",
      "Epoch 1463/2000\n",
      "  8/760 [..............................] - ETA: 4495s - loss: 5.2153 - acc: 0.5344 ETA: 6376s - loss: 5.2606 - acc: 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.551529). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 10/760 [..............................] - ETA: 3636s - loss: 5.4056 - acc: 0.4925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.381468). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 12/760 [..............................] - ETA: 3049s - loss: 5.4044 - acc: 0.4896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.691459). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/760 [============================>.] - ETA: 0s - loss: 5.5798 - acc: 0.4653Epoch 01462: saving model to SummarizationWithoutAttentionV3.2.7Weights.hdf5\n",
      "760/760 [==============================] - 255s - loss: 5.5800 - acc: 0.4653 - val_loss: 5.4188 - val_acc: 0.4993\n",
      "Epoch 1464/2000\n",
      "102/760 [===>..........................] - ETA: 6010s - loss: 5.4867 - acc: 0.4750"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=[TrainingDataIX,decoderInputSummary], \n",
    "          y=decoderTargetSummary,\n",
    "          batch_size=2,\n",
    "          epochs=2000,\n",
    "          validation_split=0.2,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25976973999487724]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKzgHgZlZwf0v31rWoG1QKaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1f4e77410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 190 samples\n",
      "Epoch 11/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8603 - acc: 0.5215Epoch 00010: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 129s - loss: 4.8668 - acc: 0.5199 - val_loss: 4.9409 - val_acc: 0.5284\n",
      "Epoch 12/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8487 - acc: 0.5271Epoch 00011: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 127s - loss: 4.8505 - acc: 0.5263 - val_loss: 4.9928 - val_acc: 0.5284\n",
      "Epoch 13/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8413 - acc: 0.5338Epoch 00012: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 127s - loss: 4.8399 - acc: 0.5337 - val_loss: 5.0013 - val_acc: 0.5326\n",
      "Epoch 14/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8086 - acc: 0.5396Epoch 00013: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 135s - loss: 4.8112 - acc: 0.5391 - val_loss: 4.9941 - val_acc: 0.5313\n",
      "Epoch 15/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8093 - acc: 0.5397Epoch 00014: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 135s - loss: 4.8033 - acc: 0.5404 - val_loss: 4.9686 - val_acc: 0.5343\n",
      "Epoch 16/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7874 - acc: 0.5419Epoch 00015: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 130s - loss: 4.7858 - acc: 0.5418 - val_loss: 4.9955 - val_acc: 0.5358\n",
      "Epoch 17/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.8177 - acc: 0.5453Epoch 00016: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 129s - loss: 4.8146 - acc: 0.5453 - val_loss: 5.0286 - val_acc: 0.5345\n",
      "Epoch 18/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7818 - acc: 0.5485Epoch 00017: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 128s - loss: 4.7806 - acc: 0.5480 - val_loss: 4.9436 - val_acc: 0.5376\n",
      "Epoch 19/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7615 - acc: 0.5500Epoch 00018: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 127s - loss: 4.7624 - acc: 0.5492 - val_loss: 4.9465 - val_acc: 0.5396\n",
      "Epoch 20/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7385 - acc: 0.5516Epoch 00019: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 126s - loss: 4.7484 - acc: 0.5500 - val_loss: 4.9699 - val_acc: 0.5383\n",
      "Epoch 21/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7546 - acc: 0.5517Epoch 00020: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 128s - loss: 4.7496 - acc: 0.5522 - val_loss: 5.0428 - val_acc: 0.5350\n",
      "Epoch 22/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7272 - acc: 0.5571Epoch 00021: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 128s - loss: 4.7267 - acc: 0.5567 - val_loss: 4.9989 - val_acc: 0.5392\n",
      "Epoch 23/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7245 - acc: 0.5561Epoch 00022: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 127s - loss: 4.7147 - acc: 0.5578 - val_loss: 5.0095 - val_acc: 0.5396\n",
      "Epoch 24/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7183 - acc: 0.5583Epoch 00023: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 137s - loss: 4.7167 - acc: 0.5578 - val_loss: 4.9510 - val_acc: 0.5350\n",
      "Epoch 25/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7049 - acc: 0.5572Epoch 00024: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 134s - loss: 4.7006 - acc: 0.5575 - val_loss: 4.9801 - val_acc: 0.5395\n",
      "Epoch 26/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7161 - acc: 0.5599Epoch 00025: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 127s - loss: 4.7128 - acc: 0.5604 - val_loss: 4.9872 - val_acc: 0.5396\n",
      "Epoch 27/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7087 - acc: 0.5604Epoch 00026: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 133s - loss: 4.7048 - acc: 0.5610 - val_loss: 4.9668 - val_acc: 0.5409\n",
      "Epoch 28/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.7186 - acc: 0.5610Epoch 00027: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 132s - loss: 4.7068 - acc: 0.5628 - val_loss: 4.9796 - val_acc: 0.5371\n",
      "Epoch 29/1000\n",
      "736/760 [============================>.] - ETA: 4s - loss: 4.6930 - acc: 0.5653Epoch 00028: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 142s - loss: 4.6985 - acc: 0.5639 - val_loss: 5.0086 - val_acc: 0.5368\n",
      "Epoch 30/1000\n",
      "736/760 [============================>.] - ETA: 4s - loss: 4.7160 - acc: 0.5630Epoch 00029: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 138s - loss: 4.7108 - acc: 0.5642 - val_loss: 5.1025 - val_acc: 0.5345\n",
      "Epoch 31/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6905 - acc: 0.5633Epoch 00030: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 136s - loss: 4.6797 - acc: 0.5649 - val_loss: 4.9867 - val_acc: 0.5361\n",
      "Epoch 32/1000\n",
      "736/760 [============================>.] - ETA: 4s - loss: 4.6749 - acc: 0.5667Epoch 00031: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 143s - loss: 4.6655 - acc: 0.5681 - val_loss: 5.0024 - val_acc: 0.5374\n",
      "Epoch 33/1000\n",
      "736/760 [============================>.] - ETA: 5s - loss: 4.6577 - acc: 0.5689 Epoch 00032: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 183s - loss: 4.6624 - acc: 0.5678 - val_loss: 4.9543 - val_acc: 0.5372\n",
      "Epoch 34/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6458 - acc: 0.5698Epoch 00033: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 132s - loss: 4.6497 - acc: 0.5686 - val_loss: 4.9782 - val_acc: 0.5411\n",
      "Epoch 35/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6462 - acc: 0.5701Epoch 00034: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 139s - loss: 4.6400 - acc: 0.5710 - val_loss: 5.0355 - val_acc: 0.5382\n",
      "Epoch 36/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6312 - acc: 0.5707Epoch 00035: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 138s - loss: 4.6302 - acc: 0.5712 - val_loss: 4.9575 - val_acc: 0.5395\n",
      "Epoch 37/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6479 - acc: 0.5717Epoch 00036: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 134s - loss: 4.6409 - acc: 0.5725 - val_loss: 4.9707 - val_acc: 0.5361\n",
      "Epoch 38/1000\n",
      "736/760 [============================>.] - ETA: 4s - loss: 4.6174 - acc: 0.5756Epoch 00037: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 139s - loss: 4.6266 - acc: 0.5738 - val_loss: 5.1379 - val_acc: 0.5376\n",
      "Epoch 39/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6444 - acc: 0.5730Epoch 00038: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 136s - loss: 4.6406 - acc: 0.5733 - val_loss: 5.0388 - val_acc: 0.5361\n",
      "Epoch 40/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6550 - acc: 0.5733Epoch 00039: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 128s - loss: 4.6477 - acc: 0.5742 - val_loss: 5.0179 - val_acc: 0.5343\n",
      "Epoch 41/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6129 - acc: 0.5769Epoch 00040: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 130s - loss: 4.6133 - acc: 0.5766 - val_loss: 5.0452 - val_acc: 0.5386\n",
      "Epoch 42/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6190 - acc: 0.5764Epoch 00041: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 129s - loss: 4.6222 - acc: 0.5756 - val_loss: 4.9602 - val_acc: 0.5387\n",
      "Epoch 43/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6066 - acc: 0.5785Epoch 00042: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 132s - loss: 4.6091 - acc: 0.5779 - val_loss: 5.1236 - val_acc: 0.5376\n",
      "Epoch 44/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6177 - acc: 0.5780Epoch 00043: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 136s - loss: 4.6198 - acc: 0.5772 - val_loss: 4.9727 - val_acc: 0.5376\n",
      "Epoch 45/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6076 - acc: 0.5785Epoch 00044: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 131s - loss: 4.6062 - acc: 0.5787 - val_loss: 5.0180 - val_acc: 0.5380\n",
      "Epoch 46/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.6203 - acc: 0.5752Epoch 00045: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 131s - loss: 4.6063 - acc: 0.5771 - val_loss: 4.9678 - val_acc: 0.5351\n",
      "Epoch 47/1000\n",
      "736/760 [============================>.] - ETA: 7s - loss: 4.5834 - acc: 0.5815 Epoch 00046: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 240s - loss: 4.5847 - acc: 0.5806 - val_loss: 4.9432 - val_acc: 0.5391\n",
      "Epoch 48/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.5912 - acc: 0.5818Epoch 00047: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 133s - loss: 4.5979 - acc: 0.5806 - val_loss: 4.9610 - val_acc: 0.5389\n",
      "Epoch 49/1000\n",
      "736/760 [============================>.] - ETA: 3s - loss: 4.5851 - acc: 0.5814Epoch 00048: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 131s - loss: 4.5835 - acc: 0.5814 - val_loss: 4.9735 - val_acc: 0.5386\n",
      "Epoch 50/1000\n",
      "736/760 [============================>.] - ETA: 4s - loss: 4.5812 - acc: 0.5810Epoch 00049: saving model to SummarizationWithoutAttentionV3.2.5Weights.hdf5\n",
      "760/760 [==============================] - 141s - loss: 4.5838 - acc: 0.5804 - val_loss: 5.0447 - val_acc: 0.5380\n",
      "Epoch 51/1000\n",
      "512/760 [===================>..........] - ETA: 43s - loss: 4.5863 - acc: 0.5821"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-22969739c0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_split=0.2,callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(x=[TrainingDataIX,decoderInputSummary], \n",
    "          y=decoderTargetSummary,\n",
    "          batch_size=32,\n",
    "          epochs=1000,initial_epoch=10,\n",
    "          validation_split=0.2,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28921052664518354, 0.47055921429081965, 0.47368421240856773, 0.47980263452780875, 0.48845394818406357, 0.48957236597412512, 0.49608553365657204, 0.49970394655277856, 0.50911184423848199, 0.51878289674457756]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7097e1610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder Inference\n",
    "encoder_model_inf=Model(inputs=encoder_input,outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder Inference\n",
    "decoder_state_input_h=Input(shape=(300,))\n",
    "decoder_state_input_c = Input(shape=(300,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input,initial_state=decoder_input_states)\n",
    "decoder_states=[decoder_h,decoder_c]\n",
    "#decoder_inf_out = decoder_dense_rel(decoder_out)\n",
    "#decoder_inf_final_out=decoder_dense(decoder_inf_out)\n",
    "#decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,outputs=[decoder_inf_final_out] + decoder_states )\n",
    "decoder_inf_final_out = decoder_dense(decoder_out)\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_inf_final_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5423"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modiefiedSummaryWord_index['SOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_vocab_summaries = {}\n",
    "for word, value in modiefiedSummaryWord_index.items():\n",
    "    int_to_vocab_summaries[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(input_seq):\n",
    "    # Initial states value is coming from the encoder \n",
    "    #We get the encoder states into states_val variable\n",
    "    states_val = encoder_model_inf.predict(input_seq)#return encoder states\n",
    "    target_seq = np.zeros((1,1,ModifiedVocabSize))\n",
    "    print('target_seq shape:->',target_seq.shape)\n",
    "    target_seq[0, 0, modiefiedSummaryWord_index['SOS']] = 1\n",
    "    print(target_seq.shape)\n",
    "    #target_seq=embeddingModifiedSummaries[modiefiedSummaryWord_index['SOS']]\n",
    "    summarized_sent = ''\n",
    "    stop_condition = False\n",
    "    i=1\n",
    "    while not stop_condition:\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #print(decoder_out)\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_summary_word = int_to_vocab_summaries[max_val_index]\n",
    "        #print('sampled_summary_word is:->',sampled_summary_word)\n",
    "        #print()\n",
    "        summarized_sent += sampled_summary_word+\" \"\n",
    "        #print('summarized_sent is:->',summarized_sent)\n",
    "        #print()\n",
    "        if ((sampled_summary_word == 'EOS') or (len(summarized_sent) >= maxSummaryLength)) :\n",
    "            print('terminated')\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1,1,ModifiedVocabSize))\n",
    "        target_seq[0, 0, max_val_index]=1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        i=i+1\n",
    "        \n",
    "    return summarized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  after a string of subpar sequels this bloody actionpacked reboot takes the predator franchise back to its testosteronefueled roots PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  half nelson features powerful performances from ryan gosling and shareeka epps it is a wise unsentimental portrait of lonely people at the crossroads PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  director werner herzog has once again made a compelling tale of man versus nature and christian bale completely immerses himself in the role of fighter pilot and prisoner of war dieter dengler PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  colorful rich with action and wonderfully choreographed takeshi kitano takes on the classic samurai character with his own brand of cinematic flair PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  while ben affleck fits the role and the story is sporadically interesting daredevil is ultimately a dull brooding origin story that fails to bring anything new to the genre PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  delightfully sweet like a lollipop just like heaven is a dreamy romantic comedy that may give you a toothache when it attempts to broach difficult end of life issues by throwing a cherry on top PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  an engrossing and energetic portrait of a great musicians achievements and foibles ray is anchored by jamie foxxs stunning performance as ray charles PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the script is unconvincing and the courtroom action is unegaging PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  my neighbor totoro is a heartwarming sentimental masterpiece that captures the simple grace of childhood PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a bleak but heartbreaking comingofage tale that resonates with truth PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  paul newman and jackie gleason give iconic performances in this dark morally complex tale of redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the bad news bears is rude profane and cynical but shot through with honest unforced humor and held together by a deft understated performance from walter matthau PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  smart compassionate and moving the crash reel uses the familiar sportdoc formula to subvert expectations and ask challenging questions about ambition and achievement PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  slow west serves as an impressive calling card for firsttime writerdirector john m maclean and offers an inventive treat for fans of the western PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  tyrannosaur is a brutal frank and ultimately rewarding story of violent men seeking faroff redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  leviathan lives up to its title offering trenchant wellcrafted social satire on a suitably grand scale PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a bmovie with its tongue planted firmly in cheek the core is so unintentionally intentionally bad that it is a hoot PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  as unkempt and inscrutable as joaquin phoenix himself i am still here raises some interesting questions about its subject as well as the nature of celebrity but it fails to answer many of them convincingly PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  with a clever script and hilarious interplay among the cast the hangover nails just the right tone of raunchy humor and the nonstop laughs overshadow any flaw PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  warm and smartly paced and boasting impeccable performances from morgan freeman and jessica tandy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  despite quirky and original writing the subject matter feels too removed to produce laughs PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  casino royale disposes of the silliness and gadgetry that plagued recent james bond outings and daniel craig delivers what fans and critics have been waiting for a caustic haunted intense reinvention of 007 PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  catfish may tread the line between reallife drama and crass exploitation a little too unsteadily for some viewers tastes but its timely premise and tightly wound mystery make for a gripping documentary PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the movie may be a downer but it packs an emotional wallop some fine acting on display here PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  despite a few laughs and good intentions the ringer is too predictable to really score the points it aims for PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  faithful to the source material without sacrificing its own cinematic flair justin kurzels macbeth rises on the strength of a mesmerizing michael fassbender performance to join the upper echelon of bigscreen shakespeare adaptations PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  more depth about the legendary outlaw would be welcome but as it is ned kelly is a reasonably entertaining western PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  lars and the real girl could have so easily been a onejoke movie but the talented cast a great script and direction never condescends to its character or the audience PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a decent performance from pegg in a disappointing film neither sharp nor satirical weides adaptation relies too heavily on slapstick and misses the point of the source material in the process PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  michael caines excellent performance makes flawless something more than an average heist movie PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  if it does not reach the heights of director james camerons and star arnold schwarzeneggers previous collaborations true lies still packs enough action and humor into its sometimes absurd plot to entertain PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this crime drama features great performances and the three directors make the setting 1970s and 1980s yorkshire an immersive gritty and dangerous place PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the jackass gang might be running out of grossout stunts but this installment contains plenty of brilliantly braindead comedy and the 3d adds a pungent new dimension PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  thoughtprovoking and beautifully filmed before sunrise is an intelligent unabashedly romantic look at modern love led by marvelously natural performances from ethan hawke and julie delpy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  anchored by sean penns powerhouse performance milk is a triumphant account of americas first openly gay man elected to public office PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this remake has been praised by some as an expertly made bmovie and dismissed by others as formulaic PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the nightmare before christmas is a stunningly original and visually delightful work of stopmotion animation PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  skinwalkers is an atrociouslyacted project whose unoriginal and ineptlystaged action sequences remind viewers of far better werewolf and action movies PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  narratively contrived and visually a mess the gallows sends viewers on a shaky tumble to the bottom of the foundfootage horror barrel PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a creepy french psychological thriller that commands the audiences attention throughout PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  while sluggish in spots resurrecting the champ is a sportsnewsroom drama elevated by highcaliber performances by samuel jackson josh hartnet and alan alda PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  last night does not opt for easy answers but the framework and characters overall are too slight and plain to be compelling PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  jennifers body features occasionally clever dialogue but the horrorcomic premise fails to be either funny or scary enough to satisfy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  neither fair nor balanced itself outfoxed offers an often entertaining indictment of the fox news channel PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  it may not be as powerful as the 1984 edition but the 2010 karate kid delivers a surprisingly satisfying update on the original PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  it is a pleasure to see hollywood produce a romance this refreshingly adult but love and other drugs struggles to find a balance between its disparate plot elements PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  kurt cobain montage of heck makes a persuasive case for its subject without resorting to hagiography and includes plenty of rare and unreleased footage for fans PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this modest cinematic sliceoflife manages to subtly capture many small but resonant and truthful moments of adolescence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated\n",
      "System Generated Summary: PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  chweneyagaes powerful performance carries this simple yet searing tale of a shantytown teenagers redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  eager to please and stuffed with stars valentines day squanders its promise with a frantic episodic plot and an abundance of romcom cliches PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n"
     ]
    }
   ],
   "source": [
    "human_summary=[]\n",
    "for i in range(50):    \n",
    "    #print('System Generated Summary:',summary)\n",
    "    temp=[]\n",
    "    for j in range(len(testPaddedSummary[i])):\n",
    "        temp.append(int_to_vocab_summaries[testPaddedSummary[i][j]])\n",
    "    human_summary.append(temp)    \n",
    "humanSummary=\" \"        \n",
    "for i in range(50):\n",
    "    data=testPaddedReviews[i].reshape(1,200)\n",
    "    summary=decode_seq(data)\n",
    "    print('System Generated Summary:',summary)\n",
    "    for j in range(len(human_summary[i])):\n",
    "        humanSummary+=human_summary[i][j]+\" \"\n",
    "    print('Human Summary',humanSummary)\n",
    "    humanSummary=\" \"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  after a string of subpar sequels this bloody actionpacked reboot takes the predator franchise back to its testosteronefueled roots PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  half nelson features powerful performances from ryan gosling and shareeka epps it is a wise unsentimental portrait of lonely people at the crossroads PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  director werner herzog has once again made a compelling tale of man versus nature and christian bale completely immerses himself in the role of fighter pilot and prisoner of war dieter dengler PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  colorful rich with action and wonderfully choreographed takeshi kitano takes on the classic samurai character with his own brand of cinematic flair PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  while ben affleck fits the role and the story is sporadically interesting daredevil is ultimately a dull brooding origin story that fails to bring anything new to the genre PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  delightfully sweet like a lollipop just like heaven is a dreamy romantic comedy that may give you a toothache when it attempts to broach difficult end of life issues by throwing a cherry on top PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  an engrossing and energetic portrait of a great musicians achievements and foibles ray is anchored by jamie foxxs stunning performance as ray charles PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the script is unconvincing and the courtroom action is unegaging PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  my neighbor totoro is a heartwarming sentimental masterpiece that captures the simple grace of childhood PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a bleak but heartbreaking comingofage tale that resonates with truth PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  paul newman and jackie gleason give iconic performances in this dark morally complex tale of redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the bad news bears is rude profane and cynical but shot through with honest unforced humor and held together by a deft understated performance from walter matthau PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  smart compassionate and moving the crash reel uses the familiar sportdoc formula to subvert expectations and ask challenging questions about ambition and achievement PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  slow west serves as an impressive calling card for firsttime writerdirector john m maclean and offers an inventive treat for fans of the western PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  tyrannosaur is a brutal frank and ultimately rewarding story of violent men seeking faroff redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  leviathan lives up to its title offering trenchant wellcrafted social satire on a suitably grand scale PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a bmovie with its tongue planted firmly in cheek the core is so unintentionally intentionally bad that it is a hoot PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  as unkempt and inscrutable as joaquin phoenix himself i am still here raises some interesting questions about its subject as well as the nature of celebrity but it fails to answer many of them convincingly PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  with a clever script and hilarious interplay among the cast the hangover nails just the right tone of raunchy humor and the nonstop laughs overshadow any flaw PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  warm and smartly paced and boasting impeccable performances from morgan freeman and jessica tandy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  despite quirky and original writing the subject matter feels too removed to produce laughs PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  casino royale disposes of the silliness and gadgetry that plagued recent james bond outings and daniel craig delivers what fans and critics have been waiting for a caustic haunted intense reinvention of 007 PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  catfish may tread the line between reallife drama and crass exploitation a little too unsteadily for some viewers tastes but its timely premise and tightly wound mystery make for a gripping documentary PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the movie may be a downer but it packs an emotional wallop some fine acting on display here PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  despite a few laughs and good intentions the ringer is too predictable to really score the points it aims for PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  faithful to the source material without sacrificing its own cinematic flair justin kurzels macbeth rises on the strength of a mesmerizing michael fassbender performance to join the upper echelon of bigscreen shakespeare adaptations PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  more depth about the legendary outlaw would be welcome but as it is ned kelly is a reasonably entertaining western PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  lars and the real girl could have so easily been a onejoke movie but the talented cast a great script and direction never condescends to its character or the audience PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a decent performance from pegg in a disappointing film neither sharp nor satirical weides adaptation relies too heavily on slapstick and misses the point of the source material in the process PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  michael caines excellent performance makes flawless something more than an average heist movie PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  if it does not reach the heights of director james camerons and star arnold schwarzeneggers previous collaborations true lies still packs enough action and humor into its sometimes absurd plot to entertain PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this crime drama features great performances and the three directors make the setting 1970s and 1980s yorkshire an immersive gritty and dangerous place PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the jackass gang might be running out of grossout stunts but this installment contains plenty of brilliantly braindead comedy and the 3d adds a pungent new dimension PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  thoughtprovoking and beautifully filmed before sunrise is an intelligent unabashedly romantic look at modern love led by marvelously natural performances from ethan hawke and julie delpy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  anchored by sean penns powerhouse performance milk is a triumphant account of americas first openly gay man elected to public office PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this remake has been praised by some as an expertly made bmovie and dismissed by others as formulaic PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  the nightmare before christmas is a stunningly original and visually delightful work of stopmotion animation PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  skinwalkers is an atrociouslyacted project whose unoriginal and ineptlystaged action sequences remind viewers of far better werewolf and action movies PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  narratively contrived and visually a mess the gallows sends viewers on a shaky tumble to the bottom of the foundfootage horror barrel PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  a creepy french psychological thriller that commands the audiences attention throughout PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  while sluggish in spots resurrecting the champ is a sportsnewsroom drama elevated by highcaliber performances by samuel jackson josh hartnet and alan alda PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  last night does not opt for easy answers but the framework and characters overall are too slight and plain to be compelling PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  jennifers body features occasionally clever dialogue but the horrorcomic premise fails to be either funny or scary enough to satisfy PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the the PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  neither fair nor balanced itself outfoxed offers an often entertaining indictment of the fox news channel PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  it may not be as powerful as the 1984 edition but the 2010 karate kid delivers a surprisingly satisfying update on the original PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  it is a pleasure to see hollywood produce a romance this refreshingly adult but love and other drugs struggles to find a balance between its disparate plot elements PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  kurt cobain montage of heck makes a persuasive case for its subject without resorting to hagiography and includes plenty of rare and unreleased footage for fans PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  this modest cinematic sliceoflife manages to subtly capture many small but resonant and truthful moments of adolescence PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  chweneyagaes powerful performance carries this simple yet searing tale of a shantytown teenagers redemption PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "target_seq shape:-> (1, 1, 5425)\n",
      "(1, 1, 5425)\n",
      "terminated\n",
      "System Generated Summary: the PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "Human Summary  eager to please and stuffed with stars valentines day squanders its promise with a frantic episodic plot and an abundance of romcom cliches PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD \n",
      "BlEU SCORE IS:-> 0\n",
      "AVERAGE BLEU SCORE:-> 0.0\n"
     ]
    }
   ],
   "source": [
    "humanSummary=\" \"  \n",
    "scores=[]\n",
    "for i in range(50):\n",
    "    testData=testPaddedReviews[i].reshape(1,200)\n",
    "    summary=decode_seq(testData)\n",
    "    print('System Generated Summary:',summary)\n",
    "    for j in range(len(human_summary[i])):\n",
    "        humanSummary+=human_summary[i][j]+\" \"\n",
    "    print('Human Summary',humanSummary)\n",
    "    #calculation of bleu score\n",
    "    score=sentence_bleu(nltk.word_tokenize(summary),nltk.word_tokenize(humanSummary),weights=(0.5, 0.5, 0, 0))\n",
    "    print('BlEU SCORE IS:->',score)\n",
    "    scores.append(score)      \n",
    "    humanSummary=\" \"\n",
    "\n",
    "total=0\n",
    "for i in scores:\n",
    "    total+=i\n",
    "print('AVERAGE BLEU SCORE:->',total/len(scores))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
